Title: AAD PostgreSQL Setup.txt
AAD PostgreSQL Setup

To register and login Azure PostgreSQL servers, the following procedure, step by step, must be performed.  Also, each login will require repeating certain steps as noted.

Open a terminal or command line application and type in the following command as shown below: (az login)



Select the appropriate account as shown below:




Once the account is selected, the following page will be displayed after a successful login:



The terminal will show the following output:




Next, type in the following command as show below: (az account get-access-token --resource https://ossrdbms-aad.database.windows.net)



The following output from the command in Step 5 will be display as follows:



NOTE!  The accessToken value between the double quotes will need to be used as the password for logging into PostgreSQL servers the account is authorized for during the current session.  Do not close the terminal window or the process will need to be repeated from Step 1.


Open and login to the Azure Portal and the AADPIM (Azure AD Privileged Identity Management) area as shown below: (Entering Azure AD Privileged Identity Management in the search bar within the Azure Portal will also navigate to the appropriate landing page)



Select on the “Groups” item in the list at the left side of the page as shown below:



After the redirect occurs and the new page loads, select the appropriate group shown below:



After the page redirects from Step 9, click on the “Activate” link on the page that loads as shown below:




After clicking “Activate”, the following tab will be displayed and must be completed, see example below: (Make sure to put in the necessary information under the “Reason” for accessing an upper environment, such as a CR number or other appropriate reason, then click on “Activate” to complete the process.)




Once the “Activate” button is clicked, a series of operations will take place as shown in the following screenshots shown:









The image above represents the landing page that will be displayed after the two preceding images processes are completed.  The AADPIM process is now completed, and no further action currently is necessary within the portal.

Open pgAdmin, enter the master password for the installation locally.  Once loaded, right click on the “Servers” item in the list, then “Register”, then “Server” as shown below:




The following screenshots show the registration details, but those will vary according to the server being register and are only provided as an example with one exception.  The username for ALL registrations MUST be the AAD Group shown, which is the same group which was used in Steps 7-11.  Also note that during the setup, make sure to deselect the “Connect now?” option before clicking the “Save” button.  Images on the left show the state before clicking “Save”.  Images on the right show a successfully registered server as well as the required entries for the given fields.

 

 
Double click on the newly registered server as shown below:




The following password entry dialog will be displayed.  Copy the accessToken that was created from Step 5 and displayed in Step 6.  Take care to copy only the value between the double quotes and do not include the double quotes.  This value will be the password that is required to be entered into the dialog box as shown below: (Note!  Do not click “Save Password” as a new accessToken will likely be required upon next login.  Tokens expire regularly and will not last longer than 4-8 hours.  These tokens are randomly assigned expiry dates and times.  Once done pasting the accessToken, click on the “OK” button to complete the login process.



After clicking “OK”, and provided the correct accessToken has been entered, the following screenshot shows a successful login:



The process is now complete, no further actions are required unless the token expires.  If the token expires, all steps must be repeated, omitting Step 12 and Step 13 if the AADPIM has expired.  If AADPIM has not expired, Step 7 through Step 13 will be omitted.

--------------------------------------------------------------------------------
Title: Account updation.txt
Use case – Forgot to add account number in the dispute.


Note – If the dispute is a direct dispute we can update the account number but cannot update if it is for regular dispute (ACDV’s)


Query to update-  update direct_dispute set account_number = '205A1YD75Y1O1FM2MRB8G98UJ' where id = 50128346

change the account number and the id number according to the information provided.

Run the above query in pg-admin and give response to the ticket and mark as solved.

--------------------------------------------------------------------------------
Title: ACDV's response code error.txt

USE CASE 11 - ACDV’S RESPONSE CODE ERROR

Step 1- Go to Sonnet and select the company.
Step 2- Open the shared folder and click on the Fix response code error.sql

QUERY -      select dispute.company_id, response_due_date,name, error_message, dispute.id from dispute
join company on company.id=dispute.company_id
join eoscar_response_errors err on err.dispute_id=dispute.id
where sonnet_status='Error'
order by response_due_date

Update eoscar_response
set response_code = '23'
where dispute_id in  (select dispute.id from dispute
join eoscar_response_errors err on err.dispute_id=dispute.id
where sonnet_status='Error'
and error_message like '%RESPONSE CODE ERROR:%You may change your Response Code to 23%')


Update dispute
set sonnet_status='Complete'
where id in (select dispute.id from dispute
join eoscar_response_errors err on err.dispute_id=dispute.id
where sonnet_status='Error'
and error_message like '%RESPONSE CODE ERROR:%You may change your Response Code to 23%')

Update eoscar_response
set response_code = '22'
where dispute_id in  (select dispute.id from dispute
join eoscar_response_errors err on err.dispute_id=dispute.id
where sonnet_status='Error'
and error_message like '%RESPONSE CODE ERROR:%You may change your Response Code to 22%')

Update dispute
set sonnet_status='Complete'
where id in (select dispute.id from dispute
join eoscar_response_errors err on err.dispute_id=dispute.id
where sonnet_status='Error'
and error_message like '%RESPONSE CODE ERROR:%You may change your Response Code to 22%')

Update eoscar_response
set response_code = '21'
where dispute_id in  (select dispute.id from dispute
join eoscar_response_errors err on err.dispute_id=dispute.id
where sonnet_status='Error'
and error_message like '%RESPONSE CODE ERROR:%You may change your Response Code to 21%')

Update dispute
set sonnet_status='Complete'
where id in (select dispute.id from dispute
join eoscar_response_errors err on err.dispute_id=dispute.id
where sonnet_status='Error'
and error_message like '%RESPONSE CODE ERROR:%You may change your Response Code to 21%') 

Step 4- Run the above query one at a time.
Step 5- Go to the sonnet and give a response and mark the ticket as solved and submit it.


--------------------------------------------------------------------------------
Title: APCU - SymXchange Credentials Worksheet - Complete.txt
 	 	 
SymXchange Credentials Worksheet 
Please complete the entire form below and return to your assigned project manager.   
To be completed by customer: 
 
 
 
WSDL Standard URL : http://<IP Address>:<port>/SymXchange/  OR  https://<IP Address>:<port>/SymXchange/ 
For trivial inquiries (modeling Home banking or other login) use HB Credentials  all accounts have login / names passwords set in the following formula: 
VPN IPs setup
Regular Net: 172.20.2.16/29
TEST IP:
PROD IP:

DR Net: 172.20.1.16/29
TEST IP:
PROD IP:




Limited Distribution 	Page 1 of 1 	March 2022 
 
--------------------------------------------------------------------------------
Title: API client clearing queue in step 3.txt
Use case-  API client clearing the data in the step 3 even if the data files are not available for the company .    For reference  ticket # 21850, company name – Mortgage portal.


Question - 

Step 1- Open Pg-admin and execute the below query

Query 1 – Select * from facs_file_queue where company_id = ------  and file_step =3.
Query 2- delete from facs_file_queue where company_id = 14400 and file_step =3

Run these 2 queries in Pg- admin and check in the sonnet dashboard the data files have changed to 0.



--------------------------------------------------------------------------------
Title: Azure-SSH-Server Logins.txt
How to login with Active Directory SSH to production (Only production requires PIM access)
First activate your PIM group 
You can go to https://portal.azure.com search on Azure AD Privileged Identity management then select that link.  Once in the PIM portal select SECD-PaliPrd-Virtual-Machine-Admin under eligible assignments then activate access with reference to support ticket, change control or dev ops story.

Activate your role – note default is 24 hours.



Step 1: Ensure you have the latest Azure CLI installed.

You can install the Azure CLI from https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest . Note that you can install this on Windows, macOS, and just about any flavor of Linux.
Step 2: Run the Azure CLI and log into your Azure account.

Once you've installed the CLI, open a command prompt, terminal, or PowerShell and run the following command to log into your Azure account.

az login
Step 3: Install the SSH extension for Azure CLI
az extension add --name ssh
Step4: Use the command to login into the vm’s in a subscription.
Production Servers require PIM!
az ssh vm --vm-name prdpipe-l01 --resource-group rg-PaliPRD-LAN --prefer-private-ip --subscription Sonnet_Production_Environment

az ssh vm --vm-name prdkey01 --resource-group rg-PaliPRD-LAN --prefer-private-ip --subscription Sonnet_Production_Environment
SFTP Severs
az ssh vm --vm-name prdweb01 --resource-group rg-PaliPRD-DMZ --prefer-private-ip --subscription Sonnet_Production_Environment
az ssh vm --vm-name prdweb02 --resource-group rg-PaliPRD-DMZ --prefer-private-ip --subscription Sonnet_Production_Environment
API Server
az ssh vm --vm-name prdapi02 --resource-group rg-PaliPRD-DMZ --prefer-private-ip --subscription Sonnet_Production_Environment

az ssh vm --vm-name prdcoresa01 --resource-group rg-PaliPRD-IMZ --prefer-private-ip --subscription Sonnet_Production_Environment
az ssh vm --vm-name prdint01 --resource-group rg-PaliPRD-IMZ --prefer-private-ip --subscription Sonnet_Production_Environment
Image Servers
az ssh vm --vm-name prdrpa01 --resource-group rg-PaliPRD-IMZ --prefer-private-ip --subscription Sonnet_Production_Environment
az ssh vm --vm-name prdrpa02 --resource-group rg-PaliPRD-IMZ --prefer-private-ip --subscription Sonnet_Production_Environment
az ssh vm --vm-name prdocr01 --resource-group rg-PaliPRD-LAN --prefer-private-ip --subscription Sonnet_Production_Environment
az ssh vm --vm-name prdresp01 --resource-group rg-PaliPRD-LAN --prefer-private-ip --subscription Sonnet_Production_Environment
az ssh vm --vm-name prdresp02 --resource-group rg-PaliPRD-LAN --prefer-private-ip --subscription Sonnet_Production_Environment
Rules Engine Server
az ssh vm --vm-name prdre01 --resource-group rg-PaliPRD-LAN --prefer-private-ip --subscription Sonnet_Production_Environment


CQA
az ssh vm --vm-name cqaweb01 --resource-group rg-PaliCQA-DMZ --prefer-private-ip --subscription Sonnet_CQA_Environment


UAT 
az ssh vm --vm-name uatkey01  --resource-group rg-Paliuat-LAN --prefer-private-ip --subscription Sonnet_UAT_Environment
az ssh vm --vm-name uatapi01  --resource-group rg-Paliuat-DMZ --prefer-private-ip --subscription Sonnet_UAT_Environment
az ssh vm --vm-name uatweb01 --resource-group rg-Paliuat-DMZ --prefer-private-ip --subscription Sonnet_UAT_Environment
az ssh vm --vm-name uatresp01  --resource-group rg-Paliuat-LAN --prefer-private-ip --subscription Sonnet_UAT_Environment
az ssh vm --vm-name uatint01  --resource-group rg-Paliuat-IMZ --prefer-private-ip --subscription Sonnet_UAT_Environment
az ssh vm --vm-name uatrpa02  --resource-group rg-Paliuat-IMZ --prefer-private-ip --subscription Sonnet_UAT_Environment
az ssh vm --vm-name uatpipe-l01  --resource-group rg-Paliuat-LAN --prefer-private-ip --subscription Sonnet_UAT_Environment
az ssh vm --vm-name uatrpa01  --resource-group rg-Paliuat-IMZ --prefer-private-ip --subscription Sonnet_UAT_Environment
az ssh vm --vm-name uatre01  --resource-group rg-Paliuat-LAN --prefer-private-ip --subscription Sonnet_UAT_Environment
az ssh vm --vm-name uatcoresa01 --resource-group rg-Paliuat-IMZ --prefer-private-ip --subscription Sonnet_UAT_Environment




Dev
az ssh vm --vm-name devrpa02 --resource-group  rg-PaliDev-IMZ --prefer-private-ip --subscription Sonnet_Development_Environment
az ssh vm --vm-name devweb01 --resource-group  rg-PaliDev-DMZ --prefer-private-ip --subscription Sonnet_Development_Environment
az ssh vm --vm-name Devlinux-vm1  --resource-group  sonnet-dev --prefer-private-ip --subscription Sonnet_Development_Environment
az ssh vm --vm-name devapi01  --resource-group  rg-Palidev-DMZ --prefer-private-ip --subscription Sonnet_Development_Environment
az ssh vm --vm-name devresp01  --resource-group  rg-Palidev-LAN --prefer-private-ip --subscription Sonnet_Development_Environment
az ssh vm --vm-name devrpa02  --resource-group  rg-Palidev-LAN --prefer-private-ip --subscription Sonnet_Development_Environment
az ssh vm --vm-name devint01 --resource-group rg-PaliDev-IMZ --prefer-private-ip --subscription Sonnet_Development_Environment
az ssh vm --vm-name devre01  --resource-group  rg-Palidev-LAN --prefer-private-ip --subscription Sonnet_Development_Environment



Export the SSH configuration for use with SSH clients that support OpenSSH
https://learn.microsoft.com/en-us/azure/active-directory/devices/howto-vm-sign-in-azure-ad-linux#export-the-ssh-configuration-for-use-with-ssh-clients-that-support-openssh
such as putty etc..

--------------------------------------------------------------------------------
Title: Azure_New_Client_Implementation-Backend.txt
Azure Client Implementation Back End 
Objective:  Set up the automation for new clients; setup may include creating the applicable server directories and FTP Users, updating automation scripts, and allowing access to Palinode production servers.     


Create Directory on prdrpa01 and prdrpa02 Servers 
All Clients will need a directory on prdrpa01, prdrpa02.  Without these directories or an incorrect setup of a directory, downloading from e-Oscar will cause degraded server performance. 
Log into the prdrpa01 and prdrapa02 Servers (sudo su – sonnet)
Go to the directory /sonnet/images:   $ cd /sonnet/images.  All companies have a directory where images are placed. 
Run the script to make the company directories.  This script uses sudo command to change permissions.   
$ ./make_dirs.sh companyabbreviation 
Enter server password if prompted
Verify the directory was created correctly and the permissions and owner match other company folders.  ($ ll) 
Also verify the directory in cd /sonnet_attachments/www has the correct permissions and owner. 
To change owner run $ sudo chown sonnet:sonnet companyabbreviation 
Enter server password 
To change folder permissions run $ sudo chmod 775 companyabbreviation 
Enter server password 
If company using API proceed to API Data Exchange 
If company using Batch files proceed to FTP Data Exchange 

API Data Exchange 
Create the company's directory in prdapi01  if the client is using the API.    
Create Directory on prdapi01 Server 
Log into prdapi01 
Go to the directory /sonnet/images:   $ cd /sonnet/images 
Make a directory with the company abbreviation as the name:  $ mkdir companyabbreviation) 
Check the owner and permissions by listing the contents of the /sonnet/images/ directory.  Should be sonnet and drwxrwxr-x 
If owner is not sonnet for the directory created change the owner ($ sudo chown -R sonnet:sonnet companyabbreviation/ ) 
If permissions are incomplete change the permissions ($ sudo chmod -R 775 companyabbrevition/) 
Repeat step 4 


Update Move API Images Script 
This script moves images from the company's prdrpa01 and prdrap02  server directory to the company's prdapi01 server directory for companies using the API Data Exchange method. *CollectOne platform clients use FTP for image transfers and will need to be added to the Move Images script instead of Move API Images. 
Update local repository.  If using Visual Studio Code (VS) open the folder with move images repository.   
Make sure you're on the master branch by using the git command "git status" in the Terminal.  If not on branch master use git command "git checkout master" which will update the branch to master. 
The command "git pull" will refresh your local repository.  
Create a branch named with the following naming convention:  companyIDzdtID 1000zdt1958  
Open the move_api_images.php and add the Company ID to api_company_ids list starting on line 13.  Save changes. 
Open the. gitignore and add the company abbreviation to the end of the list /companyabbreviation.  Save changes 
Stage changes for commit then commit the saved changes.  The commit comments should provide a summary of the change.  Example:  Added companyabbreviation to API move images and gitignore. 
Git push or Push to push branch to bitbucket 
Go to the Move Images branches in move-images - Repos (azure.com), locate your branch and create a pull request.  The reviewer should be Lidiexy.   
After the branch is approved, Lidiexy will merge the branch into master and pull the changes on the noon server. 
NOTE:  This is not complete until the branch is merged by approver. 
 
Whitelist Company's IP for prdapi01 Server 
ZenDesk Ticket should include the public IP address that should be whitelisted for the company.  The public IP address may be different that the Sonnet user's public IP address. 
Open up Cato https://palinode.auth.catonetworks.com ->Network -> IP Allocation -> Remote Port Forwarding
Add the companies IP address to sonnetapi.palinode.io port 443
 
Note the ZenDesk ticket with the CATO whitelisting when complete. 

Test Connection 
Provide company API Token and API URL via ShareFile link on the ZenDesk ticket. 
Create a text document with the format below, update the <API Token> with the company's API Token and save in the Company's folder: 
 
  
To create and share a ShareFile link, go to https://palinode.sharefile.com/dashboard and select Share Files.  Attach the text document then Get Link.  Share the link with the company contact on the ticket. 
The client should see the response   
 
Setup for API company is complete.  Update ZenDesk ticket. 
Troubleshooting 
Client using URL, but the request is timing out. 
Public IP address used does not match whitelisted IP.  Check the api_log in the database 
Select * from api_log where company_id=companyid order by created_on desc 
Check the IP Address of the request and verify matches whitelisted IP.   
 

FTP Data Exchange 
Create the company's directory in Prdweb01 if the client is using Batch files. *CollectOne platform clients are API but will use this for image transfers. 
Create Directory on Prdweb01 Server 
Log into Prdweb01 
Go to the directory /sonnet/ftpdir:  $ cd /sonnet/ftpdir 
Run the script to make the company directories.  This script uses sudo command to change permissions.   
$ ./make_dirs.sh companyabbreviation 
Enter your server password 
Verify the directory was created correctly and the permissions and owner match other company folders. 


Update Move Images Azure Script 


This script is run every hour to transfer files from prdrpa01, prdrap02 to prdweb01 with logging. 
Update local repository.  If using Visual Studio Code (VS) open the folder with move images repository.   
Make sure you're on the master branch by using the git command "git status" in the Terminal.  If not on branch master use git command "git checkout master" which will update the branch to master. 
The command "git pull" will refresh your local repository.  
Create a branch named with the following naming convention:  companyIDzdtID 1000zdt1958  
Open the move_images.sh and add the following to the last line of the file with the company's abbreviation companyabbreviation is listed. 

/usr/bin/rsync -avz --remove-source-files --log-file=/sonnet/images/logs/companyabbreviation.`date +"%Y%m%d"`.log /sonnet/images/ companyabbreviation /* /sonnet/ftpdir/companyabbreviation/images
 
Save changes. 
Open the. gitignore and add the company abbreviation to the end of the list /companyabbreviation.   
Save changes 
Stage changes for commit then commit the saved changes.  The commit comments should provide a summary of the change.  Example:  Added companyabbreviation to API move images and gitignore. 
Git push or Push to push branch to Azure 
Go to the Move Images branches in Azure, locate your branch and create a pull request.  The reviewer should be Lidiexy.   
After the branch is approved, Lidiexy will merge the branch into master and pull the changes on the noon server. 
NOTE:  This is not complete until the branch is merged by approver. 
 


FTP 
If Sonnet is hosting the FTP (Client Gets and Puts files on Sonnet's FTP) proceed to Sonnet Hosted FTP 
If Company is hosting the FTP (Sonnet Puts and Gets files on Company's FTP) proceed to External FTP 




Sonnet Hosted FTP 
     Whitelist Company's IP for Incoming Access via CATO to remote port forwarding
ZenDesk Ticket should include the public IP address that should be whitelisted for the company.  The public IP address may be different that the Sonnet user's public IP address 
Add to the SFTP Gateway groups (22, 38122, 30000-31000) in Cato 
 
 
 
 
 
     Create FTP User for Company 
Log into crushftp go to user menu
Add user as company abbreviation
Create new remote item with name of companyabbreviation
Pick SMB3 use the string with the correct company abbreviation palinodeprodsftpstore.file.core.windows.net/prdsftpfs/companyabbreviation

Go to Bitwarden to get the credentials for the ftp storage account palinodeprodsftpstore 
Update the User name and Password – note this update the URL – save then test 
Modify the permission to match permissions 


Provide Client FTP Login Information
Provide company FTP login information via ShareFile link on the ZenDesk ticket. 
Create a text document with the format below, update the username with the company's abbreviation and the FTP user's password and save in the Company's folder named ftp_users: 
 
 
 
 
 
 
 
 
 
 
To create and share a ShareFile link, go to https://palinode.sharefile.com/dashboard and select Share Files.  Attach the text document then Get Link.  Share the link with the company contact on the ticket. 
Company confirms they are able to access the FTP. 
Backend setup is complete.  Solve ZenDesk ticket 

External FTPS 
     Whitelist Company's IP for Outgoing Traffic from prdweb01 Server 
Hosting company should provide the DNS or Host name, Username and Password to access their FTP.  Attempt to locate the IP address for the DNS or Host. 
Test the FTP connection from Dawn and accept the certificate:  
$sudo su sonnet
$sftp username@domainorip portnumberifprovided 
Enter FTP password.  May need to accept a certificate. 
If bad login, reach out to client for assistance.  Cannot proceed until credentials are validated. 
Save FTP login information in a text file named ftp_user and save to company's folder 
Create a ticket with Zendesk using standard format below with the highlighted fields updated.  Request may take up to 24 hours to process.  Assign to Emery Geyer  or John Hawkins
Target IP or DNS preferred!, Port CompanyAbbreviation is all that is required.
 
Note the ZenDesk ticket with the ZenDesk ticket number when complete. 
 
     FTP Configuration Setup for Externally Hosted FTPS 
Sonnet Admin:  Go to Company and add push_pull = T to Company Additional Settings 
Sonnet Admin:  Got to Company and add file schedule to Company Scheduled Actions 
Copy putimages.ftp, putstep1.ftp, putstep3.ftp and get.ftp in /sonnet/ftpdir/__blank (__ is 2 underscores).  This will move images to and from their root directory as in will not go into folders or move between folders in their FTP. 
$cd /sonnet/ftpdir/__blank 
$ cp ./*ftp /sonnet/ftpdir/companyabbreviation/ 
Go to the company's directory and update the copied blank scripts  
$cd /sonnet/ftpdir/companyabbreviation 
$ll (verify the copied FTP files are present) 
Edit the FTP files by replacing the blank with the company abbreviation 
Select the file to edit $vi get.ftp 
I to Change mode from View to Insert  
To exit vi/vim ESC  
To exit without saving enter :q! 
To exit and save enter :wq 
Repeat i-iii for all ftp files 
Add the Commands and update the Kernel for Automation 
Update local repository sonnet-datafiles 
Create a branch named with the following naming convention:  companyIDzdtID 1000zdt1958 
Copy BlankImages.php, BlankStep1.php, BlankStep2.php and BlankStep3.php from app>Console>Blank to Commands.   
Rename the copied files with the companyabbreviationStep1.php, etc.  This is case sensitive. 
Modify each file  
Step 1  
class blankStep1 extends Command – replace with name of the file companyabbreviationStep1 
protected $signature = 'blank:step1'; - replace with company abbreviation 
protected $description = 'blank: Send Step 1 file – replace with company abbreviation 
$readpath = '/sonnet/ftpdir/blank/ - replace with company abbreviation 
exec('sshpass -p blank sftp user@blank < /sonnet/ftpdir/blank/putstep1.ftp', $out); 
'sshpass' -p ftppassword sftp username@dnsorip (if applicable port number) 
/sonnet/ftpdir/blank/putstep1.ftp' replace with company abbreviation 
Step 2 
class blankStep2 extends Command – replace with name of the file companyabbreviationStep2 
protected $signature = 'blank:step2' – replace with company abbreviation 
protected $description = 'blank: Get Step 2 file' – replace with company abbreviation 
$disputes = DB::table('dispute')->select('id')->where('company_id', 'blank')->w – replace with company ID 
$fh = fopen('/sonnet/ftpdir/blank/get.ftp', 'wb'); file' – replace with company abbreviation 
fwrite($fh, "lcd /sonnet/ftpdir/blank\nget – replace with company abbreviation 
exec('sshpass -p blank sftp user@blank < /sonnet/ftpdir/blank/get.ftp'); see i5 
Step 3 
class blankStep3 extends Command – replace with name of the file companyabbreviationStep3 
protected $signature = 'blank:step3' – replace with company abbreviation 
protected $description = 'blank: Get Step 3 file' – replace with company abbreviation 
$readpath = '/sonnet/ftpdir/blank/ - replace with company abbreviation 
exec('sshpass -p blank sftp user@blank < /sonnet/ftpdir/blank/putstep3.ftp', $out); see i5 
Images 
class blankImages extends Command – replace with name of file companyabbreviationImages 
protected $signature = 'blank:images'; - replace with company abbreviation 
protected $description = 'blank: Send Image Files'; - replace with company abbreviation 
$readpath = '/sonnet/ftpdir/blank/images/'- replace with company abbreviation 
$r = exec('sshpass -p blank sftp blank < /sonnet/ftpdir/blank/putimages.ftp'); see i5 
$log = fopen('/sonnet/logs/blank_images.'- replace with company abbreviation 
Add Command to Kernel 
Go to app\Console\Kernel.php 
Add 4 commands to list.   
Save Changes, Stage, Commit with comments and Push branch 
Create Pull request in sonnet-datafiles - Repos (azure.com) with Lidiexy as the approver. 
--------------------------------------------------------------------------------
Title: Case  Processing_STEP 2 FILE.txt
                              Case : PROCESSING STEP 2 FILE

Step 1: Login into prodweb01 server:
                    az ssh vm --vm-name prdweb01 --resource-group rg-PaliPRD-DMZ --prefer-private-ip --subscription Sonnet_Production_Environment
Step 2: Change the directory into FTPDIR à cd /sonnet/ftpdir
Step 3: Check the company names with à ll and then change the directory to processed.

Step 4: Then change the directory into company nameà cd comp_abbrv
Step 5: Check whether it contains step 2 attachment or not and then move it.
** sudo su sonnet
**mv attachment_01 ../

Step 6: After the step 2 is moved successfully then check into datafiles and read step 2:


Step 7: After the read step done and step 2 has been processed then inform the same to user and close the ticket.
--------------------------------------------------------------------------------
Title: Cato Firewall Groups for whitelisting.txt
Cato Firewall Groups for whitelisting
Security tab -> Remote Port Forwarding
API Group:
sonnetapi.palinode.io

CQA API:
cqa-sonnetapi.palinode.io

SFTP Groups:
SFTP Gateway (22)
SFTP Gateway (38122)
SFTP Gateway (30000-31000)
--------------------------------------------------------------------------------
Title: Checking ACDV's Manually.txt
Usecase - Are you able to tell me how many ACDV’s we are currently getting in WF for each of these codes?
 
Manual review:
002 - Belongs to another individual with same/similar name
101 - Consumer not liable for account
103 - Consumer claims true identity fraud/account fraudulently opened
104 - Consumer claims account take-over, fraudulent charges made on account
118 - disputes current balance or amount past due
119 - Disputes original charge off amount
704 - item blocked per valid copy of police report
 
Step 1- If the organization has multiple companies you have check for all.
Step 2 – go to pg-admin and execute the below query.

Query - select * from dispute where company_id in(6600, 6601, 6602) and sonnet_received_timestamp > '2025-05-01' and (dispute_code_1 = '704' or dispute_code_2 = '704')

Step 3 – Update in the ticket and mark it as pending .

--------------------------------------------------------------------------------
Title: Creation of SFTP.txt
USE CASE -  SFTP SETUP

STEP 1- Open shared folder and search for Image server copy the command login to the command prompt (Copy the below command and paste in the command prompt)
Command 1  - az ssh vm --vm-name prdrpa01 --resource-group rg-PaliPRD-IMZ --prefer-private-ip --subscription Sonnet_Production_Environment 
Command 2 – sudo su sonnet
Command 3 – cd /sonnet/images
Command 4 - ./make_dirs.sh ______ company abbreviation in the blank space.

ààà Exit from rpa01 server

Step 2 – Repeat the same steps for rpa02 server
Command 1- az ssh vm --vm-name prdrpa02 --resource-group rg-PaliPRD-IMZ --prefer-private-ip --subscription Sonnet_Production_Environment 
Command 2 – sudo su sonnet
Command 3 – cd /sonnet/images
Command 4 - ./make_dirs.sh______ company abbreviation in the blank space.
Command 5 - cd /sonnet_attachments/www  à this is the step to verifying the permissions.

Command 6 – ll or ls  à it is used to list out the folders present in the directory and check for the company which you have created is present or not.

Check for the client if the client is API client then proceed with API data exchange if not go for FTP data exchange.

The below steps is for FTP data exchange.

Step 3 – Login to the SFTP server command(copy the below command and paste it in the command prompt)
Commnad 1 - az ssh vm --vm-name prdweb01 --resource-group rg-PaliPRD-DMZ --prefer-private-ip --subscription Sonnet_Production_Environment 
Command 2 – sudo su sonnet
Command 3 – cd /sonnet/ftpdir
Command 4 - ./make_dirs.sh______ company abbreviation in the blank space.
Command 5 - – ll or ls  à it is used to list out the folders present in the directory and check for the company which you have created is present or not.
Step 4 – Open Visual studio  and go to file at the top left corner click on select folder and select move images.

Step 5 – Create New Branch into Visual studio

Step  6 – Go to move_images_azure.sh and add the company name into it.


Step 7- Stage the changes , and give brief description into it and then commit.

Step 8 – Push the changes .


Step 9 – Go to Sonnet repo and pull the request that we made in visual studio to take approval from the reviewer.


Create FTP User for Company  
Log into crushftp go to user menu 
Add user as company abbreviation 
Create new remote item with name of companyabbreviation 
Pick SMB3 use the string with the correct company abbreviation palinodeprodsftpstore.file.core.windows.net/prdsftpfs/companyabbreviation 
 
Go to Bitwarden to get the credentials for the ftp storage account palinodeprodsftpstore  
Update the User name and Password – note this update the URL – save then test  
Modify the permission to match permissions  


Provide Client FTP Login Information 
Provide company FTP login information via ShareFile link on the ZenDesk ticket.  
Create a text document with the format below, update the username with the company's abbreviation and the FTP user's password and save in the Company's folder named ftp_users:  
  
  
  
  
  
  
  
  
  
  
To create and share a ShareFile link, go to https://palinode.sharefile.com/dashboard and select Share Files.  Attach the text document then Get Link.  Share the link with the company contact on the ticket.  
Company confirms they are able to access the FTP.  
Backend setup is complete.  Solve ZenDesk ticket  




--------------------------------------------------------------------------------
Title: data_science_fundamentals.md
# Data Science Fundamentals

## Introduction
Data science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.

## Key Components
1. **Statistics**: Foundation for data analysis
2. **Programming**: Python, R, SQL
3. **Machine Learning**: Predictive modeling
4. **Data Visualization**: Communicating insights
5. **Domain Expertise**: Understanding the business context

## Popular Tools
- Pandas for data manipulation
- NumPy for numerical computing
- Matplotlib/Seaborn for visualization
- Scikit-learn for machine learning
- Jupyter notebooks for interactive development

## Career Paths
- Data Analyst
- Data Scientist
- Machine Learning Engineer
- Data Engineer
- Business Intelligence Analyst

This document provides an overview of data science concepts.

--------------------------------------------------------------------------------
Title: Deleting the disputes in error queue.txt
ISSUE: DELETING THE DISPUTES IN ERROR QUEUE

***DELETING THE DISPUTES THAT ARE IN ERROR QUEUE 
 
         select id from dispute where company_id = 24400 and sonnet_status = 'Error' 
****  REQUESTING TO DELETE THE DISPUTES FOR THE CUSTOM DATE IN THE ACTIVE QUEUE
Query:
     update dispute set sonnet_status = 'Worked' where company_id = 24400 and response_due_date < '2025-03-22' and sonnet_status = 'Active' 
** date format – YYYY-MM-DD 


--------------------------------------------------------------------------------
Title: Dev create disputes.txt
Log on to server sonnetdataapidev.palinode.io
	You must have the ec2_access.pem file for access
	Open Bash window where you have the .pem file stored
	Run command in Bash, use the folder path to where you have the .pem:
$ ssh -i c:/Users/JamesMaki/Desktop/Dev/ec2_access.pem ubuntu@ec2-3-14-121-153.us-east-2.compute.amazonaws.com

Navigate to the images directory:
	$cd /sonnet/images
Create directory for the new company and make sure permissions match the others
	$sudo su sonnet
	$mkdir companyabbreviation
	Copy small, medium, large and larger.tif files to the new directory
	$cp *.tif ./companyfolder
Navigate to /sonnet/db-scripts
	$cd /sonnet/db-scripts
If you see these warnings when running the script:
PHP Warning:  Attempt to read property "social_security_number" on null in /sonnet/db-scripts/make_api_newautonation.php on line 446
PHP Warning:  Attempt to read property "date_of_birth" on null in /sonnet/db-scripts/make_api_newautonation.php on line 447

Correction is to add “?? null” to those lines as shown:

--------------------------------------------------------------------------------
Title: Dev_API_Whitelist.txt
Dev API Whitelist
Objective: Whitelist new client’s IP address(es) for access to the Dev API.
Access Requirements: Amazon Web Services login
Log in to the AWS website.
Click the Services drop down menu at the top of the page then select EC2.
On the left side of the page scroll through the menu to Network & Security and select Security Groups.
Select Sonnet Web.
In the bottom portion of the page go to Inbound rules and then click Edit Inbound Rules.
Scroll down to the bottom and click Add rule.
Select HTTPS in the first drop down, enter the IP address or range, and a description.
When finished click Save rules.
--------------------------------------------------------------------------------
Title: Didnt receive any disputes.txt
USE CASE 3     -         Didn’t Receive Any Disputes.

Go to Sonnet and select the company.
`downloaded in the dashboard then we have to do some additional download.
Go to Sonnet admin.
Click on the schedule Downloads and select the company and change the amount to 0.	
Check box for Sweep ACDV’s and click on add schedule download .
Wait for the status to get complete.
Once the status is completed click on the company name and click on the visit in sonnet.
Create a Step 1 file, select menu at the right top corner and click on the data files.
 Click on the make step # 1 file.
Go to azure my roles and responsibilities and activate the virtual machine and run the SSH command in the command prompt.
SSH command - az ssh vm --vm-name prdweb01 --resource-group rg-PaliPRD-DMZ --prefer-private-ip --subscription Sonnet_Production_Environment.
Give command as    cd /sonnet/ftpdir/acuonline/     press enter.
 ls    ----  list all files.
 sudo rm/2023*   -- delete the files of the year 2023.
Response to the ticket in the Zendesk.





--------------------------------------------------------------------------------
Title: Dispute deletion from step 1 queue.txt
Usecase – Delete the dispute from step 1 file and update the status as worked.

Step 1 – Run the below query in the pg-admin
update dispute set sonnet_status = 'Worked' where id = 63533380 

Step 2 – Run the below query
delete from facs_file_queue where file_step = 1 and dispute_id = 63533380

Step 3 – Give response to ticket and mark as solve or pending


--------------------------------------------------------------------------------
Title: Dispute page error.txt
USECASE – When You click on the dispute id the page seems to be error.


Step 1 – Go- to Pg-admin and execute the below query.
Query - insert into facs_data_snapshot (dispute_id) values (18793248)

Step 2 – Run the rules engine command in the command prompt until you find the company id.
Step 3- Once the company is found refresh the page and check whether the dispute page is available or not.

Step 4 – respond to the customer in the Zendesk.
--------------------------------------------------------------------------------
Title: Disputes came back with the same error...txt
CASE: Disputes came back with the same error..

Issue-->
I JUST processed to disputes and they came back with the same error (ACDV CONTROL NUMBER ERROR) Why is that? we don&#039;t touch those numbers. Due the time sensitive nature of these dispute can you please assist as quickly as possible? 

*****To resolve I ran this query to find the ids from the eoscar_response table:
select * from eoscar_response where dispute_id in (62373950,62373966)
 
there were 2 entries for each dispute so one had to be removed from each and then resubmit the response.
example: delete from eoscar_response where id = 159007747 (this is the id from eoscar_response and not the dispute_id so be careful when running this type of query)
 
this is one of the rare times we delete from eoscar_response table.
--------------------------------------------------------------------------------
Title: Disputes hung up in step 3 file queue.txt
                                 DISPUTES HUNG UP IN STEP 3 FILE QUEUE 
Requested: We have some disputes that look to be hung up in our Step 3. Would you be able to provide some insight as to what these disputes are?
Resolving Steps :
STEP 1: Go to PGAdmin and run the below quey
Select * from facs_file_queue where company_id= ______ and file_step=3
STEP 2: make it in ascending order 
Select * from facs_file_queue where company_id= ______ and file_step=3 order by created_on
Step 3: Take any one of the dispute Id from the table and search with that ID in Dispute search(sonnet admin) 
Step 4 : If you see any disputes with that sonnet Id then run the below query for specific date we needed to delete :
Select * from facs_file_queue where company_id= ______ and file_step=3 and (created_on >’dd-mm-yyyy’ and created on <’dd-mm-yyyy-)
Select * from facs_file_queue where company_id= ______ and file_step=3 and dispute_source=’EO’ and (created_on >’dd-mm-yyyy’ and created on <’dd-mm-yyyy-)






--------------------------------------------------------------------------------
Title: Disputes stucked NEW status.txt
                                         CASE:DISPUTES STUCKED IN NEW STATUS

Step 1: Initially check with the dashboard whether it has disputes in new status those are waiting for in house data--


Step 2: Cross check with look ahead


Step 3: Go into sonnet admin> Rules engine> disputes>rules engine queue
Search with company name and see if the disputes has been stucked (if the company has status with T) and then go to reset processed flag and give the company name and submit.
After submitting the disputes rules engine runs and unlock those stucked disputes.
Verify it on the dashboard.


Step 4:
Inform the user as disputes are available now and then close the ticket. 


--------------------------------------------------------------------------------
Title: Dispute_Deletion.txt
USE CASE 10 -   DIRECT DISPUTE DELETION.


Step 1-    Go to sonnet and select the company.
Step 2 -  Then click on direct and click on the investigation select active and search the id is in active or not.

**If the ticket is not active and we have duplicate:
delete from response_queue where id = 50127033     ß  run this in query in pg admin
**If the ticket is active 

Run the below query in pg-admin
update direct_dispute set sonnet_status = 'Worked' where id
 Sonnet ID 
Step 3- Once the query is returned successfully check if the dispute is deleted or not.

Step 4- If the dispute is deleted then go to Zendesk and give a response to the ticket and mark it as solved.
--------------------------------------------------------------------------------
Title: Email authentication.txt
USE CASE  - Not getting authentication code sent to email.
Login into sonnet and select the company
Select the menu at the left top corner and go down to the admin page
Select view users tab and select the user.
Open the Postmarkapp.com    (Log In to Postmark)   in the new tab and login by the given credentials which is available in the shared folder.
(For the credentials open the shared folder select user admin folder and follow the steps mentioned).
Select sonnet mail and select Default Transactional Stream.
Select activity and search for e-mail address from the sonnet copay and paste it in the search bar.
Copy the authentication code from the sonnet.
Give a response – Please use a code 170644 to login. Please find below the soft bounded message due to which emails are not getting delivered. Copy the soft bounded message and paste it in response section.
Submit ticket as solved.
--------------------------------------------------------------------------------
Title: Fixing E-Oscar Credentials Issue.txt
Fixing E-Oscar Password Issue
Overview
This article outlines the process and command usage for executing migration operations within the Sonnet Probe environment. These operations are typically performed using Node.js scripts to interact with the eoscar:api:migrate endpoint.
Environment Details
User: sonnet
Host: prdrpa02
Working Directory: /sonnet/scrape/sonnet-probe
Command History Analysis
The following commands were executed to perform migration tasks:
Command Breakdown
node app.js: Executes the Node.js application.
-o eoscar:api:migrate: Specifies the operation to be performed, targeting the eoscar API's migrate function.
-u: (Optional) Likely indicates an update or user-specific flag.
-c  : Specifies the configuration or command ID used during migration.
Observed Command IDs
26800
25000
17900
These IDs may correspond to specific migration batches, configurations, or operational parameters.
Best Practices
Always verify the command ID (-c) before execution to ensure it aligns with the intended migration scope.
Use history | grep migrate to audit previous migration commands for traceability.
Maintain logs in /sonnet/scrape/logs/YYYY/Mon/bonneville for post-operation review.
Troubleshooting Tips
If a migration fails, check the logs in the corresponding date directory.
Ensure that the Node.js environment is properly configured and dependencies are up to date.
Validate the API endpoint and parameters before execution.
Conclusion
Migration operations in the Sonnet Probe system are executed via structured Node.js commands. Proper usage and auditing of these commands ensure smooth and traceable data migration processes.

--------------------------------------------------------------------------------
Title: jXchange - CrBurInfoInq Fields.txt
All fields available in CrBurInfoInq service 





--------------------------------------------------------------------------------
Title: KPI Evaluation of KT.txt
KPI to evaluate the success of the knowledge transfer

To evaluate the effectiveness of the KT sessions, we have broadly divided into 3 portions along with weightage. The measurement to evaluate will be basis of ratings within the range of 1 to 10 points, reviewed by Chandan, Lidi and Sreeni
Category	: Onboarding Sessions + Hands-on
Weightage	: 25%. 
Duration	: 3 weeks
Create test for every session. Tests to include known issues or bugs that can drive the analysis and resolution by the team.  
A questionnaire will be generated based on current documentation and training videos. 
We will evaluate or grade the resulting artifacts or train of thoughts. 
For the DevOps team, we will assign specific tasks for environment creation or replication. 
For the Dev team, task will include the setting up of the local environment for development.  

Category	: Simulation 
Weightage	: 25%. 
Duration	: 4 weeks 
In addition to the test cases, we will use previous customer requests, bugs and tickets in general to generate the simulation of an issue.  
We will include complexity to cover cases for Developer, DevOps or Support can do. 
Everything will start from Support and based on knowledge acquired they can pass to the Dev team. 
Outage simulation for different components in the Ecosystem. 

Category	: Shadowing & Reverse-Shadowing 
Weightage	: 25%. 
Duration	: 2 weeks of Shadowing and 3 weeks of Reverse-Shadowing
Support Shadowing 
While shadowing the current team, the new team members are expected to document the SOP. 
Current team will be validating and Correcting the SOP. 
Development Showing 
PR Reviews, comments and recommendations. 
Describe how the issues will be solved with the tools and knowledge they have related to features and bugs. 
Support Reverse-Shadow 
Response time and Quality of the response to be evaluated by current team members. 
Customer satisfaction. Evaluate the bad ratings by doing a deep analysis of the situation. 
Developer Reverse-Shadow 
PR Reviews 
QA/Test performance. Evaluate Unit testing generation. Improve of Coverage. 
 
Standard Operating Procedures (SOP) write it down. (KPI for current team) 
Guide the creation of the SOP. (each team member) 
Completion of items in the Sprint 88 & 89 (each team member) – Need Amanda to Sprint Planning and add anything that will be include for current. 
  
Notes:  
Sonnet DevOps will drive until stabilization.
No more items in 90+ Sprints for Current teams (Task for current team only shadowing) 
 
 

--------------------------------------------------------------------------------
Title: Large volume in step 3.txt
                                     Large volume in step 3
Requested: we have a very large volume in step 3 appearing on the dashboard. If any of that volume contains block notifications would you please remove them so I know what our true number is
Steps:
Go to Pg admin and run the below query to check the block notifications and to remove the large fileso to Pg admin  —
      select * from facs_file_queue where company_id = 18400 and file_step = 3
**Here it will show the table with BL in dispute source.
 
delete from facs_file_queue where company_id = 18400 and file_step = 3 and dispute_source = 'BL'
** It will remove the BL in dispute source

Again run with select query to cross check whether BL has been removed or not:
select * from facs_file_queue where company_id = 18400 and file_step = 3
**If the dispute source is AU then it has been removed 


Close the task



--------------------------------------------------------------------------------
Title: machine_learning_guide.md
# Sample Document 1

This is a sample document about machine learning.
It contains information about various ML algorithms and techniques.

## Topics Covered:
- Supervised Learning
- Unsupervised Learning
- Deep Learning
- Neural Networks

This document serves as an example for the RAG system.

--------------------------------------------------------------------------------
Title: MISSING DISPUTES.txt
                             GENERIC: MISSING DISPUTES

Resolving steps:
Step 1)From Sonnet Admin go to Scheduled Downloads
Step 2)run a new download for the client set the count to 0 
Step 3) check the box for Sweep ACDVs which means to download all disputes
Step 4) Inform the customer and solve the ticket.
--------------------------------------------------------------------------------
Title: MultiEndpointSupport.txt
Overview

As JHA’s integrated services platform has grown over recent years, coupled with the tendency to move services to the Cloud, the number of supporting environments for a given institution may utilize more than a single server farm.  These environments, or farms, are established to meet needs concerning capacity, provider services and location of data.  
To support this, consumers are required to support multiple endpoints for an institution. As a consumer, you must prepare for the possibility that not all operations will utilize the same endpoint.  With those endpoints, the message credentials and the jXchangeHdr values must also be configurable to correlate to multiple environments.
Normally, the boundary separating environments are the providers themselves.  Core based services, 4Sight and Synergy are just a few of the providers and may have separate endpoints for an institution.   Multiple endpoints/environments are not present for every situation but are increasing in frequency.   At a high level, the link to group multiple endpoints is the Institution itself, then the provider.  At the bottom level, each operation is associated with a given endpoint.
During a production environment implementation, the IDG Operations team will provide access information for each configured provider.  This information may contain a single or multiple endpoints.  
This document is provided to help you understand these requirements.   Below are diagrams to help visualize this concept.  



Single tenant applications supporting multiple endpoints

The following diagrams are provided merely as examples of how an application might be required to access multiple endpoints for a particular institution.  This does not imply that certain providers are grouped within an environment. 











Multi-Tenant applications supporting multiple endpoints



--------------------------------------------------------------------------------
Title: Palinode - PaaS Flexible Server Information.txt
Azure PostgreSQL Flexible Server
Backup Management
Azure Database for PostgreSQL Flexible Server automatically performs regular backups to ensure data protection and supports point-in-time restore (PITR) capabilities. Backups are stored in geo-redundant storage, providing resilience against regional failures. You can configure the backup retention period based on your requirements, with a default of 7 days, extendable up to 35 days. Additionally, the service supports on-demand backups, allowing you to create backups anytime. For more detailed information, refer to the official documentation on backup and restore.
Migration Strategies
Migrating to Azure Database for PostgreSQL Flexible Server can be achieved through various methods, depending on your source environment and downtime tolerance. For migrations from Azure Database for PostgreSQL Single Server, an automigration process is available. This service-initiated migration occurs during a planned downtime window, with advance notifications and scheduling options provided. For comprehensive guidance on migration strategies, consult the following resource: Migration Guide.
Monitoring and Alerts
Effective monitoring is crucial for maintaining the health and performance of your database instances. Azure Database for PostgreSQL Flexible Server integrates with Azure Monitor, allowing you to track key metrics such as CPU usage, memory consumption, and storage I/O. You can set up alerts to notify you of critical conditions, enabling proactive management. For detailed instructions on configuring monitoring and alerts, see: Monitoring and Alerting.
Performance Optimization
Optimizing performance involves configuring server parameters, scaling resources, and utilizing performance-enhancing features. Azure Database for PostgreSQL Flexible Server offers various compute and storage options to match your workload requirements. Additionally, features like connection pooling and query optimization can significantly improve performance. For best practices and performance tuning guidelines, refer to: Performance Optimization.
Tools and Extensions
Enhancing the functionality of your PostgreSQL instances is possible through various tools and extensions. Azure Data Studio, for example, provides a modern editor experience with IntelliSense, code snippets, and source control integration. Additionally, PostgreSQL supports a wide range of extensions to extend its capabilities. For more information on available tools and extensions, visit: Tools and Extensions.
Patching, Upgrades, and Security Updates
Azure Database for PostgreSQL Flexible Server manages patching and updates to ensure your instances are secure and up-to-date. The service applies security patches automatically during scheduled maintenance windows, minimizing disruption. You can also perform major version upgrades when necessary. For details on patching and upgrade procedures, see: Patching and Upgrades.

--------------------------------------------------------------------------------
Title: Palinode - SSO Setup 2.txt
Table of Content


Introduction

This document will guide you through the steps on how to create a custom Single Sign On (SSO) application in Azure Portal using Entra ID and SAML configuration. This will make it possible for Sonnet to provide SSO authentication for your users in your organization.
The SSO ID is needed to begin the setup and is provided by Sonnet. The SSO ID is the string used to customize specific authentication URLs, only allowed to your organization. The sso_id placeholder will appear many times in this guide, make sure to replace it with your real SSO ID in your setup.
After the SSO Application is created and configured in your organization environment, provide the following parameters to Sonnet:
SSO application Login URL
SSO application Logout URL
Microsoft Entra Identifier
Base64 encoded certificate (the .cer file provided by Entra ID)
Depending on your organization policies, you can instead provide the Federation Metadata XML. file. That file can be downloaded at the end of the setup and contains all the information required by Sonnet.

Creating a Custom Azure Application for Sonnet

You will first create a custom Azure application. Sonnet will use this application within your organization to request login and logout actions through SAML. Ensure this Azure application is created in the same context your organization’s user accounts reside, since this application is the only way Sonnet will be able to consume the correct user sessions.

Navigate to Azure Portal(https://portal.azure.com) and access Microsoft Entra ID (previously Azure AD)

If quick access is not available on the landing page of your Azure portal, you can use the search bar to search for “Entra ID” at the top of your portal.

Once inside Entra ID, select “Enterprise Applications”.


Use the New Application link in the top menu section. 
 
Select “Create your own application” from the top menu section. It will open a right-side drawer with a small form.

Enter some name for the custom application so you can easily identify it among others (we recommend Sonnet-SSO) and make sure to select the bottom option Non-gallery. Click on the Create button at the bottom of the form.  It will take a few seconds and then open the new application overview page.


Configure SAML SSO in the new application.

For the SAML configuration, use the SSO ID for your organization provided by Sonnet. Use the SSO ID in the setup to replace the sso_id placeholder. This placeholder will appear a couple of times in the following steps, so do not forget to use the provided SSO ID instead.

In the Sonnet Application page, select the option 2. Set up single sign on. 

If option 2. Set up single sign on is not available, you can use the option Single sign-on in the left-side menu bar.

Tip: After creation, the new application will also be searchable. Type in the name used in Step 5 and select the link.

Select the box SAML from the options available for single sign-on. It will open a new page with many options to configure SAML. 


The many options available are grouped into 4 categories. You only need to set values for the first two.
You should be able to edit each group using the pen icon at the top-right corner of each box. Every edition will open a right-side menu form, like the one used while creating the custom app.

Basic SAML Configuration. The SSO ID will be used here. Sonnet does not support SAML sign-on and that is why the Sign on URL is not required.




Attributes & Claims. Because Sonnet maintains the ownership of user roles and details, the email address is the only claim currently required. It is used to link the SAML authentication with a valid Sonnet session.
The main goal is to assign e-mail address as required.

Click on the required claim row. In the new form, select user.mail as the Source Attribute.

Use the link Save in the top menu options. You can add or remove any number of attributes. Sonnet only needs to get emailaddress. The bare minimum required by Sonnet is:




Configuration parameters required by Sonnet.

After completing the SAML setup for the custom Azure application, your environment is ready to accept SAML2 authentication requests. Now we will need to know the resulting details of your setup to make it possible to provide the SSO service on Sonnet.

To provide configuration details for Sonnet, we will need the information available in the third and fourth categories in the very same SAML Single sign-on setup page.

Download the Base64 certificate. This can be found in the first Download link at the third box.

Copy all three URLs available in the fourth category box

Create a zip file with all this info and send an encrypted email to support@palinode.io  containing the following:
Certificate (Base64)
URLs – Login URL, Microsoft Entra Identifier and Logout URL
Alternatively, you can get all that information by downloading the Federation Metadata XML. That’s the third link in the SAML Certificates box. You can zip it and send it to Sonnet.
--------------------------------------------------------------------------------
Title: Postmark.txt
Website
https://account.postmarkapp.com/login
UN: palinode 
PW: G.!'rh4|89fX 

Go to
Sonnet Mail -> Default Transactional Stream -> Activity
You should see this screen:


From here you can search by the user’s email address or the company domain.
--------------------------------------------------------------------------------
Title: Product Adoption IDG Consumer Integration Form.txt

The purpose of this form is to capture pertinent information that will be important for you product becoming a consumer of Integration Services.
Please provide deployment and integration Diagrams to Product Adoption
Overview

Contact Information (name/email/phone) 
Development Dates
Installation and Production Planning 
The sponsoring institution will need to have Jxchange contracts signed prior to moving forward with Beta testing


Production Environments
IDG Products
Providers
* Alert Center is a real-time Deposit Check service that provides participating Financial Services Organizations (FSOs) advance notification of potentially high-risk transactions.
Operations
Concerns/Additional Notes

--------------------------------------------------------------------------------
Title: Product Adoption Use Case Form .txt

© 1999-2014 Jack Henry & Associates, Inc.
All rights reserved. Information in this document is subject to change without notice.
Printed in the United States of America.  

No part of this document may be copied, reproduced, stored in a retrieval system, displayed, distributed or transmitted in any form or any means whatsoever (electronic, mechanical or otherwise), including by photocopying or recording for any purpose, without the prior written permission of Jack Henry & Associates, Inc.  Making unauthorized copies of this document for any purpose other than your own personal use is a violation of United States copyright laws.
Any unauthorized use of Jack Henry & Associates, Inc.’s trademarks and service marks is strictly prohibited. 

The following marks are registered and unregistered trademarks and service marks of Jack Henry & Associates, Inc.:
3rd Party Sweep™; 4|sight™; Account Analysis™; Account Cross Sell™; Account Cross Sell Jumpstart™; Account Number Change™; ACH/Check Conversion Services™; ACH Client™; ACH Manager™; ACH Origination/Processing™; Advanced Reporting for Credit Unions™; AlertCenter™; AlertManager™; AllAccess™; Alogent®; Alogent® Back Counter™; Alogent® Commercial Remote Deposit™; Alogent® Enterprise Duplicate Detection™; Alogent® Front Counter™; Alogent® Image ATM™; Alogent® Mobile Remote Deposit™; Alogent® Payment Web Services™; Alogent® Payments Gateway™; Alogent® Retail Remote Deposit™; Andiamo™; Annual Disclosure Statement Online™; ArgoKeys®; ArgoKeys® Branch Sales Automation™; ArgoKeys® DepositKeys™; ArgoKeys® LendingKeys™; ArgoKeys® RelationshipKeys™; ATM Manager Pro®; ATM Manager Pro® – Asset & Site Management™; ATM Manager Pro® – Cash Management™; ATM Manager Pro® – Event Management™; ATM Manager Pro® – Financial Management™; AudioTel™; Basel II Pro™; Biodentify™; BladeCenter™; BondMaster™; Branch Deposit Reporting Pro™; Brand Management Services™; BusinessManager®; Call Report Pro™; Cash Automation™; Cash Dispenser™; Cash Recycler™; Centurion Business Continuity Planning™; Centurion Business Recovery Consulting Group™; Centurion Co-Location™; Centurion Disaster Recovery®; Centurion Emergency Notification™; Centurion Enterprise-Level Recovery™; Centurion Episys Hosted Failover™; Centurion Hosted High Availability™; Centurion LiveVault™; Check 21 Cash Letter™; Check 21 Exception Processing™; CheckCollectPlus™; Check Collect Recovery Services™; CheckMaster™; CheckMaster Plus™; Check Writer for Core Director®; CIF 20/20®; Co-Mingle™; Cognos 10™; Collateral and Document Tracking™; Compliance Access™; Core Director®; Core Director® Teller™; Core Director® Teller Capture™; CreātaCard®; Cruise®; CruiseNet®; CTRMaster™; CUPRO® ALM™; CUPRO® ALM Express™; Customer Payment Portal™; Database Cleansing Package™; DataLink CU™; Demand Account Reclassification™; DIME™ (Document Image Management Engagement); DirectLine International™; DirectLine® OFX; DirectLine Wires™; Dynamic Content Modules™; ECS Capture Solutions™; ECS Digital Data Conversion™; ECS Paper-to-Digital Conversion™; ECS Web™; eCTR™; Electronic Statements™; Electronic Statements – Interactive™; Enhanced Account Analysis™; Enhanced Loan Application™ (ELA); Enhanced Loan Collections™; Enhanced Member Application™ (EMA); Enterprise Backup and Tape Encryption™; Enterprise Capture Solutions™; Enterprise Conversion Solutions™; Enterprise Payment Solutions™; Episys®; Episys® Anywhere™; Episys® Collateral and Document Tracking™; Episys® Collection Toolkit™; Episys® Dealer Reserve Accounting™; Episys® Escrow Module™; Episys® ID Scanner Interface™; Episys® Management Server™; Episys® Overdraw Tolerance™; Episys® Quest™; Episys® University™; Episys® Vaulting™; Episys® Virtualization™; EPS Remote Deposit Capture™; Extra Awards®; Failover™; Fed-File Pro™; FlexPass™; FormSmart™; FX Gateway™; Genesys Check Imaging Suite™; Gladiator®; Gladiator® Advanced Malware Protection™; Gladiator® Consulting Services™; Gladiator® CoreDEFENSE Managed Security Services™; Gladiator® eBanking Compliance Services™; Gladiator® eCommercial SAT™; Gladiator® Enterprise Network Design, Implementation & Support Services™; Gladiator® Enterprise Security Monitoring™; Gladiator® Enterprise Virtualization Services™; Gladiator® eSAT™; Gladiator® eShield™; Gladiator® IT Regulatory Compliance/Policy Products™; Gladiator® Managed IT Services™; Gladiator® Managed Unified Communications Services™; Gladiator® NetTeller® Enterprise Security Monitoring™; Gladiator® Network Services™; Gladiator® Phishing Defense and Response Service™; Gladiator® Social Media Compliance Services™; Gladiator Technology®; Gladiator® Unified Communications Services™; goDough®; GoldPass™; Hosted Pay Page™; iBizManager™; Image ATM™; Image ATM Capture and Reconciliation™; ImageCenter™; ImageCenter ATM Deposit Management™; ImageCenter Image Capture™; ImageCenter Interactive Teller Capture™; Intellix CIF 20/20® OutLink Renewal Engagement™; Intellix Consulting™; InTouch Voice Response®; Investor Servicing™; iPay Biz 2.0™; iPay Consumer Online Bill Pay™; iPay OneClick™; iPay Payment Data API™; iPay QuickPay™; iPay Solutions™; iRisk™; Isosceles™; iTalk™; Jack Henry & Associates, Inc.®; Jack Henry Banking®; JHA Consumer Pieces™; JHA Merchant ServicesSM; JHA OutLink Processing Services™; JHA Payment Processing Solutions®; jhaAddress Verify™; jhaCall Center™; jhaDirect®; jhaEnterprise Workflow™; jhaID Scan™; jhaKnow™; jhaKnow Express™; jhaPassPort Debit Optimizer™; jhaPassPort™; jhaPassPort.pro™; jhaPassPort Direct™; jhaPassPort Extra Awards™; jhaPassPort Fraud Center™; jhaPassPort Hot Card Center™; jhaPassPort Promotions and Consulting Services™; jhaPassPort Switch™; jhArchiveSM; jVault®; jXchange™; Know-It-All Credit Programs™; Know-It-All Education™; Know-It-All Learning Management Portal™; Know-It-All Now™; Landlord/Tenant Security Deposit Tracking™; LendingNetwork®; Loan Collateral Tracking™; Margin Maximiser Interactive™; Margin Maximizer Interactive™; Margin Maximiser MaxConnect™; Margin Maximizer MaxConnect™; Margin Maximiser Pronto™; Margin Maximizer Pronto™; Margin Maximiser Suite®; Margin Maximizer Suite®; MasterlinkSM; MaxConnect Interactive™; MedCashManager®; Member Business Services™; Member Privilege™; Merchant Deposit Capture™; Mobile Website™; Multifactor Authentication™; Mutual Fund Sweep™; Net.Check™; NetTeller®; NetTeller® Bill Pay™; NetTeller® Cash Management™; NetTeller® Member Connect™; NetTeller® Online Banking™; OnBoard Loans™; OnNet™; OnX™; OpCon™; Opening Act™; Opening Act Express™; Optimizer™; Participation Lending™; PassBook™; PointSM; PointMobilitySM; PowerOn®; PowerOn2™; PowerOn Marketplace®; PowerOn® Studio™; PPS ImageSelect™; Prepaid Cards™; Professional Consulting Services™; PROFITability®; Organizational PROFITability® Analysis System™; Product PROFITability® Analysis System™; PROFITability® Budget™; PROFITability® Reporting Service™; PROFITstar®; PROFITstar® ALM Budgeting™; PROFITstar® Budget™; PROFITstar® Classic™; PROFITstar® Reporting Service™; ProfitStars®; ProfitStars® Direct™; ProfitStars mRDC™; ProfitStars Synergy®; Real Time™; Real Time Gateway™; Refi Analyzer™; Regulatory Reporting Solutions™; Relationship 360™; Relationship Profitability Management™ (RPM); RemitCentral™; RemitPlus®; RemitPlus® Remittance/Lockbox™; RemitWeb™; Remote Deposit Anywhere™; Remote Deposit Capture™; Remote Deposit Complete™; Remote Deposit Express™; Remote Deposit Now™; Remote Deposit Scan™; RPM Reporting Service™; Shared Branch™; SigMaster™; Silhouette Document Imaging®; SilverLake System®; Smart EIP™; Smart GL™; SmartSight®; smsGuardian™; Store Forward™; StreamLine Platform Automation®; StreamLine Platform Automation® – Deposits™; StreamLine Platform Automation® – Loans™; Summit Support®; Sweep Account Processing™; SymAdvisor™; SymChoice Loan™; SymConnect™; SymForm™; SymForm PDF™; Symitar®; Symitar® ATM Services™; Symitar® Fraud Management™; Symitar® EASE™; SymX™; SymXchange™; Synapsys®; Synapsys® Lobby Tracking™; Synapsys® Member Relationship Management™; Synergy API Integration Toolkit™; Synergy AutoImport™; Synergy Automated Document Recognition™ (ADR); Synergy Batch Document Recognition™ (BDR); Synergy Check Archive™; Synergy DataMart™; Synergy Document Management™; Synergy Document Tracking™; Synergy eDistribution™; Synergy Enterprise Content Management™ (ECM); Synergy eSign™; Synergy eSignWeb™; Synergy Express™; Synergy ID Scan™; Synergy iSign™; Synergy Kofax Capture™; Synergy PowerSearch™; Synergy Reports™; Synergy Workflow Management™; TeleBank™; TeleWeb Bill Payment™; TeleWeb Cash Management™; TeleWeb Mobile™; TeleWeb Online Banking™; TellerMaster™; TheWayiPay®; TimeTrack Human Resources™; TimeTrack Payroll System™; TimeTrack Time and Attendance™; Transaction Logging and Vaulting Server™; Transaction Logging Server™; ValuePass™; Vehicle Pricing Interface™; Vertex Teller Automation System™; Vertex Teller Capture™; Virtual Transaction Logging Server™; WebEpisys™; Website Design & Hosting™; Website Security Services™; Wire Management™; Yellow Hammer™; Yellow Hammer ACH Origination™; Yellow Hammer BSA™; Yellow Hammer BSA Regulatory Consulting Service™; Yellow Hammer EFT Fraud Detective™; Yellow Hammer Fraud Detective™; Yellow Hammer SAR Center™; Yellow Hammer Wire Origination™; Xperience™

Slogans
Cutting-Edge IT Solutions for the Future of Credit UnionsSM; Know-It-All – Empowering Users Through KnowledgeSM; Leading through technology … guiding through supportSM; Powering Actionable InsightSM; Snap it Send it Spend it®; The Depth of Financial IntelligenceSM; We Are Looking Out For YouSM; Where Tradition Meets TechnologySM 

Various other trademarks and service marks used or referenced in this document are the property of their respective companies/owners.



Purpose:
The purpose of this document is to provide an extra layer of certainty as to the end goals of the project before entering into the development phase.  

This helps identify any GAP items that may exist and allows for them to be addressed pro-actively instead of being discovered once the actual development work is underway.

What is a Use Case?

In software and systems engineering, a use case is a list of steps, typically defining interactions between an “actor” and a system to achieve a goal.

For the purposes of consuming jXchange services, the actor is the Consumer and the system is the Provider.

A typical jXchange use case would include the following focal points:

Purpose/Summary – a high level description of the goals of the specific scenario
Operation(s) being used if known, if not N/A is fine and this can be worked through during the GAP analysis call with the Business Analyst.
Parameters/Values that will be supplied to the requested Operation
Parameters/Values expected or required from the response in order to fulfill the use case objective.
 Example:
Use Case #1: Ping the endpoint to make sure services are active

Purpose/Summary:

As a consumer I plan to send a ping request to the service gateway endpoint to ensure that the services are up and running.  I will send a message such as “Hello jXchange” in the request and I will expect to receive my message echoed back if everything is up and running.

Operation:

PING

Request Parameters/Values:

Ping Request Element: Hello jXchange

Response Parameters/Values:

Ping Response Element: Hello jXchange 
Please list out any known use cases below:

Use Case #1: Search by Account Number.
Purpose/Summary: Search the Account Number related to the downloaded ACDV.
Operation(s): 
Request Parameters: getAcct
Response Parameters: <What data will be utilized from the operation>

--------------------------------------------------------------------------------
Title: python_programming.txt
This is a sample text document about Python programming.

Python is a versatile programming language that is widely used for:
- Web development
- Data science
- Machine learning
- Automation
- Desktop applications

Key features of Python:
1. Easy to learn and read
2. Extensive libraries
3. Cross-platform compatibility
4. Strong community support

This document is part of the RAG system example.

--------------------------------------------------------------------------------
Title: Re-Run Step3 File for ACDVs answered on 22025.txt
                                          USE CASES: SONNET SUPPORT

ISSUE: Re-Run Step3 File for ACDVs answered on 2/20/25
Steps to be followed:
1)Open the command prompt and log in using the following command: --az ssh vm --vm-name prdweb01 --resource-group rg-PaliPRD-DMZ --prefer-private-ip --subscription Sonnet_Production_Environment
2)Navigate to the data files directory by running: --cd /sonnet/datafiles
3)Switch to the sonnet user by using the command: --sudo su sonnet
4) ***To find the Tracker ID: In Sonnet’s web browser, go to the "Data Files" section, select the specific date and company name, then click "Submit." Copy the Tracker ID from there.






5)Execute the following command to check the file with the given paths: --php artisan sonnet

6) Then enter the step number that need to be pushed: php artisan sonnet:makestep3 --company_id=8300 --file_tracker_id=623463
7)Once done, exit the data files path by typing: --exit.
6)To check the file in the pdqservices/ directory, use the command: --cd pdqservices/.
7)Go to Sonnet and verify the data files for the specific step that needs to be pushed, then proceed to push the step.
8)Then recheck whether the step is pushed or not in CMD –

8)Finally, notify the customer and close the task.





--------------------------------------------------------------------------------
Title: Removing LCS Disputes.txt


USE CASE – 7    REMOVING LCS DISPUTES FROM THE SONNET FOR THE REQUESTED SONNET ID.

STEP 1 – GO to sonnet and select the company and select the disputes.
STEP 2 – Click on the search option, copy the sonnet id from the Zendesk and paste in the sonnet id and click the Search Disputes.
STEP 3 -  Check for the Status if it is Active state then we need to change the status.
STEP 4 –  For changing the status of sonnet write the below query in the pgadmin
     QUERY -----   update dispute set sonnet_status = 'Worked' where id = enterID  
(the above query is for changing the status for one sonnet id)

QUERY ------ update dispute set sonnet_status = 'Worked' where id in (enter id)
(the above query is used to change the sonnet status for the multiple disputes)

STEP 5 – After the query is executed copy the sonnet id from the Zendesk and paste it in the sonnet id and check for the status. Status should change from Active status to Worked status.

Step 6 – Give response to the ticket and close.


--------------------------------------------------------------------------------
Title: Requesting for the report on custom date.txt
USE CASE: Requesting for the report on custom date.

1)Access Sonnet and Select the Company:

First, log into the Sonnet platform and select the relevant company from the available options.
Navigate to Reports:

2)On the left-hand side of the Sonnet interface, locate and click on the Reports section.
Choose the Report Category and Type:

3)From the list of available categories, select ACDV (Automated Credit Dispute Verification).
Next, find and click on the Dispute Submitted report type.
Set the Date Range:

4)Choose Custom Range as the date selection option.
Input the desired date range for the report and then proceed to run the report.
Handling Errors and Running the Report in PGAdmin:

5)If you encounter an error while generating the report in Sonnet, you will need to generate the report manually in PGAdmin.
6)Before proceeding with PGAdmin, make sure that the PostgreSQL service is activated in your Azure account.
7)Open PGAdmin and select the appropriate server from the available list to begin the connection process.
9)After running the command, copy the access token that is generated in the terminal
10)Go back to PGAdmin and paste the access token in the password field for authentication.
Select the Sonnet Database:

11)Once logged in, locate and select the Sonnet database under the Databases section in PGAdmin.
Open the Query Tool:

12)Click on the Query Tool to open the space where you can write and execute SQL queries.
Write and Execute the Query:

13)Write the necessary SQL query to retrieve the report data. Once the query is ready, click the Execute button to run it and fetch the report.
Download the Report:

14)After the query has been executed successfully, download the generated report to your local machine.
Respond to the Customer in Zendesk:

15)Finally, log in to Zendesk and locate the corresponding customer support ticket.
Attach the downloaded report to the ticket and provide a clear, concise response to the customer regarding the report or any further action required.
--------------------------------------------------------------------------------
Title: REQUESTING TO DELETE THE DISPUTES FOR THE CUSTOM DATE IN THE ACTIVE QUEUE.txt
USECASE -   REQUESTING TO DELETE THE DISPUTES FOR THE CUSTOM DATE IN THE ACTIVE QUEUE

EX - Can you please remove disputes through 3/21 from our Active queue

STEP 1- Go to sonnet and select the company.
STEP 2-  Open pg-admin and paste the below query 
Query - update dispute set sonnet_status = 'Worked' where company_id = 24400 and response_due_date < '2025-03-22' and sonnet_status = 'Active'
** date format – YYYY-MM-DD


STEP 3- Check the disputes whether it has deleted or not in the dispute page.
Step 4 – Give a response to the ticket and mark it as solved.
--------------------------------------------------------------------------------
Title: Response Queue.txt

USE CASE 8 - Response Queue is backed up and not sending out.

Step 1 – Go to the sonnet and select the company.
Step 2 – Click on the response queue.
It is usually just because of the login has gotten hunk basically. We are going to reset it
Step 3 – Select Menu from the top right corner and click on the sonnet admin.
Step 4 – Select Dashboard and use Ctrl + F   to find the company.
Step 5 –  Select next to the company name. If the submitting ACDV’s toggle is on turn it off and select save to sonnet.
Step 6 – Select Organization and select the company and click on the company and select visit in sonnet at the left top.
Step 7 – Click on the response queue and check for the response. 
Step 8 – Give response and close the ticket.

--------------------------------------------------------------------------------
Title: SOP_8-eOSCAR-connector-Questions-Workshop.txt
Of course. Here is a professional Standard Operating Procedure (SOP) based on the provided documentation.

***

### **Standard Operating Procedure: Sonnet System Troubleshooting and Issue Resolution**

**SOP ID:** SON-OPS-001
**Version:** 1.0
**Effective Date:** 2024-10-26
**Approved By:** [Approver Name/Title]

---

**1.0 Purpose**

This document provides standardized, step-by-step procedures for diagnosing and resolving common operational issues within the Sonnet platform. These procedures are designed for use by Technical Support, Operations, and Engineering personnel.

**2.0 Scope**

This SOP covers troubleshooting procedures for issues related to Automated Consumer Dispute Verification (ACDV) downloads, responses, receipts, and associated system components like the eOSCAR Connector, Notary, and system logs.

**3.0 System Fundamentals**

Before proceeding with troubleshooting, personnel must be familiar with the following core concepts.

**3.1 Log Path Structure**

The standard log path for tracing events associated with a specific company and date follows this structure:
`/sonnet/scrape/logs/[Year]/[Mon]/[company_alias]/[log_file_name]`

*   **Example:** `/sonnet/scrape/logs/2025/Feb/credencerm/xxxx13.log`

**3.2 Log Entry "Fingerprint"**

Many log entries use a "fingerprint" to uniquely identify a record and its context. This is the primary tool for locating specific transactions during troubleshooting.

*   **Format:** `CompanyAlias:Type:Action/Bureau:ControlNumber`
*   **Examples:**
    *   `credencerm:ACDV:Download:384878`
    *   `credencerm:ACDV:EFX:99995030531194023`

---

**4.0 Troubleshooting Procedures**

**4.1 Procedure: Investigating Reports of No ACDV Disputes to Process**

**Problem Statement:** One or more companies report they have no new ACDV disputes to work for the current day.

**Procedure:** Follow these steps in the specified order to triage the issue.

1.  **Step 1: Check the Sonnet Admin Dashboard**
    *   **Action:** Log in to the Sonnet Admin dashboard and review the company's status. Check for any system-wide alerts, processing backlogs, or specific errors related to the eOSCAR connection.
    *   **Reasoning:** This is the quickest method to identify high-level, obvious issues affecting one or more clients without digging into logs.

2.  **Step 2: Review eOSCAR Connector Logs**
    *   **Action:** Investigate the eOSCAR Connector logs for the relevant time frame. Look for connectivity errors, authentication failures, or messages indicating no new data was available from eOSCAR.
    *   **Reasoning:** The eOSCAR Connector is the entry point for all dispute data. Failures at this stage will prevent any disputes from entering the Sonnet system.

3.  **Step 3: Review Rules Engine Logs**
    *   **Action:** Analyze the Rules Engine logs. Search for the affected company alias to determine if disputes were received but subsequently filtered or routed incorrectly based on existing rules.
    *   **Reasoning:** The Rules Engine processes disputes after download. An issue here could mean data was successfully downloaded but not correctly assigned or made visible to the client.

4.  **Step 4: Review Sonnet Web App Logs**
    *   **Action:** Examine the main Sonnet web application logs for any application-level errors that may have occurred during the processing or display of the downloaded disputes.
    *   **Reasoning:** This is the final check for application-specific errors that may prevent otherwise healthy data from being presented to the user.

5.  **Step 5: Request Further Evidence from Customer**
    *   **Action:** If all internal checks show no errors, contact the customer. Request screenshots, specific timeframes, and any other evidence they have to confirm the issue is not on their end (e.g., browser cache, local network issues).
    *   **Reasoning:** This step is performed last to ensure all internal avenues have been exhausted before consuming customer time.

**4.2 Procedure: Investigating Missing ACDV Receipts**

**Problem Statement:** A company reports they are missing PDF receipts for their ACDV responses.

**Procedure:** Follow these steps to diagnose the cause of the missing receipts.

1.  **Step 1: Review Notary Logs**
    *   **Action:** The first and most critical action is to thoroughly review the Notary service logs. The Notary service is responsible for the creation of ACDV receipts. Search for the relevant `ControlNumber` or `CompanyAlias` to find specific processing errors.
    *   **Reasoning:** This is the most direct and singular point of failure for receipt generation. Issues found here are the most likely cause.

2.  **Step 2: Review Supporting Service Logs**
    *   **Action:** If the Notary logs show no record of the transaction, expand the investigation to the following services:
        *   **eOSCAR Connector Logs:** Confirm the response was successfully transmitted.
        *   **Sonnet Web App Logs:** Verify the application correctly initiated the receipt generation request.
        *   **Sonnet Probe Logs:** Check for related health or monitoring alerts.
    *   **Reasoning:** These services are upstream from the Notary service. A failure in one of them could prevent the receipt generation job from ever being triggered.

3.  **Step 3: Check the Sonnet Admin Dashboard**
    *   **Action:** Review the dashboard for any system-wide issues or alerts related to the Notary service or its dependencies.

**4.3 Procedure: Analyzing ACDV Response Discrepancies**

**Problem Statement:** A company finds no evidence of a response on their end, but the Sonnet UI shows the ACDV as "Responded" on a specific date.

**Procedure:** Verify the response event by analyzing the following components and logs.

1.  **Step 1: Verify System of Record**
    *   **Action:** Check the status in the Sonnet Admin UI and query the Sonnet Database (DB) to confirm the `ControlNumber` is marked as responded with the correct timestamp.
    *   **Reasoning:** This confirms Sonnet's internal state.

2.  **Step 2: Analyze eOSCAR Connector Logs**
    *   **Action:** Investigate the eOSCAR Connector logs to find evidence of the communication event with eOSCAR. Look for a successful submission confirmation.
    *   **Reasoning:** This service is responsible for the final transmission of the response. The logs will contain definitive proof of a successful (or failed) handoff to eOSCAR.

3.  **Step 3: Trace Events in Response Logs**
    *   **Action:** Using the company alias and date, locate and review the specific response log file. Use the "fingerprint" to trace all events tied to the `ControlNumber`.
    *   **Log Path:** `/sonnet/scrape/logs/[Year]/[Mon]/[company_alias]/acdv-response.[YYYYMMDD].log`
    *   **Example:** `/sonnet/scrape/logs/2025/Feb/credencerm/acdv-response.20250210.log`

**4.4 Procedure: Resolving Stuck ACDV Responses**

**Problem Statement:** Company responses appear stuck in the processing queue. The API user is marked intermittently as "in-use," but no progress is visible.

**Procedure:** Follow this sequence of actions to resolve the issue.

1.  **Step 1: Report to Support Team**
    *   **Action:** Immediately report the issue to the support team to ensure visibility and tracking.
    *   **Reasoning:** This initiates the formal incident management process.

2.  **Step 2: Verify Data to Submit**
    *   **Action:** Confirm that there is valid, pending data in the queue for the company.
    *   **Reasoning:** Ensures the problem is a processing stall, not a lack of data.

3.  **Step 3: Investigate Company Response Logs**
    *   **Action:** Dig into the company-specific response logs to identify any abnormal situations, such as looping processes, repeated errors, or timeouts. Use the "fingerprint" format to isolate relevant entries.
    *   **Reasoning:** Log analysis is crucial for identifying the root cause of the processing stall.

4.  **Step 4: Toggle the "In-Use" Switch**
    *   **Action:** If log analysis indicates a lock or stall, carefully toggle the "in-use" switch for the API user in the Sonnet Admin interface.
    *   **Reasoning:** This can manually release a stuck process. This should only be done after investigation confirms a deadlock-like situation, as it can interrupt a legitimately long-running process.

5.  **Step 5: Create a Bug Task**
    *   **Action:** If the issue is recurring or caused by an identifiable flaw, create a bug task in the development team's Sprint placeholder with all collected evidence (logs, timestamps, etc.).
    *   **Reasoning:** This ensures a long-term fix is implemented to prevent recurrence.

**4.5 Procedure: Attachment (Image) Recovery**

**Problem Statement:** Image attachments associated with a dispute were not successfully downloaded and need to be recovered.

**Procedure:** Use the following methods for recovery, in order of preference.

1.  **Step 1: Standard Recovery Process**
    *   **Action:** In the affected Sonnet environment, create a new "download recovery job" for the specific artifacts.
    *   **Reasoning:** This is the primary, built-in mechanism for re-initiating the download process for missed attachments.

2.  **Step 2: Manual e-OSCAR Query**
    *   **Action:** If the automated recovery job fails, query e-OSCAR manually to retrieve the data for the specific artifacts. This data must then be manually associated with the dispute in Sonnet.
    *   **Reasoning:** This is a fallback manual process when the standard automation fails.

3.  **Step 3: On-Demand Environment Replication (Special Cases)**
    *   **Action:** For critical, on-demand cases where other methods fail, the environment may be replicated locally. The attachments can then be extracted and provided directly to the Support team for delivery to the client.
    *   **Reasoning:** This is a high-effort, last-resort option reserved for exceptional circumstances.
--------------------------------------------------------------------------------
Title: SOP_eOscar API credential mgmt.txt
Of course. Based on the document provided, here is a professional Standard Operating Procedure for resolving eOscar API credential errors.

***

### **Standard Operating Procedure: Resolving eOscar API Credential Errors**

**SOP ID:** OPS-SOP-2025-007
**Version:** 1.0
**Effective Date:** 07/01/2025
**Author:** [Your Name/Department]
**Approved By:** James Maki, Lidiexy Alonso

---

### **1.0 Purpose**

To provide a standardized procedure for the identification, diagnosis, and resolution of login failures related to eOscar API credentials. This SOP ensures the timely processing of automated responses and downloads by maintaining valid authentication credentials, thereby preventing service interruptions and data processing backlogs.

### **2.0 Scope**

This SOP applies to all Technical Support and Operations personnel responsible for monitoring and maintaining the eOscar integration services.

### **3.0 Prerequisites**

*   Access to application servers with permissions to execute scripts and commands.
*   Access to the production database with read/write permissions for tables such as `MemberCredentials`, `Organization`, `ResponseQueue`, and `EoscarResponse`.
*   Familiarity with identifying authentication failure messages in application logs (e.g., "login fail," "check your password").
*   Knowledge of the tools used for password migration and scheduling test downloads.

### **4.0 Procedure**

#### **4.1 Initial Diagnosis and Triage**

1.  **Identify the Issue:** Monitor the eOscar response queue (`ACDV` dashboard) for abnormal backlogs or a stalled queue where the volume of pending items is not decreasing.
2.  **Inspect Logs:** Investigate application logs for recurring authentication error messages associated with the eOscar service. Common error messages include:
    *   `login fail`
    *   `check your password`
    *   `You are not logged in`
3.  **Isolate the Affected Company:** Identify the specific company or organization ID experiencing the login failure from the log entries.

#### **4.2 Resolving Errors for a Single-Company Account**

This procedure applies to organizations with only one associated company and one set of credentials.

1.  **Obtain New Credential:** Secure the new, correct password for the company.
2.  **Execute Password Update:**
    *   Navigate to the `sona_eoscar_connector` directory on the application server.
    *   Execute the password migration command/script to update the credential (e.g., using the `migrate` operation with the specific company ID).
3.  **Verify and Test:**
    *   **Database Verification:** Query the `MemberCredentials` table in the database to confirm the password field has been updated for the company.
    *   **Live Test:** Schedule a one-time test download for the affected company to confirm the new credential is valid.
    *   **Monitor:** Observe the download process in real-time. A successful connection and initiation of the download confirms the resolution. Document the fix.

#### **4.3 Resolving Errors for a Multi-Company Account**

This procedure applies to organizations with multiple sub-companies that may share a single set of credentials (e.g., Revco, RSA). An error on one sub-company often indicates a password discrepancy across the entire organization.

1.  **Identify All Associated Credentials:**
    *   Using the Organization ID from the error logs, query the database to retrieve all associated `MemberCredential` and `Company` IDs for that organization.
2.  **Audit and Clean Up Credentials:**
    *   Carefully review the list of credentials for any duplicates (e.g., two credential entries for the same sub-company).
    *   If a duplicate is found, investigate to determine which is obsolete and delete the duplicate entry from the database to prevent conflicts.
3.  **Update All Associated Credentials:**
    *   Obtain the new, correct password for the organization.
    *   Execute the password migration command for the **main company ID**.
    *   **CRITICAL:** The automated migration may only update the credential for the main company. Manually query the database and update the password for **all other associated sub-company credentials** to match the new password. This step is essential to prevent account lockouts from failed login attempts by processes running for other sub-companies.
4.  **Verify and Test:**
    *   Schedule a one-time test download for the **main company ID**.
    *   Monitor the download process. A successful connection confirms the resolution for the entire organization. Document the fix.

#### **4.4 Handling Locked Accounts & Customer Escalation**

This procedure is initiated when internal password updates fail repeatedly, which strongly indicates the account has been locked by eOscar due to multiple failed login attempts.

1.  **Cease Internal Actions:** Immediately stop all internal attempts to update or test the password to avoid prolonging the lockout.
2.  **Initiate Customer Contact:**
    *   Identify the primary administrative user for the customer's company.
    *   Instruct the Support Team to create a new ticket assigned to that administrative user.
3.  **Request Password Reset:** The ticket must clearly and professionally request that the customer:
    *   **Reset the password for their eOscar API login directly with eOscar.**
    *   Provide the new password back to the support team via the ticket.
4.  **Implement New Credential:** Once the new password is received from the customer, return to the appropriate procedure (**Section 4.2 or 4.3**) to apply the new credential.

### **5.0 Appendix: Sample Queries and Commands**

*Note: The following are examples based on the transcript and may require adaptation for the specific environment.*

**5.1 Query to Find Associated Credentials:**
```sql
SELECT * FROM MemberCredentials
WHERE OrganizationID = [Target_Organization_ID];
```

**5.2 Password Migration Command Concept:**
```bash
# Example of executing a script for a password migration
./run_script.sh --operation migrate --company_id [Company_ID]
```

**5.3 Download Scheduling Command Concept:**
```bash
# Example of scheduling a one-time download for testing purposes
./schedule_download.sh --company_id [Company_ID] --type onetime --count 10
```
--------------------------------------------------------------------------------
Title: SOP_Sonnet - Product Demo_Training - Part 1 - AI Notes (1).txt
Here is a Standard Operating Procedure (SOP) based on the provided document.

***

### **Standard Operating Procedure: Dispute Management in Sonnet**

**SOP Number:** SON-DM-001
**Version:** 1.0
**Effective Date:** [Date]
**Author:** [Author's Name/Department]
**Approved By:** [Approver's Name/Title]

---

### **1.0 Purpose**

The purpose of this Standard Operating Procedure (SOP) is to define the standardized process for managing, processing, and resolving consumer credit disputes using the Sonnet platform. This document ensures all users follow a consistent workflow for handling disputes received from E-Oscar, interacting with client Systems of Record (SOR), and utilizing the various work queues within Sonnet.

### **2.0 Scope**

This SOP applies to all personnel, including dispute resolution specialists and supervisors, who are responsible for processing consumer credit disputes within the Sonnet platform.

### **3.0 Definitions**

*   **Sonnet:** The primary application used for managing and processing credit disputes.
*   **E-Oscar:** The electronic system for exchanging dispute information between data furnishers (our clients) and Credit Reporting Agencies.
*   **System of Record (SOR):** The client's internal database that provides the consumer and account information necessary to investigate a dispute.
*   **Dashboard:** The landing page in Sonnet that provides an at-a-glance summary of dispute statuses and key metrics.
*   **Active Queue:** The primary work queue containing disputes that have all necessary data from the SOR and are ready for investigation and processing.
*   **Work in Progress (WIP) Queue:** A global queue for disputes that have been partially worked on but are saved for later completion.
*   **QA Queue:** A permissions-based queue for disputes that require review and approval from a supervisor or quality assurance specialist.
*   **Error Queue:** A queue containing disputes that were submitted to E-Oscar but were rejected due to an error.

### **4.0 Responsibilities**

*   **Dispute Resolution Specialists (Users):** Responsible for the daily processing of disputes from the Active Queue, correcting errors from the Error Queue, and moving disputes to the WIP or QA queues as needed.
*   **Supervisors / QA Personnel:** Responsible for reviewing and processing disputes from the QA Queue, managing team workflow, and providing guidance on complex disputes.

---

### **5.0 Procedure**

#### **5.1 Daily Start-Up and Dashboard Review**

1.  **Login:** Log into the Sonnet platform. The **Dashboard** is the default landing page.
2.  **Dashboard Assessment:** Review the tiles on the Dashboard to understand the current day's workload and system status. Key tiles include:
    *   **E-Oscar Response Queue:** Disputes completed and awaiting transmission back to E-Oscar.
    *   **Disputes Waiting for System of Record Data:** Disputes downloaded from E-Oscar that are pending data from the client's SOR. *Note: Data exchange with most clients occurs once daily.*
    *   **Disputes Received Today:** A count of new disputes received on the current day.
    *   **Disputes Completed Today:** A count of disputes resolved on the current day.
    *   **Disputes within 5 Days of Due Date:** A critical indicator for prioritizing work to remain in compliance.
3.  **Review Dispute Backlog:** Examine the dispute backlog graphic to understand the total volume of open disputes and their distribution across the various queues (Active, QA, WIP).

#### **5.2 Standard Dispute Processing Workflow**

1.  **Access Active Queue:** Navigate to the **Active Queue**. This queue contains all disputes ready for processing.
2.  **Select a Dispute:** Open a dispute from the queue. Upon opening, the dispute is automatically **locked** to prevent other users from working on it simultaneously.
3.  **Review Dispute Details:** On the dispute details page, methodically review all provided information:
    *   Header information
    *   Consumer Information (from E-Oscar)
    *   Account Information (from client SOR)
    *   Payment History Profile
    *   Attached Images or documents
    *   Notes from previous user interactions
4.  **Investigate and Formulate Response:** Analyze the consumer's dispute claim against the client's SOR data. Determine the correct response and any necessary updates to the account.
5.  **Enter Response:** Navigate to the appropriate response tabs. Enter the resolution codes and any required narrative or data updates for both E-Oscar and the client's SOR.
6.  **Submit Dispute:** Once all required fields are completed, submit the dispute. The resolution is transmitted to E-Oscar and the client's SOR. The dispute will now appear in the **Completed Today** queue.

#### **5.3 Managing Special Queues and Scenarios**

**5.3.1 Pausing Work (Work in Progress Queue)**

1.  If a dispute cannot be completed in one session, move it to the **Work in Progress (WIP) Queue**.
2.  Before moving, add a clear note detailing the current status and any pending actions.
3.  To resume work, retrieve the dispute from the WIP Queue. *Note: Any user can access and continue work on a dispute in the WIP Queue.*

**5.3.2 Requesting Supervisory Review (QA Queue)**

1.  For complex disputes, or as part of a new employee training process, send the dispute to the **QA Queue**.
2.  The dispute will be inaccessible to standard users and must be reviewed, completed, and submitted by a supervisor or a user with QA permissions.

**5.3.3 Correcting Submission Errors (Error Queue)**

1.  Routinely monitor the **Error Queue** throughout the day. Disputes appear here if they are rejected by E-Oscar (typically within 5 minutes of submission).
2.  Open the dispute from the Error Queue. Review the specific error message provided by E-Oscar (e.g., "incorrect response code," "bad value in payment history").
3.  Make the necessary corrections based on the error message.
4.  Resubmit the dispute.

#### **5.4 Handling Custom Work Queues**

1.  If configured by the client, custom work queues may be used to segregate disputes based on specific criteria (e.g., fraud, bankruptcy).
2.  These queues are visible to all users. Follow internal client policies for managing and prioritizing work from these custom queues.

#### **5.5 Understanding the Dispute Locking Mechanism**

1.  When a user opens a dispute, it is locked to prevent data conflicts.
2.  If a user is inactive on a locked dispute for **15 minutes**, the dispute will automatically unlock and return to its original queue, making it available for other users. To avoid this during a planned break, proactively move the dispute to the WIP Queue.

---

### **6.0 Document Control**

| Version | Date       | Author                | Change Description           |
| :------ | :--------- | :-------------------- | :--------------------------- |
| 1.0     | [Date]     | [Author's Name]       | Initial version of the SOP.  |
--------------------------------------------------------------------------------
Title: SOP_Sonnet - Product Demo_Training - Part 1 - AI Notes.txt
Of course. Here is a professional Standard Operating Procedure (SOP) based on the provided document.

***

### **Standard Operating Procedure: Dispute Management in Sonnet**

| **SOP ID:** | SON-DM-001 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Effective Date:** | October 26, 2023 | **Approved By:** | Management |
| **Applies To:** | All personnel responsible for processing consumer credit disputes using the Sonnet platform, including Users, Supervisors, and Quality Assurance (QA) staff. |

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) provides standardized guidelines for navigating the Sonnet platform, understanding the dispute lifecycle, and processing consumer disputes. The objective is to ensure consistent, efficient, and accurate dispute resolution in compliance with E-Oscar and internal client requirements.

### **2.0 Scope**

This document covers all procedural steps from initial dashboard review to final dispute submission, including queue management, handling exceptions, and quality assurance protocols within the Sonnet system.

### **3.0 Definitions**

*   **Sonnet:** The primary application for managing credit disputes.
*   **E-Oscar:** The electronic system for exchanging dispute information with Credit Reporting Agencies.
*   **System of Record (SOR):** The client's internal system that houses the definitive consumer and account data.
*   **Queue:** A virtual location within Sonnet where disputes are grouped based on their current status in the workflow (e.g., Active, QA, Error).

### **4.0 Responsibilities**

*   **User/Analyst:** Responsible for processing disputes from the Active Queue, utilizing the Work in Progress queue, submitting disputes for QA review, and correcting disputes from the Error Queue.
*   **Supervisor/QA Personnel:** Responsible for reviewing and processing disputes from the permission-based QA Queue, managing team workflow, and ensuring procedural adherence.

---

### **5.0 Procedure**

#### **5.1 Understanding the Sonnet Dashboard**

The Sonnet Dashboard is the landing page upon login and provides a high-level, static overview of the dispute processing environment.

1.  **Review Dashboard Tiles:** Familiarize yourself with the key metrics displayed on the informational tiles:
    *   **E-Oscar Response Queue:** Disputes completed and awaiting transmission to E-Oscar.
    *   **Disputes Waiting for SOR Data:** Disputes downloaded from E-Oscar that are pending data from the client's System of Record.
    *   **Disputes Received Today:** A count of new disputes received on the current day.
    *   **Disputes Completed Today:** A count of disputes completed on the current day.
    *   **Disputes within 5 Days of Due Date:** A critical alert for disputes nearing their regulatory deadline.
2.  **Analyze Dispute Backlog:** Use the backlog graphic to understand the total volume of disputes in the system and their distribution across the primary queues (Active, QA, Work in Progress).

#### **5.2 The Standard Dispute Lifecycle and Queue Management**

The following steps outline the standard flow of a dispute through the Sonnet system.

1.  **Initial Ingestion (Automated):** Disputes are downloaded from E-Oscar and initially populate the **Disputes Waiting for SOR Data** queue. No user action is required at this stage.
2.  **Activation:** Once Sonnet receives the necessary data from the client's SOR (typically a daily process), disputes move to the **Active Queue**. These disputes are now ready for processing.
3.  **Processing:** Users work on disputes from the **Active Queue** or designated **Custom Work Queues**.
4.  **Completion:** Once a dispute is submitted, it is transmitted to E-Oscar and the client's SOR. It will appear in the **Completed Today Queue** for tracking purposes.

#### **5.3 Processing an Individual Dispute**

1.  **Select a Dispute:** Navigate to the appropriate work queue (e.g., Active Queue) and select a dispute to work on.
    *   **Dispute Locking:** Upon opening a dispute, the system will automatically lock it, preventing other users from accessing it simultaneously.
    *   **Automatic Unlock:** Be advised that the lock is released automatically after 15 minutes of inactivity.
2.  **Review Dispute Details:** On the dispute details page, thoroughly review all available information:
    *   Header Information
    *   Consumer & Account Information
    *   Payment History Profile
    *   Attached Images and Notes
3.  **Formulate and Submit Response:** Use the designated response tabs to prepare and submit the final response for both E-Oscar and the client's SOR.
4.  **Saving In-Progress Work:** If a dispute cannot be completed in a single session:
    *   Select the option to send the dispute to the **Work in Progress Queue**.
    *   Add clear and concise notes for context. This saves all progress and makes the dispute available for another user to complete if necessary.

#### **5.4 Handling Exceptions and Quality Assurance**

##### **5.4.1 Submitting for Quality Assurance (QA)**

1.  **Identify Need for QA:** For complex disputes, or as required by new employee training protocols, send the dispute to the **QA Queue** for supervisory review.
2.  **Supervisor Review:** A supervisor or authorized QA user will access the permission-based **QA Queue**.
3.  **Final Submission:** The supervisor is responsible for conducting the review and performing the final submission of the dispute from the QA Queue.

##### **5.4.2 Managing Errors**

1.  **Monitor the Error Queue:** All users must regularly monitor the **Error Queue**, which contains disputes that were rejected by E-Oscar. Errors are typically returned within minutes of submission.
2.  **Identify the Error:** Open the dispute from the Error Queue. Read the specific error message provided by E-Oscar (e.g., "incorrect response code," "bad value in payment history").
3.  **Correct and Resubmit:** Correct the specific issue identified in the error message.
4.  **Resubmit the Dispute:** Submit the corrected dispute for re-processing by E-Oscar.

#### **5.5 Using Custom Work Queues**

1.  **Purpose:** Clients may configure **Custom Work Queues** to segment disputes based on specific criteria, such as fraud or bankruptcy cases.
2.  **Accessibility:** These queues are visible to all users.
3.  **Assignment:** The assignment of users to specific custom queues is managed by internal client policies and procedures, not by the Sonnet system itself. Follow your team lead's or supervisor's direction for working from these queues.

---
### **6.0 Revision History**

| Version | Date | Author | Description of Changes |
| :--- | :--- | :--- | :--- |
| 1.0 | October 26, 2023 | SOP Generator | Initial document creation based on Sonnet training session. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet - Product Demo_Training - Part 2 - AI Notes (1).txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure for managing credit disputes.

***

### **Standard Operating Procedure: Managing Credit Disputes in the Sonnet Platform**

**SOP ID:** SON-DIS-001
**Version:** 1.0
**Effective Date:** October 26, 2023
**Department:** Dispute Resolution Operations
**Author:** Process Excellence Team

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) provides a standardized methodology for users to investigate, comment on, respond to, and manage consumer credit disputes using the Sonnet platform. The procedure also covers the creation of Automated Universal Dataforms (AUDs) and the review of post-submission notifications. Adherence to this SOP ensures consistency, accuracy, and comprehensive record-keeping for all dispute resolution activities.

### **2.0 Scope**

This SOP applies to all personnel responsible for processing and resolving consumer credit disputes within the Sonnet platform.

### **3.0 Procedure: Investigating a Dispute**

Upon opening a dispute in Sonnet, the following steps should be taken to conduct a thorough investigation.

**3.1 Review Dispute History**
1.  Navigate to the **History** section of the dispute.
2.  Review the activity log to gain full insight into the dispute's lifecycle. The log includes:
    *   Data downloads from E-Oscar.
    *   All changes made to the dispute data.
    *   A record of all user activities within the dispute.
3.  Utilize this history as supporting information for client review and for potential legal situations.

**3.2 Utilize the Investigation Checklist**
1.  Locate the **Investigation Checklist** within the dispute interface. This checklist is configured by the client to align with their internal policies.
2.  As you complete each required investigation step, mark the corresponding item on the checklist.
3.  **Note:** The checklist serves as a guide and a double-check to ensure procedural compliance. Submitting a response is not contingent on the completion of all checklist items.

**3.3 Add Comments**
1.  To add a note or comment to the dispute, navigate to the **Comments** section.
2.  Type your comment into the text field provided.
3.  Click **Add Comment** to save the entry.
4.  **Note:** All comments are logged with the dispute and are included in the Step 3 export file for client visibility.

**3.4 Flag for Information Requests (If Applicable)**
1.  If additional information is required from the consumer to proceed (e.g., an ID theft package, a copy of a bill), check the appropriate **Request Information** checkbox.
2.  This action adds a flag to the Step 3 export file, which triggers the client's internal workflow for information retrieval.
3.  If waiting for information, add a descriptive note in the **Comments** section and use the **Save and Exit** function (see section 4.3) to move the dispute to the work-in-progress queue.

### **4.0 Procedure: Submitting a Dispute Response**

After the investigation is complete, select one of the following submission options.

**4.1 Submit Response**
1.  This is the standard action for a completed dispute.
2.  Click **Submit Response**.
3.  The response is transmitted to E-Oscar, and the dispute is marked as "Completed" in Sonnet.
4.  If the "Go to Next Dispute" feature is enabled for your user profile, you will automatically be taken to the next dispute in your active queue.

**4.2 Send to Quality Assurance (QA)**
1.  If the dispute requires a second-level review, prepare to send it to the QA queue.
2.  Add a comment clearly explaining the reason for the QA escalation.
3.  Click the **Send to QA** button. The dispute will be moved to the QA queue for review.

**4.3 Save and Exit**
1.  If the dispute is not ready for submission (e.g., awaiting information), use this option.
2.  Click **Save and Exit**.
3.  The dispute is moved to the "Work-in-Progress" queue.
4.  An optional comment may be added to provide context for why the dispute was saved without submission.

### **5.0 Procedure: Creating an Automated Universal Dataform (AUD)**

An AUD can be initiated to proactively update consumer data with the credit bureaus.

**5.1 Create AUD from Scratch**
1.  Navigate to the AUD creation section.
2.  Select the option to create a new AUD.
3.  Manually complete all required fields in the form.
4.  Select the appropriate correction indicator and submit the AUD.

**5.2 Create AUD from an Existing ACDV**
1.  If the account has been part of a previous ACDV, you may have the option to create an AUD from it.
2.  Select this option to pre-fill the AUD form with the most recent response data from the previous dispute.
3.  Review and modify any necessary fields and submit the AUD. The AUD will appear in the active AUD list.

**5.3 Automated Creation via API**
Clients may use the Sonnet API to automate AUD creation directly from their system of record. These AUDs will populate in Sonnet for management and submission.

### **6.0 Procedure: Reviewing Post-Submission Notifications**

After submitting disputes or AUDs, review notifications from the bureaus to ensure actions were processed and to take further steps if necessary.

**6.1 AUD Notifications**
1.  Review AUD notifications to confirm whether submitted AUDs were successfully processed by the credit bureaus.
2.  If an AUD was not processed, the notification will provide a reason (e.g., internal bureau policies, inability to locate the consumer).
3.  Use this feedback to take corrective action.

**6.2 Data Reporter (DR) Notifications**
1.  Review DR notifications for updates from the bureaus regarding actions taken on reported trade lines (e.g., changes made based on a dispute response).
2.  If the notification indicates a change (e.g., deletion due to fraud), take the required action to investigate and update the client's system of record accordingly.

### **7.0 Best Practices: System of Record Management**

Maintaining data integrity between Sonnet and the client's system of record is critical.

1.  **Utilize the Step 3 File:** The Step 3 file is the primary data export from Sonnet that contains all changes, comments, and flags from the dispute resolution process.
2.  **Update System of Record:** It is a best practice for the client to use the Step 3 file to update their internal system of record. This ensures that any modified information is corrected internally.
3.  **Prevent Data Re-pollution:** Failing to update the system of record can lead to re-reporting the same incorrect information to the bureaus in subsequent reporting cycles.
4.  **Finalize Dispute Record:** At a minimum, the client's system of record should be updated to note that the dispute was completed for the account.
--------------------------------------------------------------------------------
Title: SOP_Sonnet - Product Demo_Training - Part 2 - AI Notes.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure for managing credit disputes within the Sonnet system.

---

### **Standard Operating Procedure: Sonnet Dispute Resolution Process**

**SOP Number:** SON-DR-001
**Version:** 1.0
**Effective Date:** October 26, 2023
**Department:** Operations / Dispute Resolution

---

### 1.0 Purpose

To establish a standardized process for investigating, responding to, and managing consumer credit disputes using the Sonnet platform. This SOP ensures consistency, accuracy, and compliance in all dispute-handling activities.

### 2.0 Scope

This SOP applies to all personnel responsible for processing, investigating, and responding to credit disputes received via E-Oscar within the Sonnet system.

### 3.0 Definitions

*   **Sonnet:** The software platform used for managing and responding to credit disputes.
*   **E-Oscar:** The electronic system used to transmit dispute information between data furnishers and credit reporting agencies (CRAs).
*   **AUD (Automated Universal Dataform):** A standardized form used to proactively report updates or corrections to consumer credit information to the CRAs, outside of a direct dispute response.
*   **ACDV (Automated Consumer Dispute Verification):** The standardized form received from a CRA via E-Oscar that initiates a consumer dispute investigation.
*   **DR Notification (Dispute Resolution Notification):** An update from a CRA detailing an action they have taken on a reported tradeline, which may require an update to the client's system of record.
*   **Step 3 File:** An export file generated by Sonnet containing all data related to completed disputes, including comments and flags. Clients use this file to update their internal systems of record.
*   **QA (Quality Assurance):** A review queue for disputes that require a second level of review before being submitted.

### 4.0 Procedure: Dispute Investigation and Initial Actions

#### 4.1 Accessing and Reviewing a Dispute

1.  **Review Dispute History:** Upon opening a dispute, navigate to the **History** section. Review the log of all activities, including the initial data download from E-Oscar, user actions, and system-generated changes. This provides a complete audit trail for the dispute.
2.  **Add Investigation Comments:**
    *   Navigate to the **Comments** section.
    *   Enter clear and concise notes regarding the investigation findings, actions taken, or information required.
    *   Click **Add Comment** to save the entry.
    *   **Note:** All comments are logged in the dispute history and included in the Step 3 file provided to the client.

#### 4.2 Conducting the Investigation

1.  **Complete the Investigation Checklist:**
    *   Locate the client-specific **Investigation Checklist**. This checklist is configured by the client to align with their internal policies.
    *   As each required investigation step is completed, mark the corresponding item on the checklist.
    *   **Note:** The checklist serves as a guide and a double-check to ensure a thorough investigation. Submission of the dispute response is not contingent upon checklist completion.
2.  **Request Additional Information (If Necessary):**
    *   If additional information is required from the consumer or client (e.g., ID theft package, copy of a utility bill), select the appropriate **Request Information** checkbox.
    *   This action places a flag in the Step 3 file, which signals the client to initiate their internal workflow for retrieving the necessary documentation.

### 5.0 Procedure: Finalizing and Submitting the Response

After completing the investigation, select one of the following submission options based on the outcome.

#### 5.1 Submit Response to E-Oscar

*   **Action:** Select the **Submit Response** option.
*   **Result:** The dispute response is transmitted to E-Oscar, and the dispute is marked as "Completed" in Sonnet. This is the standard action for a fully resolved dispute.

#### 5.2 Send to Quality Assurance (QA)

*   **Action:** If a secondary review is required, select the **Send to QA** option.
*   **Result:** A comment field will appear. You must enter a note explaining the reason for the QA escalation. The dispute is then moved to the QA queue for review by another team member.

#### 5.3 Save and Exit (Work in Progress)

*   **Action:** If the dispute cannot be completed (e.g., awaiting information from the consumer), select the **Save and Exit** option.
*   **Result:** The dispute is moved to the "Work-in-Progress" queue. You may add an optional comment to provide context for the delay.

#### 5.4 Go to Next Dispute

*   **Action:** After submitting a response, the system may automatically load the next available dispute from the active queue.
*   **Result:** This functionality, managed via user permissions, streamlines workflow by eliminating the need to return to the main queue manually.

### 6.0 Procedure: Post-Submission and Data Management

#### 6.1 Client System of Record Updates (via Step 3 File)

*   The client is responsible for utilizing the **Step 3 file** to update their internal system of record with any changes made during the dispute resolution process (e.g., corrected account information, updated status).
*   **Best Practice:** It is critical for clients to update their systems to prevent the re-reporting of incorrect information to the CRAs on subsequent data submissions. At a minimum, the client should record that a dispute was investigated and completed for the account.

#### 6.2 Creating an AUD (Automated Universal Dataform)

An AUD can be created to proactively correct data with the CRAs.

1.  **Create from Scratch:**
    *   Navigate to the AUD creation module.
    *   Manually fill in all required fields in the form.
    *   Select the appropriate correction indicator and submit.
2.  **Create from an Existing ACDV:**
    *   Open the relevant ACDV.
    *   Select the option to **Create AUD from ACDV**. The system will pre-fill the AUD form with the most recent response data from the dispute, reducing manual entry.
    *   Review, modify if necessary, and submit the AUD.
3.  **API Automation (Client-Side):** Clients may use the Sonnet API to programmatically generate AUDs from their own systems, which are then populated in Sonnet for processing.

### 7.0 Procedure: Monitoring Bureau Notifications

#### 7.1 Review AUD Notifications

*   Regularly monitor **AUD Notifications** to confirm whether submitted AUDs were successfully processed by the CRAs.
*   If an AUD was not processed, review the provided reason (e.g., internal bureau policies, inability to locate consumer) and take the necessary corrective action.

#### 7.2 Review DR (Dispute Resolution) Notifications

*   Regularly monitor **DR Notifications** for updates from CRAs on actions taken on reported tradelines (e.g., changes made, deletions due to fraud).
*   Based on the information in the DR Notification, the client must take appropriate action to investigate and update their system of record to ensure data accuracy and compliance.

---
**End of SOP**
--------------------------------------------------------------------------------
Title: SOP_Sonnet - Product Demo_Training - Part 3 - AI Notes (1).txt
Of course. Based on the document provided, here is a professional Standard Operating Procedure (SOP) for handling Block Notifications and Direct Disputes.

***

### **Standard Operating Procedure: Credit Reporting Compliance**

**SOP ID:** CRC-007
**Version:** 1.0
**Effective Date:** [Date]
**Author:** Compliance Department
**Approved By:** Amanda Gilbert, Head of Compliance

---

### **1.0 PURPOSE**

This Standard Operating Procedure (SOP) establishes the official process for handling two critical types of credit reporting communications: **Block Notifications** and **Direct Disputes**. The purpose is to ensure regulatory compliance, protect consumers from identity theft, maintain data accuracy, and prevent the re-reporting of fraudulent information.

### **2.0 SCOPE**

This SOP applies to all Dispute Resolution, Compliance, and Operations personnel responsible for receiving, investigating, and responding to consumer credit reporting notifications and disputes using the Sonnet platform.

### **3.0 DEFINITIONS**

*   **Block Notification:** A mandatory alert from a Credit Reporting Agency (CRA) indicating that specific information on a consumer's credit report has been blocked due to confirmed identity theft or fraud. This is a critical notification requiring immediate action.
    *   **Block Notification ID:** A block placed on a specific piece of data, such as a Social Security Number or address.
    *   **Block Trade Line:** A block placed on an entire account or trade line.
*   **Block Rescission Request (BRR):** A formal request submitted to a CRA to remove (rescind) a block when a data furnisher’s investigation determines the block was applied in error and there is no evidence of fraud.
*   **Direct Dispute:** A dispute received directly from a consumer (e.g., via letter, phone call, email) rather than through the E-Oscar system from a CRA.
*   **Sonnet:** The software platform used by the organization to manage and process all credit reporting disputes and notifications.
*   **OCR (Optical Character Recognition):** An automated process within Sonnet that extracts key information from uploaded documents to create dispute cases.

---

### **SECTION A: PROCEDURE FOR HANDLING BLOCK NOTIFICATIONS**

This section outlines the process for managing Block Notifications received from CRAs.

#### **4.0 Initial Review and Triage**

1.  **Receive Notification:** Block Notifications are received electronically and will appear within the Sonnet platform.
2.  **Identify Notification Type:** Determine if the notification is a **Block Notification ID** or a **Block Trade Line**. Block Trade Line notifications require a more thorough investigation.
3.  **Utilize Sonnet 360 View:** Access the "360 View" feature in Sonnet for the associated account number. This provides a comprehensive history of all related transactions and disputes, offering critical context for the investigation.

#### **5.0 Standard Procedure: Accepting a Block Notification**

This is the default procedure unless there is clear evidence the block is erroneous.

1.  **Acknowledge and Accept:** Review the Block Notification details. The data furnisher’s primary obligation is to accept the block.
2.  **Prevent Re-reporting:** Ensure internal systems are updated and flagged to permanently prevent the blocked information from being re-reported to any CRA in future credit reporting cycles.
3.  **Internal Documentation:** While supporting documents cannot be transmitted back to the CRA for a standard block acceptance, all review and system update actions must be thoroughly documented internally within Sonnet for audit purposes.
4.  **Close Case:** Once system flags are confirmed, close the Block Notification case in Sonnet.

#### **6.0 Exception Procedure: Initiating a Block Rescission Request (BRR)**

This procedure is followed only when an investigation provides substantial evidence that the block was applied in error.

1.  **Identify Potential Error:** Flag a Block Notification for further investigation if there is evidence that contradicts the fraud claim.
    *   *Example:* The consumer is making regular, timely payments on the account, and there are no other internal indicators of identity theft.
2.  **Conduct Internal Investigation:** Perform a detailed investigation to validate the account's legitimacy.
    *   Verify the consumer’s identity, contact information, and account history.
    *   Review all account activity for signs of fraudulent behavior.
    *   Examine the original, signed contract and all supporting documentation on file.
3.  **Decision Point:**
    *   **If evidence of fraud is found or the block cannot be disproven:** Revert to the standard procedure (Section 5.0) and accept the block.
    *   **If the investigation confirms no evidence of fraud:** Proceed with submitting a BRR.
4.  **Submit the BRR:**
    *   Compile all supporting documentation from the investigation that proves the account is legitimate and belongs to the consumer.
    *   Submit the Block Rescission Request (BRR) through the appropriate channel in Sonnet/E-Oscar to request the reinsertion of the blocked trade line or data.
5.  **Monitor and Document:** Track the CRA’s response to the BRR and document all actions and communications within the Sonnet case file.

---

### **SECTION B: PROCEDURE FOR PROCESSING DIRECT DISPUTES**

This section outlines the process for managing disputes received directly from consumers.

#### **7.0 Processing Written Direct Disputes (Mail, Email)**

1.  **Receive and Scan:** Upon receipt of a written dispute, scan the letter and any accompanying documents into a digital format (e.g., PDF).
2.  **Upload to Sonnet:**
    *   Log in to Sonnet and navigate to the **Manage Files** tab.
    *   Upload the scanned document(s) using the drag-and-drop or browse-to-upload functionality.
3.  **Monitor OCR Process:** The document status will show as processing. Wait until the OCR process is complete and the status changes to **"Ready for Review."**
4.  **Verify Extracted Data:**
    *   Open the **Direct Dispute Verification Form**. Sonnet will display the uploaded document alongside the data fields extracted by the OCR.
    *   Carefully compare the extracted information (e.g., name, address, account number) with the source document.
    *   Correct any inaccuracies or populate any missing fields.
    *   **Note:** If a single letter disputes multiple accounts, ensure Sonnet has correctly created a separate dispute case for each account number identified. If an account number is missing, follow internal procedures for consumer identification.
5.  **Create Dispute:** Once all information is verified, click **Confirm** to officially create the Direct Dispute case(s) in Sonnet. This action starts the 30-day resolution timer.

#### **8.0 Processing Verbal Direct Disputes (Phone Call)**

1.  **Gather Information:** During the phone call, collect all necessary details from the consumer regarding their dispute.
2.  **Document in System:**
    *   The details of the verbal dispute must be included in the **Step 2 data file** that is sent to Sonnet, adhering to the required file specifications.
    *   Alternatively, if manually creating the dispute in Sonnet, navigate to the Direct Dispute creation form.
3.  **Identify Source:** In the verification form or creation screen, select **"Verbal"** from the dispute source dropdown menu.
4.  **Select Dispute Reason:** Choose the appropriate reason for the dispute from the list. This list is customizable by the organization's Sonnet administrator.
5.  **Create Dispute:** Save the entry to create the dispute case in Sonnet and start the 30-day resolution timer.

#### **9.0 Investigation and Resolution of Direct Disputes**

1.  **Assignment:** Once created, the dispute is assigned to an analyst for investigation.
2.  **Investigation:** The analyst will conduct a reasonable investigation into the consumer’s claim.
3.  **Resolution:** The analyst must update the case in Sonnet with the investigation findings, a resolution code, and any necessary changes to credit reporting.
4.  **Timeliness:** All Direct Disputes must be investigated and resolved within the 30-day timeframe mandated by the FCRA, as tracked by Sonnet. Dashboard metrics should be monitored to ensure cases do not become overdue.
--------------------------------------------------------------------------------
Title: SOP_Sonnet - Product Demo_Training - Part 3 - AI Notes.txt
Of course. Based on the document provided, here are two professional Standard Operating Procedures (SOPs) for the described processes.

***

### **SOP 1: Handling Credit Bureau Block Notifications**

**SOP ID:** CR-COMP-001
**Version:** 1.0
**Effective Date:** [Date]
**Department:** Credit Reporting & Compliance
**Author:** [Your Name/Department]
**Approver:** [Manager/Compliance Officer Name]

---

**1.0 PURPOSE**

This Standard Operating Procedure (SOP) outlines the mandatory process for reviewing, handling, and responding to Block Notifications received from Credit Reporting Agencies (CRAs or Bureaus). The purpose is to ensure compliance with regulatory requirements, prevent the re-reporting of information confirmed as fraudulent, and maintain data integrity.

**2.0 SCOPE**

This SOP applies to all personnel in the Credit Reporting and Dispute Resolution teams responsible for processing and managing data furnished to CRAs, specifically those interacting with the Sonnet platform and E-Oscar.

**3.0 DEFINITIONS**

*   **Block Notification:** An alert from a CRA indicating that specific information on a consumer's credit report has been blocked due to a confirmed case of identity theft or fraud. This is a critical alert requiring immediate attention.
*   **Block Notification ID:** A type of block that may apply to a single piece of information (e.g., Social Security Number, address) or an entire consumer data set.
*   **Block Trade Line:** A type of block that applies to an entire account or trade line, blocking the full data set from being reported.
*   **Block Rescission Request (BRR):** A formal request submitted by the data furnisher to a CRA to reverse a block and reinsert a trade line, used only when an investigation proves the block was applied in error and no fraud exists.
*   **CRA (Credit Reporting Agency):** Also known as the Bureau (e.g., Equifax, Experian, TransUnion).
*   **Data Furnisher:** The entity (e.g., bank, credit union) providing account information to the CRAs.
*   **Sonnet:** The software platform used for managing credit reporting disputes and notifications.

**4.0 RESPONSIBILITIES**

*   **Credit Reporting Analysts:** Responsible for daily monitoring of notifications, conducting investigations, and processing responses in Sonnet.
*   **Compliance Manager:** Responsible for oversight, providing guidance on complex cases, and approving the submission of any Block Rescission Requests (BRRs).

**5.0 PROCEDURE**

**5.1 Receiving and Identifying a Block Notification**

1.  **Monitor Notifications:** Actively monitor incoming transactions from the CRAs within the Sonnet platform daily.
2.  **Identify Block:** Identify notifications specifically coded as "Block Notification." These are considered high priority.
3.  **Determine Block Type:** Differentiate between a "Block Notification ID" and a "Block Trade Line" to understand the scope of the required action.

**5.2 Initial Investigation and Review**

1.  **Access Account Details:** Locate the relevant account within Sonnet.
2.  **Utilize 360 View:** Open the "360 View" for the account to see a comprehensive history of all related transactions, including any prior disputes or communications.
3.  **Conduct Initial Assessment:** Review the block details. The furnisher's primary obligation is to accept the CRA's determination of fraud and prevent re-reporting. Proceed to section 5.3 unless there is strong evidence to suggest the block is erroneous.

**5.3 Accepting a Block Notification**

1.  **Acknowledge and Accept:** Formally accept the block notification within the Sonnet system as per system guidelines.
2.  **Internal System Update:** Ensure internal systems of record are flagged or updated to prevent the blocked information (e.g., the full trade line or specific consumer identifier) from being included in future credit reporting data files sent to the CRAs.
3.  **Documentation:** Although supporting documents are not transmitted to the CRA for an accepted block, all internal notes and system actions must be logged in Sonnet for audit and record-keeping purposes.

**5.4 Contesting a Block Notification (Block Rescission Request - BRR) Process**

A BRR should only be initiated when internal investigation provides definitive proof that the consumer is legitimately associated with the account and no identity theft has occurred.

1.  **Initiate In-Depth Investigation:** If initial review suggests a block is incorrect (e.g., the consumer is actively making payments and has not reported fraud to the institution), begin a thorough investigation.
2.  **Investigation Steps:**
    *   Verify the consumer’s identity and contact information against original account-opening documents.
    *   Review the complete account history for any signs or reports of identity theft.
    *   Analyze payment history and recent consumer interactions.
    *   Examine the original, signed contract or application.
3.  **Decision Point:**
    *   **If Fraud is Found or Suspected:** Cease the BRR process and proceed with section 5.3 (Accepting a Block Notification).
    *   **If No Evidence of Fraud is Found:** And there is clear evidence the debt belongs to the consumer, proceed with the BRR.
4.  **Submit Block Rescission Request (BRR):**
    *   Compile all supporting documentation from the investigation.
    *   Submit the BRR through the appropriate channel (e.g., E-Oscar) as a request to the CRA to reinsert the blocked information.
    *   Clearly articulate the findings of the internal investigation as justification for the request.
5.  **Record Keeping:** Save copies of all documentation and communications related to the BRR within the Sonnet case file.

**6.0 REPORTING**

Utilize the reporting functions within Sonnet to monitor block notification activity.
*   **Detail Reports:** For reviewing specific information about each notification.
*   **Summary Reports:** For a high-level overview of notification volumes by day or other period.

---

### **SOP 2: Processing Direct Disputes**

**SOP ID:** CR-COMP-002
**Version:** 1.0
**Effective Date:** [Date]
**Department:** Credit Reporting & Compliance / Customer Service
**Author:** [Your Name/Department]
**Approver:** [Manager/Compliance Officer Name]

---

**1.0 PURPOSE**

This SOP defines the standardized process for logging, investigating, and resolving direct disputes. This ensures that all disputes received directly from consumers—bypassing the E-Oscar system—are handled in a timely and compliant manner.

**2.0 SCOPE**

This SOP applies to all personnel responsible for receiving and processing consumer disputes, including those received via mail, email, or phone call, using the Sonnet platform.

**3.0 DEFINITIONS**

*   **Direct Dispute:** A dispute regarding credit reporting information that a consumer submits directly to the data furnisher rather than through a CRA.
*   **OCR (Optical Character Recognition):** Technology used by Sonnet to scan uploaded documents and automatically extract key information.
*   **Step 2 Data:** A data file format used to import dispute information into Sonnet, often used for disputes not initiated via document upload (e.g., verbal disputes).

**4.0 RESPONSIBILITIES**

*   **Dispute Resolution Team:** Responsible for uploading, verifying, investigating, and resolving all direct disputes within the established timeframes.
*   **Administrative Users:** Responsible for maintaining the client-customizable dispute reasons within Sonnet.

**5.0 PROCEDURE**

**5.1 Processing Written Direct Disputes (Letter, Email)**

1.  **Log into Sonnet:** Access the Sonnet platform.
2.  **Navigate to File Upload:** Select the "Manage Files" tab.
3.  **Upload Document:** Upload the scanned dispute letter or document. Use the drag-and-drop feature or browse to select the file.
4.  **Monitor OCR Process:** The system will automatically perform an OCR scan to extract data. The file status will change to "Ready for Review" upon completion.
5.  **Verify Extracted Data:**
    *   Open the "Direct Dispute Verification Form."
    *   Carefully compare the system-populated fields (e.g., consumer name, account number) against the image of the original document displayed on the screen.
    *   Correct any inaccuracies or populate any missing fields.
    *   **Note:** If a single letter disputes multiple account numbers, ensure a separate dispute is created for each account.
6.  **Finalize Dispute Creation:**
    *   Select the appropriate "Source" of the dispute (e.g., Letter, Email).
    *   Choose the relevant dispute reason(s) from the customizable drop-down list.
    *   Confirm the information to officially create the direct dispute case(s) in the Sonnet system.

**5.2 Processing Verbal Direct Disputes (Phone Call)**

1.  **Data Capture:** During the phone call, capture all necessary dispute details, including consumer identifiers, account number(s), and the specific information being disputed.
2.  **Data Formatting:** Format the captured information according to the "Step 2" data file specifications provided for Sonnet.
3.  **Data Ingestion:** Include the verbal dispute information in the next Step 2 data file submission to Sonnet.
4.  **Source Identification:** When the dispute appears in the Sonnet verification queue, ensure the "Source" is correctly identified as "Verbal."

**5.3 Dispute Investigation and Resolution**

1.  **Monitor Dashboard:** Regularly review the "Direct Dispute Dashboard" to track new disputes, completed disputes, and cases approaching their resolution deadline.
2.  **Adhere to Deadline:** Apply the standard 30-day resolution logic (or other client-specific timeframe) to all direct disputes. The clock starts upon receipt of the dispute.
3.  **Conduct Investigation:** Perform a reasonable investigation into the consumer's claim.
4.  **Update Sonnet:** Document all investigation steps, findings, and the final resolution within the Sonnet case file.
5.  **Communicate Resolution:** Send a response to the consumer as required by policy and regulation.

**6.0 MAINTENANCE OF DISPUTE REASONS**

*   Authorized administrative users are responsible for maintaining the list of direct dispute reasons in Sonnet.
*   This list can be updated as needed to reflect new trends or business requirements. Access this functionality via the administrative settings in Sonnet.
--------------------------------------------------------------------------------
Title: SOP_Sonnet - Product Demo_Training - Part 4 - AI Notes (1).txt
Of course. Here is a Standard Operating Procedure based on the document provided.

***

### **Standard Operating Procedure: Direct Dispute Management in Sonnet**

**SOP Number:** DD-SON-001
**Version:** 1.0
**Effective Date:** [Date]

---

**1.0 PURPOSE**

To establish a standardized process for managing direct consumer disputes from initial receipt through final resolution using the Sonnet platform. This procedure ensures all disputes are handled consistently, accurately, and efficiently, in compliance with operational standards.

**2.0 SCOPE**

This SOP applies to all personnel responsible for the review, investigation, and processing of direct disputes within the Sonnet system. This includes, but is not limited to, dispute resolution specialists and administrative users.

**3.0 DEFINITIONS**

*   **Sonnet:** The software platform for managing consumer disputes.
*   **Direct Dispute:** A dispute initiated directly by a consumer with the data furnisher.
*   **Investigation Tab:** The central hub in Sonnet that houses all direct dispute work queues.
*   **Review Queue:** The initial queue where newly uploaded dispute documents await user validation.
*   **New Queue:** The queue containing disputes that have been confirmed and are ready for initial processing (Step 1).
*   **Active Queue:** The queue containing disputes that are actively under investigation (Step 2).
*   **Suspended Queue:** A holding queue for disputes that lack sufficient information to proceed.
*   **360 View:** A feature that displays all historical transactions for a specific account number within Sonnet.
*   **OCR (Optical Character Recognition):** Technology used to automatically extract text and data from scanned documents.

**4.0 PROCEDURE**

This procedure is divided into five main stages, covering the entire lifecycle of a direct dispute in Sonnet.

**4.1 Stage 1: Initial Triage in the Review Queue**

1.  Navigate to the **Investigation Tab** in Sonnet.
2.  Access the **Review Queue**. This queue contains all newly uploaded dispute documents pending review.
3.  Select and open a dispute. Carefully review the information extracted by the OCR system against the original document image.
4.  Based on the review, determine the appropriate action:
    *   **If information is sufficient and correct:** Click **Confirm Information**. This action formally creates the dispute in Sonnet and moves it to the **New Queue** for the next step.
    *   **If information is insufficient:** Click **Suspend**. This moves the dispute to the **Suspended Queue**, effectively pausing the workflow until additional information can be obtained.

**4.2 Stage 2: Data Validation in the New Queue**

1.  Navigate to the **New Queue** within the **Investigation Tab**.
2.  Open a dispute to begin the data validation process (Step 1).
3.  Verify the accuracy of all data fields, with particular attention to critical identifiers like the **Account Number**.
4.  If any information is incorrect or was not captured properly by OCR, manually edit the field by typing in the correct data.
5.  After making all necessary corrections, click **Update** to save the changes. This ensures the accuracy of the record as it moves forward in the process.

**4.3 Stage 3: Handling "Unable to Locate" Scenarios**

This workflow applies when a dispute document provides a consumer name and address but no identifiable account number.

1.  Using the consumer's name and address, conduct a search within your primary system of record to locate the account.
2.  If the account **cannot be located**:
    *   The dispute will be moved to an **Active Status** within Sonnet, but without an account number linked.
    *   Initiate your business process for consumer outreach. This typically involves sending a letter requesting additional identifying information. The **Mail Merge Report** in Sonnet may be used to help generate this correspondence.

**4.4 Stage 4: Investigation in the Active Queue**

1.  Disputes that have received all necessary preliminary information (Step 2) will appear in the **Active Queue**.
2.  Open a dispute from the queue to begin the full investigation.
3.  Conduct a thorough investigation by reviewing information from:
    *   Your internal system of record.
    *   The **OCR member reviewed** column in Sonnet.
    *   The original dispute documentation.
4.  Use the **Investigation Checklist** (if configured) to ensure all required investigation steps are completed. Mark each item on the checklist as it is finished.
5.  For additional context, access the **360 View** to review all prior transactions and disputes associated with the account number.
6.  Document all findings, actions, and decisions in the **Comments Section**. This creates a clear audit trail for the dispute.

**4.5 Stage 5: Finalization and Response**

1.  Navigate to the **Response Tab** to preview the information that will be included in the final response (Step 3 file/list).
2.  Once the investigation is complete and documented, select the appropriate final action using the **Action Buttons**:
    *   **Review and Complete:** Finalizes the investigation and moves the dispute to the next stage for response generation.
    *   **Send to QA:** Forwards the dispute to a Quality Assurance queue for a secondary review (if applicable to your workflow).
    *   **Save and Exit:** Saves all progress, allowing you to exit the dispute and resume work later.
    *   **Save and Suspend:** Pauses the investigation and moves the dispute to the **Suspended Queue**.

**5.0 SUPPORTING PROCESSES**

*   **Creating Support Tickets:** If a system issue prevents you from processing a dispute (e.g., unable to update a dispute code), create a support ticket. The support team will investigate and communicate updates via email.
*   **Duplicate Dispute Handling:** Be aware that Sonnet does not currently have an automated feature for detecting duplicate direct disputes. Users must manually identify and manage duplicates according to internal business rules.
*   **Administrative Functions:** Authorized administrative users can customize **Direct Responses**, **Reasons**, and the **Investigation Checklist** within the Sonnet administrative settings.

---

**6.0 APPROVALS**

| Name | Title | Signature | Date |
| :--- | :--- | :--- | :--- |
| | [Approver 1 Title] | | |
| | [Approver 2 Title] | | |
--------------------------------------------------------------------------------
Title: SOP_Sonnet - Product Demo_Training - Part 4 - AI Notes.txt
Of course. Here is a professional Standard Operating Procedure (SOP) based on the provided meeting notes.

---

### **Standard Operating Procedure: Direct Dispute Management in Sonnet**

| **SOP ID:** | DD-SON-001 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Effective Date:** | [Date] | **Author:** | Process Excellence |
| **Approved By:** | [Approver Name] | **Review Cycle:** | Annual |

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) outlines the standardized process for managing direct disputes within the Sonnet platform. The procedure covers the entire dispute lifecycle, from initial document review to final resolution, ensuring consistency, accuracy, and efficiency in handling consumer disputes.

### **2.0 Scope**

This SOP applies to all team members and personnel responsible for reviewing, investigating, and resolving direct disputes using the Sonnet system. This includes dispute resolution specialists, quality assurance staff, and administrative users.

### **3.0 Definitions**

*   **Sonnet:** The primary software platform used for managing dispute resolution workflows.
*   **Direct Dispute:** A dispute initiated directly by a consumer with the data furnisher, rather than through a credit reporting agency.
*   **Investigation Tab:** The main workspace within Sonnet that houses all direct dispute queues.
*   **Review Queue:** The initial queue where disputes are held after a document has been uploaded and is pending user review.
*   **New Queue:** The queue where disputes are placed after initial information has been confirmed. Data can be edited in this stage.
*   **Active Queue:** The queue containing disputes that have received all necessary information (Step 2) and are ready for full investigation.
*   **Suspended Queue:** A holding queue for disputes that lack sufficient information to proceed. These are temporarily removed from the active workflow.
*   **OCR (Optical Character Recognition):** Technology used to scan uploaded documents and extract text data.
*   **360 View:** A feature in Sonnet that displays all historical transactions and activities associated with a specific account number.

### **4.0 Procedure: Dispute Processing Workflow**

The direct dispute process is managed through a series of queues located in the **Investigation Tab**.

#### **4.1 Stage 1: Initial Document Review (Review Queue)**

1.  Navigate to the **Investigation Tab** to access all dispute queues.
2.  Open the **Review Queue**, which contains all newly uploaded dispute documents awaiting action.
3.  Review the information extracted from the uploaded document.
4.  Based on the review, select one of the following actions:
    *   **To Confirm the Dispute:** If the information is sufficient to proceed, click **Confirm Info**. This action creates the dispute record in Sonnet and moves it to the **New Queue** for further processing.
    *   **To Suspend the Dispute:** If there is not enough information to proceed, select the option to **Suspend**. This moves the dispute to the **Suspended Queue** and removes it from the primary workflow until more information is available.

#### **4.2 Stage 2: Data Validation and Editing (New Queue)**

1.  Access the **New Queue** within the **Investigation Tab**.
2.  Open a dispute to review its details. This queue is for validating the OCR-extracted data before the investigation begins.
3.  Verify the accuracy of all information, paying special attention to critical data points like account numbers.
4.  If any information is incorrect (e.g., an account number was misread by OCR), manually edit the field by typing in the correct data.
5.  After making any necessary corrections, click **Update** to save the changes. The updated information will be reflected in Sonnet.

#### **4.3 Stage 3: Active Investigation (Active Queue)**

Disputes move to the **Active Queue** after all preliminary information has been validated and the dispute is ready for a full investigation.

1.  Access the **Active Queue** from the **Investigation Tab**.
2.  Open a dispute to begin the investigation.
3.  Utilize the following tools to gather information and assess the dispute:
    *   **System of Record Data:** Review information from the primary system of record, which is integrated with Sonnet.
    *   **OCR Member Reviewed Column:** Cross-reference information reviewed by other team members.
    *   **360 View:** Access the 360 View for the account number to review all related transactions and historical context within Sonnet.
    *   **Investigation Checklist:** Follow the client-specific, customizable checklist to ensure all required investigation steps are completed. Check each box as the corresponding task is finished.
    *   **Comments Section:** Enter detailed, time-stamped comments to document all actions taken, decisions made, and communications related to the dispute. Review historical comments for context.
4.  Once the investigation is complete, refer to the **Response Tab** to preview the information that will be included in the final response file (Step 3).
5.  Select the appropriate final action using the **Action Buttons**:
    *   **Review and Complete:** Finalizes the dispute and forwards it to the next step (e.g., response generation).
    *   **Send to QA:** Forwards the dispute to a Quality Assurance queue for secondary review.
    *   **Save and Suspend:** Moves the dispute to the Suspended Queue if the investigation is blocked.
    *   **Save and Exit:** Saves all current work and exits the dispute, keeping it in the Active Queue.

### **5.0 Special Workflows and Considerations**

#### **5.1 Unable to Locate Workflow**

This workflow is used when a dispute is received with only a consumer's name and address, and no account number can be located.

1.  Attempt to locate the consumer's account in the primary system of record using the provided name and address.
2.  If the account cannot be located, the dispute is moved to an **Active Status** without an account number.
3.  A letter is typically sent to the consumer requesting additional information (e.g., account number, social security number) required to proceed with the investigation. The dispute will await this information.

#### **5.2 Duplicate Dispute Handling**

As of the current version, Sonnet does not have an automated duplicate-checking feature for direct disputes. Users should manually check for potential duplicates during the investigation process. This functionality is a planned future enhancement.

#### **5.3 Creating and Tracking Support Tickets**

If a system issue prevents the processing of a dispute (e.g., unable to update a dispute code, incorrect values), a support ticket must be created.

1.  Select the option to create a **Support Ticket** from within the dispute.
2.  Clearly describe the issue encountered.
3.  The support team will investigate the ticket and respond via email. All updates and communications regarding the ticket will be sent to the user's email address. There is no in-app ticket tracking portal.

### **6.0 Administrative Functions (For Administrative Users Only)**

Administrative users have access to settings to configure and maintain the direct dispute module.

*   **Customization:** Admins can configure and maintain direct dispute **response templates**, **reason codes**, and **investigation checklists**.
*   **OCR Exclusion:** In the **OCR Tab** under admin settings, specific addresses can be excluded from the OCR scanning process to improve accuracy.
*   **Reporting:** The **Mail Merge Report** is a custom report available to help clients generate consumer-facing letters for direct disputes.

---
**End of SOP**
--------------------------------------------------------------------------------
Title: SOP_Sonnet DevOps Sync-20250205_200152-Devops-Recap.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure (SOP) for the code development, merging, and deployment process.

***

### **Standard Operating Procedure: Code Development, Merging, and Deployment**

**SOP ID:** SOP-DEV-001
**Version:** 1.0
**Effective Date:** 2023-10-27
**Author:** Generated based on process review meeting with subject matter expert (Chip).
**Approver:** Head of DevOps

---

### **1.0 Purpose**

This SOP outlines the standardized process for software development, code merging, and deployment to User Acceptance Testing (UAT) and Production environments. The purpose is to ensure code quality, maintain system stability, and provide a clear, repeatable workflow for all development team members.

### **2.0 Scope**

This procedure applies to all developers and DevOps personnel involved in the development and deployment of applications managed within the Azure DevOps environment. It covers the entire lifecycle from local development to production release.

### **3.0 Roles and Responsibilities**

*   **Developer:** Responsible for creating new branches, writing code, creating Pull Requests (PRs), and ensuring their code passes all automated checks.
*   **Code Reviewer:** Responsible for reviewing PRs for quality, correctness, and adherence to standards before approval.
*   **DevOps Team:** Responsible for maintaining the CI/CD pipelines, managing agent pools, provisioning access, and executing manual production deployments.

### **4.0 Definitions**

*   **SonarCloud:** A cloud-based static code analysis service used to detect bugs, vulnerabilities, and code smells. A successful scan is mandatory for security audits.
*   **Azure DevOps Pipeline:** An automated workflow that builds, tests, and deploys code.
*   **Self-Hosted Agent:** A pipeline agent running on company-managed servers within the internal VNet, used instead of Microsoft-hosted agents for security and network access.
*   **Agent Pool:** A collection of self-hosted agents dedicated to a specific environment (e.g., `UAT-Pool`, `PROD-Pool`).
*   **Azure Configurator:** A dedicated repository in Azure DevOps containing scripts for the standardized configuration of servers (e.g., installing Apache, PHP).

---

### **5.0 Procedure: Development to UAT Deployment**

This section describes the standard workflow for getting code from a developer's local machine to the UAT environment.

**5.1 Code Development and Branching**
1.  **Create Branch:** The developer must create a new feature or hotfix branch from the `main` branch in the relevant Git repository.
2.  **Develop Code:** The developer performs all necessary coding and development tasks on this new branch.
3.  **Commit Changes:** Commit changes to the branch with clear, descriptive messages.

**5.2 Code Review and Merge to `main`**
1.  **Create Pull Request (PR):** Once development is complete, the developer creates a PR in Azure DevOps to merge their branch back into the `main` branch.
2.  **Peer Review:** The PR must be reviewed and formally approved by at least one other team member.
3.  **Merge PR:** Upon approval, the developer merges the PR into the `main` branch.

**5.3 Automated Pipeline Execution and UAT Deployment**
1.  **Pipeline Trigger:** The merge to the `main` branch automatically triggers the repository's CI/CD pipeline in Azure DevOps.
2.  **Static Code Analysis:** The pipeline's first major stage executes a static code analysis using SonarCloud.
    *   **NOTE:** A successful SonarCloud scan is a mandatory quality gate required for security audits. A failed scan will halt the pipeline, and the developer must remediate the identified issues.
3.  **Build and Deploy to UAT:** Upon a successful SonarCloud scan, the pipeline proceeds to build the application and deploy it to the UAT environment. The pipeline utilizes a self-hosted agent from the designated UAT agent pool.
4.  **Verification:** The developer and relevant stakeholders must verify the changes in the UAT environment to confirm a successful deployment and functionality.

---

### **6.0 Procedure: Production Deployment (Manual)**

Due to the high frequency of hotfixes and specific customer requests, production deployments are a deliberate, manually-triggered process to ensure maximum control and stability.

1.  **Obtain Approval:** Following successful validation in UAT, a formal request for production deployment must be made and approved by project management or the product owner.
2.  **DevOps Manual Trigger:** The DevOps team will prepare the pipeline for a production run.
    *   **NOTE:** The production deployment stage in the pipeline is typically commented out to prevent accidental deployments. The DevOps team will uncomment or enable this stage for the planned release.
3.  **Execute Production Stage:** The DevOps team manually triggers the production deployment stage of the pipeline. This stage will:
    *   Run on a self-hosted agent from the `prod` agent pool.
    *   Execute the deployment script, which contains error handling and conditional logic for a safe deployment.
4.  **Post-Deployment Verification:** The DevOps team and the requesting developer must immediately verify the application's health and functionality in the production environment.

---

### **7.0 Related Procedures**

The following processes are related to the primary development workflow and are documented separately.

**7.1 Server Configuration (Azure Configurator)**
*   **Purpose:** To configure new servers in a standardized way.
*   **Process:**
    1.  The DevOps team accesses the `Azure Configurator` repository.
    2.  A pipeline is **manually triggered** from this repository.
    3.  During the trigger, the team selects the necessary configuration scripts (e.g., Apache, PHP) and the target server/environment as parameters.
    4.  The pipeline executes the selected scripts on the target server.

**7.2 User Access Provisioning (Azure DevOps & SonarCloud)**
*   **Purpose:** To grant new users access to development tools.
*   **Process:**
    1.  The user or their manager submits a formal access request specifying the required system (Azure DevOps, SonarCloud) and desired permission level.
    2.  The request is reviewed and approved by the DevOps Lead or a designated manager.
    3.  Upon approval, the DevOps team provisions the user account and assigns the appropriate permissions.
    4.  The user is notified once access is granted.
--------------------------------------------------------------------------------
Title: SOP_Sonnet DevOps Sync-20250205_200152-Devops.txt
Of course. Based on the document provided, here is a professional Standard Operating Procedure (SOP).

---

### **Standard Operating Procedure: Sonnet Application CI/CD Pipeline and UAT Deployment**

| **Document ID:** | SOP-DEV-004 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Effective Date:** | [Date] | **Author:** | Process Analyst |
| **Approved By:** | Head of DevOps | **Next Review Date:** | [Date + 1 Year] |

---

### **1.0 Purpose**
The purpose of this document is to outline the standardized procedure for the continuous integration (CI) and automated deployment of the Sonnet application to the User Acceptance Testing (UAT) environment. This process ensures code quality through static analysis and standardizes the deployment methodology.

### **2.0 Scope**
This SOP applies to all development team members and operations personnel involved in the lifecycle of the Sonnet application. It covers the process from the creation of a pull request through the automated deployment to the UAT environment. The manual deployment process to the Production environment is considered out of scope for this document.

### **3.0 Roles and Responsibilities**
*   **Developer:** Responsible for writing code, creating pull requests (PRs) that adhere to requirements, linking PRs to work items, and verifying deployments in UAT.
*   **Reviewer / Approver:** Responsible for reviewing code for quality and functionality and approving valid pull requests.
*   **DevOps Team:** Responsible for maintaining the Azure DevOps pipelines, self-hosted agents, and server environments.

### **4.0 System Overview and Prerequisites**
*   **Source Control:** All application code is managed in Azure DevOps Repos.
*   **Agent Pools:** The CI/CD pipelines utilize self-hosted Linux (Ubuntu Pro) agents organized into environment-specific pools (CQA, Dev, Prod, UAT).
*   **Server Configuration:** Target servers are pre-configured with necessary packages (e.g., Apache, PHP) using scripts from the `Azure Configurator` repository.
*   **Service Account:** The `Sonnet` user account exists on all target servers and is the owner of all application services and files.
*   **Static Analysis:** The SonarCloud environment is integrated into the Azure DevOps pipelines for mandatory static code analysis.

### **5.0 Procedure: From Code to UAT Deployment**
This procedure is initiated when a developer is ready to merge code changes into the `main` branch for UAT testing.

**Step 1: Code Commit and Pull Request (PR) Creation**
1.1. The Developer commits code changes to a feature or bugfix branch.
1.2. The Developer creates a Pull Request (PR) to merge their branch into the `main` branch.
1.3. **Critical:** The PR must be linked to a corresponding work item in Azure DevOps to ensure traceability.

**Step 2: Peer Review and PR Approval**
2.1. Designated Reviewers are automatically assigned to the PR.
2.2. Reviewers assess the code changes for quality, standards, and functionality.
2.3. The PR must receive the required number of approvals before it can be merged.

**Step 3: Pipeline Trigger**
3.1. Upon successful approval, the PR is merged into the `main` branch.
3.2. This merge action automatically triggers the `Sonnet app Main` pipeline.

**Step 4: Pipeline Stage 1 - Build and Static Code Analysis**
4.1. The pipeline job is assigned to an available agent from the appropriate agent pool.
4.2. **SonarCloud Prepare:** The pipeline initiates the connection to SonarCloud and configures the analysis parameters.
4.3. **Build and Analyze:** The application code is built, and SonarCloud performs a static code analysis scan.
4.4. **SonarCloud Publish:** The analysis results are published to the SonarCloud dashboard. The pipeline will only proceed if the code meets the pre-defined quality gates.

**Step 5: Pipeline Stage 2 - Automated Deployment to UAT**
5.1. Upon the successful completion of Stage 1, the pipeline automatically proceeds to the UAT deployment stage.
5.2. The pipeline establishes a secure connection to the UAT server as the `Sonnet` user.
5.3. The pipeline executes the primary deployment script located in the home directory of the `Sonnet` user. This script performs the following sequence of tasks:
    *   Verifies the presence of required access tokens.
    *   Places the Laravel application into maintenance mode (`php artisan down`).
    *   Fetches the latest code version from the repository.
    *   Runs `composer` commands to update backend dependencies.
    *   Runs Laravel `artisan` commands for database migrations, cache clearing, and configuration updates (e.g., `php artisan migrate`, `php artisan cache:clear`).
    *   Applies any required hard-coded configuration changes.
    *   Runs `npm` commands to build front-end assets for production (`npm run prod`).
    *   Brings the application out of maintenance mode (`php artisan up`).

**Step 6: Post-Deployment Verification**
6.1. The Developer or an assigned QA tester accesses the Sonnet application in the UAT environment.
6.2. They perform functional testing to verify that the new changes have been deployed successfully and have not introduced regressions.
6.3. Any issues discovered are documented in a new work item, and the process is repeated.

### **6.0 Notes and Considerations**
*   **Production Deployments:** Deployments to the Production environment are intentionally handled manually. This allows for flexibility in scheduling and accommodating urgent hotfixes or customer requests.
*   **Known Challenges:** The current pipeline utilizes SonarCloud tasks that are marked as deprecated. These are scheduled for a future upgrade.
*   **Future Improvements:** Planned enhancements to this process include upgrading pipeline tasks, improving automated test case integration, and transitioning more build steps into the pipeline agents to create a more comprehensive artifact-based deployment.
--------------------------------------------------------------------------------
Title: SOP_Sonnet DevOps Sync-20250206_205132-DevOpsSetup (1).txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure (SOP) for setting up a new QA or Hotfix environment.

---

### **Standard Operating Procedure: New QA/Hotfix Environment Setup in Azure**

| **SOP ID:** | AZ-ENV-001 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Effective Date:** | [Date] | **Approved By:** | [Approver Name/Title] |
| **Author:** | [Author Name/Title] | **Review Cycle:** | 12 Months |

---

### **1.0 Purpose**

The purpose of this Standard Operating Procedure (SOP) is to provide a standardized, step-by-step process for creating a new, isolated QA (Quality Assurance) or Hotfix environment within the Provana Azure subscription. This procedure ensures that all new environments are provisioned consistently, securely, and configured correctly for application testing and deployment.

### **2.0 Scope**

This SOP applies to all technical personnel responsible for infrastructure management and application deployment. It covers the end-to-end process, including:
*   Provisioning of Azure resources (Resource Group, Virtual Machine, Database).
*   Migration of code repositories from Sonic Azure DevOps to Provana Azure DevOps.
*   Initial deployment of application components (Web App, API, Database).
*   Configuration of security and access controls.

### **3.0 Roles and Responsibilities**

*   **Implementation Engineer:** Responsible for executing the technical steps outlined in this procedure, including resource creation, repository import, and initial deployment.
*   **Senior Engineer / Architect:** Responsible for providing architectural guidance, approving the environment plan, and validating the final setup against requirements.

### **4.0 Prerequisites**

Before beginning this procedure, the following must be in place:
*   Contributor-level access to the target Provana Azure subscription.
*   Administrative credentials for both the source (Sonic) and destination (Provana) Azure DevOps organizations.
*   A clear understanding of the application architecture (web, API, database).
*   Required SSH public keys for secure virtual machine access.
*   Approval from a Senior Engineer/Architect to create the new environment.

---

### **5.0 Procedure**

Execute the following steps sequentially to provision and configure the new environment.

#### **Phase 1: Planning and Preparation**

1.1. **Define Environment Objective:** Clearly establish the purpose of the new environment (e.g., QA for a specific release, Hotfix testing).
1.2. **Confirm Azure Subscription:** Verify that all resources will be created within the **Provana Azure subscription**.
1.3. **Plan Repository Migration:** Identify all required repositories in Sonic Azure DevOps. Develop a plan to migrate them, paying special attention to any in-progress pull requests to avoid work disruption.
1.4. **Strategy for Initial Deployment:** Agree on the deployment method. Per best practices for a new environment, initial setup will involve **running deployment scripts manually from the new server** to ensure control and simplify the setup process.

#### **Phase 2: Azure Infrastructure Provisioning**

2.1. **Create New Resource Group:**
    2.1.1. Log in to the Azure Portal.
    2.1.2. Navigate to **Resource groups** and click **Create**.
    2.1.3. Name the resource group using a standard convention (e.g., `rg-[appname]-[environment]-01`).
    2.1.4. Select the appropriate region.
    2.1.5. Add any required tags and create the resource group.
    *Goal: To logically isolate all resources for the new environment and mimic the structure of existing environments where possible.*

2.2. **Provision Virtual Machine (VM):**
    2.2.1. Within the newly created resource group, create a new Virtual Machine.
    2.2.2. Define the VM specifications (Size, OS Image) based on application requirements.
    2.2.3. During creation, configure the **Administrator account** to use **SSH public key** authentication. Paste the approved public key.
    2.2.4. Configure **Networking**, ensuring the VM is placed in the correct virtual network and subnet.
    2.2.5. Configure the **Network Security Group (NSG)** to allow inbound SSH traffic (port 22) only from approved IP addresses and necessary application traffic (e.g., HTTP/S).

#### **Phase 3: Database Setup**

3.1. **Create New Database Instance:**
    3.1.1. Within the new resource group, provision a new Azure SQL Database or other required database service.
    3.1.2. Configure the server name, administrator login, and password.
    3.1.3. Configure networking rules to allow access from the newly created VM.
3.2. **Deploy Schema and Data:**
    3.2.1. Connect to the new database instance.
    3.2.2. Execute scripts to deploy the master tables and required database schema.
    3.2.3. Execute scripts to populate the database with necessary seed or master data.
    *Goal: To ensure a fresh, clean database state for accurate testing, free from residual data.*

#### **Phase 4: Repository Migration**

4.1. **Navigate to Provana Azure DevOps:** Log in and select the target project.
4.2. **Initiate Repository Import:**
    4.2.1. Go to **Repos** > **Files**.
    4.2.2. Select the repository dropdown and choose **Import a repository**.
4.3. **Configure Import Source:**
    4.3.1. Set the **Source type** to `Git`.
    4.3.2. Enter the **Clone URL** of the source repository from Sonic Azure DevOps.
    4.3.3. Check the **Requires authorization** box and provide credentials for the source repository.
4.4. **Verify and Complete Import:**
    4.4.1. Enter the desired name for the new repository in Provana Azure DevOps.
    4.4.2. **Crucially, ensure all branches are selected for import.**
    4.4.3. Click **Import** and wait for the process to complete.
4.5. **Validate Migration:** After the import is successful, verify that all branches and necessary deployment scripts have been migrated correctly. Repeat for all required repositories.

#### **Phase 5: Application Deployment and Verification**

5.1. **Connect to the New VM:** Use an SSH client and the corresponding private key to connect to the provisioned VM.
5.2. **Deploy Application Components:**
    5.2.1. Clone the newly imported repositories onto the VM.
    5.2.2. Manually execute the deployment scripts as planned in Step 1.4.
    5.2.3. Configure the application and API to connect to the new database instance created in Phase 3.
5.3. **Initial Verification (Smoke Test):**
    5.3.1. Start the application services.
    5.3.2. Perform basic functionality checks to confirm the web application, API, and database are communicating correctly.
    5.3.3. Check application logs for any startup or configuration errors.
5.4. **Handover for Testing:** Once initial verification is successful, formally notify the QA team and other stakeholders that the new environment is ready for comprehensive testing.

---
### **6.0 Revision History**

| Version | Date | Author | Summary of Changes |
| :--- | :--- | :--- | :--- |
| 1.0 | [Date] | [Author Name] | Initial document creation based on meeting discussing new environment setup. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet DevOps Sync-20250206_205132-DevOpsSetup.txt
Of course. Here is a professional Standard Operating Procedure (SOP) based on the provided document.

***

### **Standard Operating Procedure: Establishing a New QA Environment**

**SOP ID:** SOP-ITD-QA-001
**Version:** 1.0
**Effective Date:** October 26, 2023
**Department:** Development / IT Operations

---

**1.0 PURPOSE**

This Standard Operating Procedure (SOP) outlines the process for creating, configuring, and deploying a temporary Quality Assurance (QA) environment. The objective is to establish an isolated and clean environment for testing and knowledge transfer (KT) sessions, distinct from the existing development environment, which contains legacy scripts of unknown purpose.

**2.0 SCOPE**

This procedure applies to all Development and IT team members involved in the setup, deployment, and testing of the web application. The environment will be provisioned within the Provana Azure subscription and will have a lifecycle of approximately one month, after which it will be decommissioned.

**3.0 RESPONSIBILITIES**

| **Role** | **Responsibilities** |
| :--- | :--- |
| **IT Team** | • Provisioning core network infrastructure, including Virtual Network (VNet), subnets, and public IP addresses.<br>• Assisting with security group configurations as required. |
| **Development Team** | • Initiating infrastructure requests with the IT team.<br>• Creating and configuring the Azure Resource Group and Virtual Machine (VM).<br>• Managing repository migration and pull requests.<br>• Setting up the database and deploying data.<br>• Deploying all application components (Web App, API, etc.).<br>• Executing all deployment scripts manually on the server.<br>• Performing initial validation and handing over the environment to the testing team.<br>• Decommissioning the environment upon completion of its purpose. |

**4.0 PREREQUISITES**

*   Authorized access to the Provana Azure subscription with sufficient permissions to create and manage resources.
*   Access to the source "Sonit Azure DevOps" for repository migration.
*   A list of required repositories to be migrated.
*   SSH public keys for all team members requiring server access.

---

**5.0 PROCEDURE**

This procedure is divided into seven phases, from initial infrastructure setup to final validation.

**Phase 1: Infrastructure and Network Setup**

1.1. **Initiate Request:** The Development Team Lead submits a formal request to the IT Team for network infrastructure setup.

1.2. **Create Resource Group:** In the Azure Portal, create a new, public-facing Resource Group to contain all resources for this QA environment.

1.3. **Provision Networking:** The IT Team, in coordination with the Development Team, sets up the following within the new Resource Group:
    *   Virtual Network (VNet)
    *   Associated Subnet(s)
    *   A static Public IP address

**Phase 2: Virtual Machine Provisioning**

2.1. **Create Virtual Machine:** Within the newly created Resource Group, provision a new Virtual Machine with the following specifications:
    *   **Operating System:** Ubuntu Server
    *   **Size:** 2 vCPUs, 8 GB Memory
    *   **Storage:** Standard SSD

2.2. **Network Association:** During creation, associate the VM with the VNet and Subnet created in Phase 1. Assign the static Public IP to the VM's network interface.

**Phase 3: Security and Access Configuration**

3.1. **Configure Network Security Group (NSG):** Create or modify the VM's NSG to allow necessary traffic while maintaining high security.
    *   Create an inbound security rule to allow **SSH** traffic (Port 22) from authorized IP addresses.
    *   Create inbound security rules to allow **HTTP/HTTPS** traffic (Ports 80 and 443).

3.2. **Configure SSH Access:** Set up user access to the VM using public key authentication. Distribute the public IP address and access instructions to authorized personnel.

**Phase 4: Code Repository Migration**

4.1. **Manage Pull Requests:** Before migration, review all open pull requests in the source Sonit Azure DevOps. Ensure they are merged or appropriately handled to prevent code loss.

4.2. **Import Repositories:** Use the Azure DevOps import functionality to migrate the required repositories from the Sonit Azure DevOps instance to the new project environment.

**Phase 5: Database Setup**

5.1. **Provision New Database:** Create a new database server and a clean database within the Resource Group.

5.2. **Deploy Schema and Data:** Treat the environment as a fresh client installation. Deploy the master table schema and seed the necessary master data to the new database.

**Phase 6: Application Deployment and Configuration**

6.1. **Connect to Server:** Access the new VM via SSH using the configured public key.

6.2. **Deploy Components:** Manually execute all deployment scripts directly on the server to deploy the web application, API, and database components. This manual approach avoids the complexity of configuring multiple remote agents.

6.3. **Configure Web Server:** Install and configure the Apache server to host the web application.

6.4. **Finalize Configuration:** Ensure all environment variables and configuration files point to the new database and other services within the QA environment.

**Phase 7: Validation and Handover**

7.1. **Smoke Testing:** The Development Team performs initial smoke tests to verify that the application is running and all components are communicating correctly.

7.2. **Handover:** Once validated, the Development Team provides the environment URL, access credentials, and any relevant documentation to the testing team to begin KT sessions and formal testing activities.

**6.0 DECOMMISSIONING**

Upon completion of the one-month testing and KT period, the Development Team is responsible for deleting the entire Resource Group to ensure no further costs are incurred. All necessary data or logs must be backed up prior to deletion.

---

**7.0 APPROVALS**

| **Name** | **Role** | **Signature** | **Date** |
| :--- | :--- | :--- | :--- |
| | Development Team Lead | | |
| | IT Operations Manager | | |
--------------------------------------------------------------------------------
Title: SOP_Sonnet DevOps Sync-20250206_221415-AzureConfigurator (1).txt
Of course. Based on the document provided, here is a professional Standard Operating Procedure (SOP).

---

### **Standard Operating Procedure: Azure Configurator Environment Setup and Project Migration**

| **SOP ID:** | PROV-DEV-SOP-001 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Department:** | Development / IT Operations | **Effective Date:** | [Date] |
| **Owner:** | Development Lead | **Next Review Date:** | [Date, 1 Year from Effective Date] |

### **1.0 Purpose**

This Standard Operating Procedure (SOP) outlines the required steps for setting up a local development environment for the **Azure Configurator** project. The procedure details the migration of the project from the legacy "Sonnet" repository to the current "Provana" system, including environment configuration, code cloning, and server setup.

### **2.0 Scope**

This SOP applies to all development and operations team members involved in the setup, migration, and maintenance of the Azure Configurator project. This includes initial environment configuration for new team members and standardized migration tasks.

### **3.0 Responsibilities**

*   **Developer (e.g., Vandana):** Responsible for performing the initial environment setup, configuring repositories, cloning the project, and standardizing the branch structure.
*   **Lead Developer (e.g., Chip, Liddy):** Responsible for advanced Apache web server configuration and providing technical oversight and support during the setup process.
*   **System Administrator (e.g., Praveen, Chip):** Responsible for granting user access to necessary platforms, including the Azure Portal and SharePoint, upon request.

### **4.0 Prerequisites**

Before beginning this procedure, the following access and software must be in place:

*   **4.1 Azure Portal Access:** The developer must have appropriate permissions within the organization's Azure tenant.
    *   **Action:** If access is not already granted, raise an access request with the System Administrator (Praveen).
*   **4.2 Required Software:** The following tools must be installed on the developer's workstation:
    *   PowerShell
    *   Bitwise SSH Client (or equivalent)
*   **4.3 SharePoint Access (If Applicable):** For team members requiring access to billing files (e.g., Chandan), access to the designated SharePoint site must be obtained.
    *   **Action:** Request access and the specific URL from the administrator (Chip).

### **5.0 Procedure**

Execute the following steps in sequence to ensure a correct and standardized environment setup.

**Step 1: Prepare the Local Environment**

1.1. **Verify PHP Version:** Ensure the local environment is running **PHP version 8.2**. If the current version is older (e.g., 7.4), perform an upgrade.
1.2. **Open PowerShell:** Launch a PowerShell terminal with administrative privileges to execute the necessary commands.

**Step 2: Configure Repositories and Clone Project**

2.1. **Configure Git:** Set up the local Git configuration to connect to the "Provana" repository system.
2.2. **Clone Project:** Execute the `git clone` command to copy the complete "Azure Configurator" project from the "Sonnet" source repository to the local "Provana" environment setup.
    *   **Responsibility:** Developer

**Step 3: Standardize the Default Branch**

3.1. **Navigate to Project Directory:** Open a terminal in the root directory of the newly cloned project.
3.2. **Rename Branch:** To avoid confusion and align with modern standards, rename the default branch from `master` to `main`.
    *   Execute the command: `git branch -m master main`
3.3. **Push the New Branch:** Push the new `main` branch to the remote repository and set it as the upstream branch.
    *   Execute the command: `git push -u origin main`
3.4. **Update Default Branch on Remote:** Log in to the Git hosting platform and set `main` as the default branch for the repository.
3.5. **Remove Old Branch (Optional but Recommended):** Once the new `main` branch is confirmed as the default, delete the old `master` branch from the remote repository.
    *   Execute the command: `git push origin --delete master`
    *   **Responsibility:** Developer

**Step 4: Configure Apache Web Server**

4.1. **Enable Required Modules:** Access the Apache configuration files and enable all modules required for the Azure Configurator application to function correctly.
4.2. **Run Configuration Commands:** Execute any necessary scripts or commands to apply the configuration settings.
4.3. **Encryption Server Configuration:** Be aware that certain configurations may require a connection to a designated encryption server. Ensure credentials and connectivity are established as needed.
    *   **Responsibility:** Lead Developer (Chip, Liddy)

**Step 5: Verification**

5.1. **Developer Verification:** The developer confirms that the project has been successfully cloned, all files are present, and the default branch is correctly set to `main`.
5.2. **Lead Developer Verification:** The lead developer confirms that the Apache server is configured correctly and the Azure Configurator application loads without errors in the local environment.

### **6.0 Definitions**

*   **Sonnet:** The legacy system or code repository where the project was previously hosted.
*   **Provana:** The current target system and repository environment for the project.
*   **Azure Configurator:** The name of the software project being migrated and configured.

---
--------------------------------------------------------------------------------
Title: SOP_Sonnet DevOps Sync-20250206_221415-AzureConfigurator.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure (SOP) for the described process.

---

### **Standard Operating Procedure: Initial Setup of Azure Web Server (Apache & PHP)**

| | |
| :--- | :--- |
| **SOP ID:** | SOP-TECH-AZURE-001 |
| **Version:** | 1.0 |
| **Effective Date:** | [Date] |
| **Title:** | Initial Setup of Azure Web Server (Apache & PHP) in the Provana Environment |
| **Owner:** | Technical Operations Lead |
| **Approver:** | Head of Engineering |

### **1.0 Purpose**

The purpose of this document is to provide a standardized process for the initial setup of a new web server within the Provana Azure development and test subscription. This procedure covers the installation and basic configuration of Apache and PHP 8.2, server access, and the initial project code deployment. This SOP is established to ensure a consistent and repeatable setup, following the decision to perform a fresh installation rather than migrating resources from the Sonnet environment.

### **2.0 Scope**

This SOP applies to all technical staff, including System Administrators and Developers, involved in provisioning and configuring new web server environments in Azure. This procedure covers the steps from initial server connection to the point where the default Apache web page is accessible and the project repository is cloned. It does not cover final, application-specific Apache configurations, which are designated as a follow-on procedure.

### **3.0 Roles and Responsibilities**

*   **System Administrator (e.g., Chip):** Responsible for leading the server-side setup, including OS-level configuration, software installation (Apache, PHP), and providing access credentials and guidance to the development team.
*   **Developer (e.g., Vandana):** Responsible for configuring necessary repositories, cloning the project code onto the new server, and performing initial verification of the environment.
*   **Senior Engineer / Specialist (e.g., Liddy):** Responsible for assisting with advanced and final application-specific configurations after the initial setup is complete.
*   **Stakeholder (e.g., Praveen):** Provides guidance on Azure subscription policies, permissions, and high-level architectural decisions.

### **4.0 Prerequisites**

Before initiating this procedure, ensure the following are in place:
*   A new virtual machine has been provisioned in the Provana dev and test Azure subscription.
*   All necessary permissions to access and configure the Azure resources have been granted.
*   The assigned personnel have access to a workstation with the following tools installed:
    *   PowerShell
    *   An SSH client (e.g., Bitwise SSH Client)
    *   Azure CLI (optional, but recommended)
*   Access credentials (e.g., SSH key or password) for the new server are available.

### **5.0 Procedure**

**5.1. Server Connection**
1.  Launch the preferred SSH client (e.g., PowerShell with SSH command or Bitwise SSH Client).
2.  Use the provided IP address and credentials to establish a secure connection to the newly provisioned Azure server.

**5.2. System and Software Installation**
1.  **Configure System Repositories:** Update the server's package manager and configure the necessary third-party repositories required for the installation of PHP 8.2.
    *   **Note:** This step is critical and may present challenges. Verify repository sources before proceeding.
2.  **Install Apache Web Server:** Use the system's package manager to install the Apache web server (`httpd`).
3.  **Install PHP:** Install PHP version 8.2 and all required PHP modules for the project.
4.  **Start and Enable Services:** Start the Apache service and enable it to launch automatically on system boot.

**5.3. Initial Verification**
1.  Confirm that the Apache service is running without errors.
2.  Open a web browser and navigate to the public IP address of the Azure server.
3.  **Verification Checkpoint:** The default Apache test page must be displayed. This confirms that the web server is installed correctly and is accessible from the internet.

**5.4. Project Code Deployment**
1.  The assigned Developer will navigate to the web root directory (e.g., `/var/www/html`).
2.  Clone the project source code from the Sonnet application Git repository to the server.
3.  **Important Note on Branching:** The source repository's default branch is `master`, not `main`. Ensure all `git clone` and subsequent `git pull` commands explicitly target the `master` branch to avoid errors. A separate task should be logged to standardize the default branch name to `main` in the future.

### **6.0 Next Steps / Follow-on Procedures**

Upon successful completion of this SOP, the environment is ready for final configuration.
1.  The System Administrator (Chip) will collaborate with the Senior Engineer (Liddy) to finalize the advanced Apache configurations specific to the application.
2.  The Developer (Vandana) will proceed with any application-level setup required after the code has been cloned.

### **7.0 Revision History**

| Version | Date | Author | Change Description |
| :--- | :--- | :--- | :--- |
| 1.0 | [Date] | [Author Name] | Initial document creation based on meeting of [Meeting Date]. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet Domain Training-20250203_111108-Overview-Recap.txt
Of course. Based on the document provided, here is a professional Standard Operating Procedure for the dispute investigation process using the Sona platform.

***

### **Standard Operating Procedure: Sona System Dispute Investigation and Resolution**

**SOP ID:** Sona-INV-001
**Version:** 1.0
**Effective Date:** [Date]
**Approved By:** [Approver Name, Title]

---

### 1.0 Purpose

The purpose of this Standard Operating Procedure (SOP) is to establish a standardized, compliant, and efficient process for managing and resolving consumer credit disputes using the Sona platform. This procedure ensures that all investigations are conducted in accordance with client-specific policies, regulatory requirements (such as the FCRA), and internal quality standards.

### 2.0 Scope

This SOP applies to all Compliance Officers, Dispute Investigators, and authorized personnel responsible for processing, investigating, and responding to consumer credit disputes within the Sona system. This procedure covers the handling of both indirect disputes (ACDVs) and direct disputes.

### 3.0 Definitions

*   **Sona:** An integrated software solution for managing dispute investigations by consolidating information from various systems of record.
*   **System of Record (SoR):** The primary source system containing account information, such as Oscar.
*   **Indirect Dispute (ACDV):** An Automated Consumer Dispute Verification received electronically from a credit reporting agency (bureau).
*   **Direct Dispute:** A dispute received directly from a consumer or their representative via channels such as mail, email, or phone.
*   **Credit Repair Organization (CRO):** A third-party organization that submits disputes on behalf of consumers.
*   **Rules Engine:** The automated logic within Sona that applies client-specific policies and procedures to incoming disputes to determine a course of action.
*   **Auto-Response:** An automated resolution and response to a dispute generated by the Sona Rules Engine without manual intervention.
*   **FCRA:** The Fair Credit Reporting Act, a federal law that regulates credit reporting agencies and compels them to ensure the accuracy, fairness, and privacy of the information in consumer credit files.

### 4.0 Responsibilities

*   **Dispute Investigators:** Responsible for the manual review, investigation, and resolution of disputes routed to their work queue. They must adhere to the customized investigation checklist and document their findings accurately in Sona.
*   **Compliance Manager / System Administrator:** Responsible for configuring and maintaining client-specific business rules, checklists, and response templates within Sona. They also oversee the quality control validation process for auto-responses.

### 5.0 Procedure

This process outlines the end-to-end handling of a dispute from intake to final resolution within the Sona platform.

#### **5.1 Dispute Intake and Initial Processing**

1.  **Dispute Reception:** Sona ingests disputes from two primary sources:
    *   **Indirect Disputes (ACDVs):** Received automatically from credit bureaus and populated into the system.
    *   **Direct Disputes:** Received via mail, email, or other channels. Physical documents are scanned and processed using Optical Character Recognition (OCR) to extract relevant data and create a case in Sona.

2.  **Data Integration:** Upon intake, Sona automatically consolidates all relevant information for the disputed account, pulling data and associated images from integrated Systems of Record (e.g., Oscar).

#### **5.2 Automated Processing (Rules Engine)**

1.  **Rule Application:** The Sona Rules Engine automatically analyzes the incoming dispute and associated account data against predefined, client-specific policies.
2.  **Auto-Response Determination:** Based on the rule evaluation, the system determines if the dispute meets the criteria for an automated response.
3.  **Action Path:**
    *   **If Auto-Response Criteria are Met:** Sona automatically generates and sends the appropriate response, resolving the dispute without human intervention. The case is logged as resolved.
    *   **If Auto-Response Criteria are Not Met:** The dispute is automatically routed to the manual investigation queue for review by a Dispute Investigator.

#### **5.3 Manual Investigation Procedure**

1.  **Access Dispute:** The Dispute Investigator accesses an assigned dispute from their work queue in Sona.
2.  **Review Case File:** The investigator conducts a thorough review of all information consolidated within the Sona case file, including:
    *   The original dispute letter/request.
    *   Account information from the System of Record.
    *   Associated images and supporting documents.
3.  **Follow Investigation Checklist:** The investigator must complete the client-specific investigation checklist presented within the Sona interface. Each item on the checklist must be addressed to ensure a complete and compliant investigation.
    *   **Note:** Future system enhancements may automate the completion of certain checklist items based on data entered in other fields.
4.  **Special Handling for CRO Letters:** For disputes submitted by Credit Repair Organizations, the investigator must follow the client-specific policy. This may involve treating the dispute as a standard direct dispute or handling it according to other established guidelines.
5.  **Determine Outcome:** Based on the evidence, the investigator determines the outcome of the dispute (e.g., delete, modify, or verify account information).
6.  **Formulate Response:** The investigator selects and customizes the appropriate response from a pre-approved list of templates based on the dispute reason and investigation outcome.
7.  **Finalize and Close:** The investigator saves the investigation findings, finalizes the response, and closes the case in Sona. The system will log all actions and generate notifications to bureaus if changes to a trade line are required.

#### **5.4 Quality Control and Validation**

1.  **Queue for Validation:** A statistically significant percentage of auto-responded cases are automatically placed back into a dedicated validation queue.
2.  **Manual Review:** A Dispute Investigator or Compliance Manager reviews the validation case to confirm the accuracy of the Sona Rules Engine's decision.
3.  **Confirmation:**
    *   **If Accurate:** The case is approved and closed.
    *   **If Inaccurate:** The reviewer overturns the automated decision, processes the dispute manually, and provides feedback for refining the Rules Engine to prevent future errors.

### 6.0 References

*   Fair Credit Reporting Act (FCRA) Documentation
*   Consumer Data Industry Association (CDIA) Guidelines
*   Client-Specific Dispute Resolution Policies and Procedures Manual
--------------------------------------------------------------------------------
Title: SOP_Sonnet Domain Training-20250203_111108-Overview.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure (SOP) for the described process.

***

### **Standard Operating Procedure: Direct Dispute Investigation Using the Sona Platform**

| **SOP ID:** | INV-SONA-001 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Department:** | Dispute Resolution / Compliance | **Effective Date:** | October 26, 2023 |
| **Author:** | Compliance Department | **Approved By:** | [Approval Authority Name] |

---

### **1.0 Purpose**

The purpose of this Standard Operating Procedure (SOP) is to establish a standardized, compliant, and efficient process for investigating and responding to direct consumer disputes using the Sona platform. This procedure ensures that all investigations are thorough, leverage Sona's integrated data capabilities, and adhere to company policies and regulatory requirements.

### **2.0 Scope**

This SOP applies to all personnel, including Investigation Analysts and other designated staff, responsible for receiving, investigating, and resolving direct disputes submitted by consumers to the data furnisher.

### **3.0 Definitions**

*   **Sona:** The primary investigation platform designed as an all-in-one solution. It integrates information from multiple Systems of Record (SORs) to streamline the dispute resolution process.
*   **Direct Dispute:** A dispute concerning the accuracy of furnished information that is submitted directly to the data furnisher by a consumer via letter, phone call, email, web portal, or other means.
*   **System of Record (SOR):** A data management system that is the authoritative source for a particular data element. Sona integrates with multiple SORs, including a specific fourth system used to gather supplementary information like images and validation documents.
*   **Rules Engine:** An automated component within Sona that processes case information against pre-defined company policies and procedures to determine outcomes or formulate responses.
*   **Validation Documents:** Supporting evidence, such as account statements, signed agreements, or review letters, used to verify the accuracy of the information under investigation.
*   **Frivolous Dispute:** A dispute submitted by a consumer that is determined to be substantively the same as a previously submitted dispute with no new information, or one that is otherwise deemed meritless according to company policy.

### **4.0 Responsibilities**

*   **Investigation Analyst:** Responsible for executing the steps outlined in this SOP, conducting thorough investigations, utilizing Sona features, and ensuring timely resolution of disputes.
*   **System Administrator:** Responsible for the back-end configuration of Sona, including the customization of dispute reasons and response templates as per business requirements.
*   **Compliance Manager:** Responsible for overseeing the dispute resolution process, defining policies enforced by the Rules Engine, and ensuring adherence to this SOP.

### **5.0 Procedure: Investigating a Direct Dispute**

This procedure outlines the end-to-end process from dispute intake to resolution within the Sona platform.

**Step 1: Dispute Intake and Case Creation**
1.1. Upon receipt of a direct dispute from a consumer, a new investigation case shall be initiated in the Sona platform.

**Step 2: Automated Information Aggregation**
2.1. Once a case is created, Sona will automatically import and consolidate all relevant information from its integrated Systems of Record (e.g., Oscar, the fourth SOR, etc.).
2.2. This aggregated data includes primary and secondary account information, transaction history, customer communications, validation documents, and relevant images.

**Step 3: Initial Review and Rules Engine Application**
3.1. The Investigation Analyst shall perform an initial review of the consolidated case file within Sona.
3.2. Sona's Rules Engine will automatically process the data against established company policies. The engine may suggest a resolution, flag the case for specific review, or auto-generate a preliminary response.

**Step 4: Manual Investigation and Checklist Adherence**
4.1. The Investigation Analyst must follow the client-specific **Investigation Checklist** presented within the Sona interface for the specific dispute type.
4.2. The Analyst will thoroughly review all information and validation documents provided by Sona to assess the merit of the consumer's claim.
4.3. If necessary, the Analyst shall gather any additional validation documents required to complete the investigation.
4.4. The Analyst must complete all required items on the checklist to ensure all procedural steps have been followed before moving to the next stage.

**Step 5: Determine Investigation Outcome**
5.1. Based on the evidence, the Analyst will determine the outcome of the investigation (e.g., information verified as accurate, information requires modification/deletion, etc.).
5.2. **Handling Frivolous Disputes:** If the dispute is identified as frivolous (e.g., a repeated, identical claim from the same consumer), the Analyst shall follow the company's specific policy for handling such disputes. This may include categorizing the dispute as frivolous within Sona and closing the case without a response, as per policy.

**Step 6: Formulate and Generate Response**
6.1. The Analyst will document the final investigation findings and resolution within Sona.
6.2. Utilize Sona's tools to formulate the official response letter to the consumer. The system may provide standardized templates or auto-formulated text based on the Rules Engine and investigation outcome.
6.3. *Future State:* The Sona platform will be used to generate the final response letter and automatically append all relevant validation documents, creating a complete response package ready for printing and mailing.

**Step 7: Finalize and Close Case**
7.1. Send the finalized response letter and any required validation documents to the consumer.
7.2. Update the case status in Sona to "Closed" or the appropriate final status.
7.3. If the investigation results in a change to the consumer's data, ensure the necessary updates are made in the source SOR. Sona will manage relevant notifications (e.g., ADR, AUD) to credit bureaus as needed to update trade lines.

### **6.0 Sona Platform Customization**

System Administrators with appropriate permissions can customize aspects of the Sona platform to align with evolving business needs. This includes:
*   Adding, modifying, or removing dispute reasons from dropdown menus.
*   Creating or editing standardized response letter templates.
*   Configuring the Investigation Checklist with client-specific steps.

### **7.0 Revision History**

| **Version** | **Date** | **Author** | **Summary of Changes** |
| :--- | :--- | :--- | :--- |
| 1.0 | 10/26/2023 | Compliance Department | Initial document creation. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT - Direct Response, Mail Merge-20250210_093924-Recap.txt
Of course. Based on the document provided, here is a professional Standard Operating Procedure (SOP) for the process described.

***

### **Standard Operating Procedure: Generating Direct Dispute Response Letters via Manual Mail Merge**

**SOP ID:** CDR-MM-001
**Version:** 1.0
**Effective Date:** [Date]
**Department:** Client Operations / Compliance

---

#### **1.0 Purpose**
To provide a standardized, temporary procedure for clients to generate direct dispute response letters using a downloadable system report and the mail merge functionality in Microsoft Word. This process serves as an interim solution until the fully automated letter generation module is implemented.

#### **2.0 Scope**
This SOP applies to all clients and internal support staff responsible for generating and sending direct dispute response letters. It covers the process from downloading the necessary data report to finalizing the letters for distribution.

#### **3.0 Prerequisites**
*   Active user credentials with permissions to access and download reports from the system.
*   A computer with a licensed version of Microsoft Word installed.
*   A pre-approved direct dispute response letter template in Microsoft Word format (.docx), containing the necessary mail merge placeholder fields.

#### **4.0 Procedure**

**Step 1: Download the Direct Dispute Data Report**
1.1. Log into the system using your authorized credentials.
1.2. Navigate to the main dashboard or reporting section.
1.3. Locate and select the report containing the necessary data for direct dispute responses.
1.4. Download the report. Ensure the file is saved in a compatible format for mail merge (e.g., .csv or .xlsx) to a known location on your computer.

**Step 2: Prepare the Mail Merge in Microsoft Word**
2.1. Open the approved Microsoft Word letter template for direct dispute responses.
2.2. Navigate to the **Mailings** tab in the Word ribbon.
2.3. Click **Select Recipients** and choose **Use an Existing List…**.
2.4. In the file browser, navigate to the location where you saved the data report in Step 1.4, select the file, and click **Open**.
2.5. If prompted (e.g., for an Excel file with multiple sheets), select the correct worksheet containing the dispute data and click **OK**.

**Step 3: Map Data Fields and Preview Results**
3.1. Review the letter template to ensure all placeholder fields (e.g., `<<Client_Name>>`, `<<Address>>`, `<<Dispute_Details>>`) are present.
3.2. If a field is missing, place your cursor at the desired location in the document. Click **Insert Merge Field** from the **Mailings** tab and select the corresponding column header from your data report.
3.3. Click the **Preview Results** button in the **Mailings** tab to verify that the data from the report is populating the letter template correctly.
3.4. Use the arrow icons next to **Preview Results** to cycle through several records to check for formatting errors or data misalignment.

**Step 4: Finalize and Generate Letters**
4.1. Once you have confirmed the data is populating correctly, perform any final, necessary manual modifications to the letters as needed.
4.2. In the **Mailings** tab, click **Finish & Merge**.
4.3. Select one of the following options based on your requirement:
    *   **Edit Individual Documents…:** To generate a new Word document containing all the merged letters. This allows for a final review and saving as a single file. (Recommended)
    *   **Print Documents…:** To send the merged letters directly to your printer.
4.4. If you selected "Edit Individual Documents…", a new Word document will open. Review the generated letters for accuracy one last time.

**Step 5: Save and Distribute**
5.1. Save the final, merged Word document to a secure location, following your organization's file naming conventions.
5.2. Distribute the letters to the recipients via the appropriate channel (e.g., print and mail).

#### **5.0 Notes and Considerations**
*   This manual mail merge process is a **temporary solution**. Future development is planned for a fully integrated letter generation service that will automate this process.
*   It is critical to use only the company-approved letter templates to ensure compliance and consistent branding.
*   All generated letters and the source data report should be handled as confidential information and stored securely.
*   This SOP will be deprecated upon the successful implementation and launch of the automated letter generation module.

---

#### **6.0 Approval**

| **Role** | **Name** | **Signature** | **Date** |
| :--- | :--- | :--- | :--- |
| **Author** | | | |
| **Manager, Client Ops** | | | |
| **Head of Compliance** | | | |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT - Direct Response, Mail Merge-20250210_093924.txt
Of course. Based on the provided meeting notes, here is a professional Standard Operating Procedure (SOP) for the current letter generation processes.

***

### **Standard Operating Procedure: Letter Generation and Distribution**

**SOP ID:** LG-2023-01
**Version:** 1.0
**Effective Date:** [Date]
**Process Owner:** Operations/Client Services
**Approved By:** [Approver's Name/Title]

---

**1.0 Purpose**

This document outlines the standard procedures for generating and distributing client-facing letters following a direct dispute. It covers both the automated system process and the current manual workaround for mail merge functionality to ensure consistent and accurate client communication.

**2.0 Scope**

This SOP applies to all personnel and system processes involved in handling direct dispute responses and client letter generation. It details two distinct workflows:
*   **Procedure A:** The automated system response to a direct dispute.
*   **Procedure B:** The manual client process for generating letters using mail merge.

**3.0 Definitions**

*   **Direct Dispute:** A process initiated by a user to dispute information directly with the entity that furnished the information.
*   **API (Application Programming Interface):** A software intermediary that allows two applications to talk to each other.
*   **FTP (File Transfer Protocol):** A standard network protocol used for the transfer of computer files between a client and server on a computer network.
*   **Mail Merge:** A software function that allows a user to create personalized documents (e.g., letters) by combining a template with data from a source file (e.g., a spreadsheet or report).

---

**4.0 Procedure A: Automated Direct Dispute Response Letter Generation (System Process)**

This procedure describes the system's automated workflow when a user completes a direct dispute.

| Step | Action | Responsibility | Details |
| :--- | :--- | :--- | :--- |
| **4.1** | User Completes Direct Dispute | User | The process is initiated upon the successful submission of a direct dispute within the system. |
| **4.2** | System Generates Response Letter | System | The system automatically selects the appropriate template and generates a response letter based on the outcome of the dispute. |
| **4.3** | System Transmits Letter File | System | The generated letter file is delivered to the client's designated endpoint via API or a secure FTP drop. |
| **4.4** | Client Manages Mailing | Client | The client is responsible for retrieving the letter file from their system and handling the physical or electronic mailing to the end recipient. The internal system does not perform the final mailing. |

**5.0 Procedure B: Manual Client Letter Generation (Mail Merge Workaround)**

This procedure is a temporary solution for clients who utilize Microsoft Word for letter generation.

| Step | Action | Responsibility | Details |
| :--- | :--- | :--- | :--- |
| **5.1** | Download Data Report | Client | The client downloads the relevant data report from the system. This report contains the necessary data fields for the mail merge. |
| **5.2** | Customize Report (Optional) | Client | If required, the client modifies the downloaded report (e.g., in Microsoft Excel) to add, remove, or format data to meet their specific business or compliance needs. |
| **5.3** | Perform Mail Merge | Client | The client opens their master letter template in Microsoft Word and uses the mail merge function, linking the customized report from Step 5.2 as the data source. |
| **5.4** | Review and Finalize | Client | The client reviews the merged documents for accuracy and completeness. |
| **5.5** | Distribute Letters | Client | The client prints and mails or electronically distributes the finalized letters to the end recipients. |

---

**6.0 Additional Context & Future Development**

For informational purposes, the following initiatives are planned or in development and are expected to supersede or enhance the procedures outlined above:

*   **Dedicated Letter Generation Module:** A new, dedicated service for letter generation is in the development pipeline. This module aims to replace the manual mail merge workaround (Procedure B) by creating letters based on client responses directly within the system.
*   **Enhancement of Direct Response Codes:** Work to elevate the functionality and scope of direct response codes is in the development backlog.
*   **Local Environment Setup Documentation:** A process for setting up a local environment for troubleshooting and service replication is being established and will be documented separately.

---
**End of Document**
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT - Direct Services-20250210_073324-Recap.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure for setting up the local development environment.

---

### **Standard Operating Procedure: Local Development Environment Setup**

**SOP ID:** SOP-DEV-001
**Version:** 1.0
**Effective Date:** [Date]
**Author:** [Your Name/Department]
**Approved By:** Project Lead

---

**1.0 Purpose**

This Standard Operating Procedure (SOP) provides a standardized procedure for all development team members to set up their local development environment. The objective is to ensure consistency across all local instances, minimize setup errors, and streamline the onboarding process for new developers.

**2.0 Scope**

This procedure applies to all developers involved in the project. It covers the initial software installation, configuration, and database setup on a local machine. This SOP supersedes any previous informal setup instructions.

**3.0 Prerequisites**

Before beginning this procedure, the developer must have:
*   Administrative privileges on their local machine to install software.
*   Access to the project's source code repository.
*   Obtained the required configuration files (`.env`, `homestead.yml`) through the official software whitelisting and approval process.

**4.0 Procedure**

Follow these steps sequentially to ensure a correct and consistent setup.

**Step 4.1: Source Code Checkout**
1.  Clone the project repository to your local machine using Git.
2.  Navigate into the newly created project directory.

**Step 4.2: PostgreSQL Installation**
1.  Download the appropriate installer for PostgreSQL for your operating system.
2.  Install PostgreSQL directly on your local operating system.
    *   **CRITICAL NOTE:** Do **NOT** install PostgreSQL within the Vagrant virtual machine. The database instance must run on your local host machine.
3.  During installation, set a secure password for the default `postgres` user. Document this password for use in the configuration step.
4.  After installation, verify that the PostgreSQL service is running on your local machine.

**Step 4.3: Database Setup and Data Import**
1.  **Obtain Database Backup:** Contact **Luis** to acquire a copy of the most recent database backup file. This backup contains the necessary data for development and testing. The current shared backup is nearly empty and should not be used.
2.  **Create Local Database:** Using a database management tool (e.g., pgAdmin, DBeaver) or the command-line interface (`psql`), create a new, empty database for the project.
3.  **Manual Data Import:** Manually import the data from the backup file obtained in Step 4.3.1 into the newly created database.
    *   **NOTE:** This manual import process is the standard for initial setup. Automated database migration scripts are not to be used for this purpose.
    *   Example command: `psql -U <username> -d <database_name> -f <path_to_backup_file.sql>`

**Step 4.4: Environment Configuration**
1.  Place the whitelisted `.env` and `homestead.yml` files (obtained as per Section 3.0) into the root directory of the project.
2.  Open the `.env` file in a text editor.
3.  Update the following database connection variables to match the credentials of your local PostgreSQL instance configured in Step 4.2:
    *   `DB_CONNECTION=pgsql`
    *   `DB_HOST=127.0.0.1`
    *   `DB_PORT=5432`
    *   `DB_DATABASE=`[The name of the database you created in Step 4.3.2]
    *   `DB_USERNAME=`[Your PostgreSQL username]
    *   `DB_PASSWORD=`[The password you set in Step 4.2.3]

**5.0 Verification**

To confirm the environment is set up correctly:
1.  Launch the application using the standard startup command.
2.  Navigate to the application in your web browser.
3.  Verify that you can log in and that the application displays data populated from the imported database backup.
4.  Check application logs for any database connection errors. A successful setup will have no connection errors.

**6.0 Additional Information**
*   **Documentation:** A detailed document for software installation, specific to Windows machines, is under development and will be linked here upon completion.
*   **Alternative Tools:** For future needs, tools such as Laravel and DB Gene may be considered for database management. However, the procedure outlined in this SOP is the current standard.
*   **Team Processes:** This SOP is for technical setup. All team members are reminded to participate in Daily Standups and Sprint Planning sessions as scheduled. Please check with the project lead (Chandan/Lidiexy) regarding meeting times.

**7.0 Revision History**

| Version | Date | Author | Change Description |
| :--- | :--- | :--- | :--- |
| 1.0 | [Date] | [Your Name] | Initial document creation based on meeting discussions. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT - Direct Services-20250210_073324.txt
Of course. Here is a professional Standard Operating Procedure based on the provided document.

***

### **Standard Operating Procedure: Local Development Environment Setup**

**SOP ID:** DEV-ENV-001
**Version:** 1.0
**Effective Date:** [Date]
**Author:** SOP Generator
**Approved By:** [Approver's Name/Title]

---

**1.0 PURPOSE**

This Standard Operating Procedure (SOP) outlines the standardized, step-by-step process for developers to configure a local development environment. The procedure ensures consistency in setup, configuration, and database management across the team.

**2.0 SCOPE**

This SOP applies to all development team members responsible for setting up and maintaining a local instance of the application for development and testing purposes.

**3.0 PREREQUISITES**

Before proceeding with this SOP, ensure the following prerequisite is met:

*   **Initial Software Installation:** All required software (e.g., Git, Vagrant, PHP, Composer) must be installed on the local machine.
    *   **Action:** Refer to the `README.md` file in the main project repository for detailed instructions on installing the necessary base software.

**4.0 PROCEDURE**

Follow these steps sequentially to configure the local environment.

**4.1 Step 1: Install Local Services**

1.  Install the required services for the project, including PostgreSQL and Redis.
2.  **Recommendation:** It is highly recommended to use a local development tool like **DBngin** to simplify the installation and management of these services.

**4.2 Step 2: Set Up the Project Database**

This project utilizes a manual database import process. Automated migration scripts are not used.

1.  **Obtain Database Backup:** Contact **Luis** to request a copy of the most recent database backup. This backup contains a more complete dataset than the version currently in the repository.
2.  **Import Database:** Manually import the provided database backup file into your local PostgreSQL instance.

**4.3 Step 3: Configure Application Environment**

The application's configuration is managed through two primary files.

1.  Locate the following configuration files in the project root:
    *   `.env`
    *   `homestead.yml`
2.  Open the `.env` file to configure the database connection settings.
3.  In the database host/IP address field (e.g., `DB_HOST`), enter the IP address that is assigned in your **Vagrant configuration**. This ensures the application can connect to the local PostgreSQL instance running on your machine.
4.  Review and adjust any other necessary environment variables in the `.env` and `homestead.yml` files as needed for your local setup.

**4.4 Step 4: Verify the Setup**

1.  Run the necessary commands to start your local environment (e.g., `vagrant up`).
2.  Access the application through your web browser or API client.
3.  Verify that the application loads correctly and is successfully connected to the local database by checking for data that was present in the imported backup.

**5.0 SUPPORTING INFORMATION & NOTES**

*   **Configuration Files:** No additional XML or other configuration files are required for this setup beyond `.env` and `homestead.yml`.
*   **Database Management:** All database schema and seed data updates are handled via the manual import of updated database backups. There are no automated migration scripts.
*   **Cloud Database (In Progress):** An alternative Azure PostgreSQL database solution is currently under development by **Vandana**. This SOP will be updated once this option is available for general use. For now, all developers must use a local PostgreSQL instance.

---
**End of Document**
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT - Direct Services-20250210_074853-Recap.txt
Of course. Based on the document provided, the most actionable and well-defined process suitable for a Standard Operating Procedure (SOP) is the local environment setup. Here is a professional SOP for that process.

***

### **Standard Operating Procedure**

**SOP Title:** Local Development Environment Setup for OCR Service
**Document ID:** SON-DEV-SOP-001
**Version:** 1.0
**Effective Date:** [Date]
**Author:** [Your Name/Department]
**Approver:** [Team Lead/Manager Name]

---

### **1.0 Purpose**
The purpose of this Standard Operating Procedure (SOP) is to provide developers with a clear, step-by-step process for successfully setting up the Sonnet OCR service on their local machine. Adherence to this procedure ensures a consistent and functional development environment for all team members working on the application's admin-side features.

### **2.0 Scope**
This SOP applies to all new and existing developers on the Sonnet project team who are required to run, test, or develop features related to the OCR service and its integration with the Sonnet web application.

### **3.0 Prerequisites**
Before beginning this procedure, the developer must have the following:
*   **Administrative Rights:** Local administrative rights on their development machine to install software.
*   **Version Control:** Git command-line interface (CLI) or a Git GUI client installed.
*   **Code Editor:** A modern code editor or Integrated Development Environment (IDE) such as Visual Studio Code.
*   **Node.js:** The specific Node.js version required by the project must be installed. (e.g., via NVM - Node Version Manager).
*   **Repository Access:** Read/write permissions to the project's source code repository.
*   **Credentials:** Access to the necessary environment variables and configuration details, which can be obtained from the technical lead.

### **4.0 Responsibilities**
*   **The Developer** is responsible for following this SOP to set up their local environment.
*   **The Technical Lead** is responsible for providing developers with the required credentials, environment variable values, and repository access.

### **5.0 Procedure: Step-by-Step Instructions**

**Step 5.1: Clone the Project Repository**
1.  Open a terminal or command prompt.
2.  Navigate to the directory where you store your development projects.
3.  Clone the Sonnet OCR service repository using the following Git command:
    ```bash
    git clone [URL_to_Sonnet_OCR_Repository]
    ```
4.  Navigate into the newly created project directory:
    ```bash
    cd [repository-folder-name]
    ```

**Step 5.2: Set Up the Correct Node.js Version**
1.  Verify the required Node.js version from the project's `package.json` or `.nvmrc` file.
2.  If using NVM, run the following command to switch to the correct version:
    ```bash
    nvm use
    ```
3.  If not using NVM, ensure the globally installed Node.js version matches the project's requirement.

**Step 5.3: Install Project Dependencies**
1.  In the root of the project directory, run the following command to install all required packages and libraries listed in `package.json`:
    ```bash
    npm install
    ```
2.  Wait for the installation process to complete. Check the console for any critical errors.

**Step 5.4: Configure Environment Variables**
1.  Locate the sample environment file in the project directory (e.g., `.env.example`).
2.  Create a copy of this file and name it `.env` or `.env.local` as per project convention.
3.  Obtain the required values for the environment variables from your technical lead. These will include credentials and endpoints for services such as:
    *   Azure File Storage
    *   Azure AI Services (for OCR and Text Analytics)
    *   Database connection strings
    *   Python API endpoints (for Spacy NER)
4.  Open your newly created `.env` file and populate it with the provided values.
    *   **Example:**
        ```env
        AZURE_STORAGE_CONNECTION_STRING="[value_provided_by_lead]"
        AZURE_AI_ENDPOINT="[value_provided_by_lead]"
        AZURE_AI_API_KEY="[value_provided_by_lead]"
        ```
5.  Save and close the file. This file is excluded from Git via `.gitignore` and must not be committed to the repository.

**Step 5.5: Run the OCR Service**
1.  From the root of the project directory, execute the start script defined in the `package.json` file.
    ```bash
    npm run start
    ```
    *Note: The exact command may vary (e.g., `npm run dev`). Refer to the project's `README.md` file for the specific command.*

### **6.0 Verification**
Upon successful completion of Step 5.5, the local server for the OCR service will be running. Verify the setup by:
1.  Observing the terminal output for a success message, such as `Server running on port [port_number]` or `OCR service started successfully.`
2.  Ensuring there are no error messages related to missing environment variables or failed service connections.
3.  The local Sonnet web application should now be able to communicate with this local OCR service for file processing tasks.

### **7.0 Definitions**
*   **OCR (Optical Character Recognition):** The technology used to convert different types of documents, such as scanned paper documents, PDFs, or images, into editable and searchable data.
*   **Environment Variables:** A set of dynamic named values that can affect the way running processes will behave on a computer. Used here to store configuration details like API keys and connection strings.
*   **NVM (Node Version Manager):** A command-line tool that allows developers to easily manage and switch between different versions of Node.js.

### **8.0 Revision History**

| Version | Date | Author | Description of Change |
| :--- | :--- | :--- | :--- |
| 1.0 | [Date] | [Author Name] | Initial document creation. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT - Direct Services-20250210_074853.txt
Of course. Here is a professional Standard Operating Procedure (SOP) based on the provided document.

***

### **Standard Operating Procedure: OCR Document Processing and Analysis**

| | |
| :--- | :--- |
| **SOP ID:** | AI-OCR-001 |
| **Version:** | 1.0 |
| **Effective Date:** | [Date] |
| **Author:** | SOP Generation Expert |
| **Approved By:** | [Approver's Name/Title] |

---

### **1.0 Purpose**

The purpose of this Standard Operating Procedure (SOP) is to define the standardized process for the setup, execution, and troubleshooting of the Optical Character Recognition (OCR) engine. This system utilizes Azure AI, custom models, and Python services to extract, analyze, and structure text from documents.

### **2.0 Scope**

This SOP applies to all technical personnel, including developers and support engineers, who are responsible for the development, deployment, maintenance, and operation of the OCR text analysis system.

### **3.0 Definitions and Acronyms**

*   **OCR:** Optical Character Recognition. The technology used to convert different types of documents, such as scanned paper documents, PDF files or images, into editable and searchable data.
*   **AI:** Artificial Intelligence.
*   **API:** Application Programming Interface. A set of rules and protocols for building and interacting with software applications.
*   **JSON:** JavaScript Object Notation. A lightweight format for storing and transporting data.
*   **SpaCy:** An open-source software library for advanced Natural Language Processing (NLP) in Python.
*   **TLS:** Transport Layer Security. A cryptographic protocol designed to provide communications security over a computer network.

### **4.0 System Overview**

The OCR engine is a multi-component system designed for robust text extraction and analysis.

*   **Process Flow:**
    1.  **Input:** A document (primarily PDF; also supports JPEG, PNG, TIFF) is submitted to the system.
    2.  **Azure AI Processing:** The document is sent to the Azure AI service for initial OCR and text analytics, which recognizes text and base entities.
    3.  **Custom Model Enhancement:** The output from Azure AI is further processed by a custom model for enhanced entity recognition (e.g., names, addresses, account numbers).
    4.  **Python/SpaCy Analysis:** A Python-based service using SpaCy performs final analysis and structuring of the extracted text.
    5.  **Output:** The final processed data is generated as a JSON file, which includes extracted text, entities, confidence scores, and sentiment analysis.
    6.  **Local Storage:** The output JSON file is stored locally for debugging, verification, and comparison purposes.

### **5.0 Procedure: Local Development Environment Setup**

This procedure outlines the steps required to configure the OCR engine on a local development machine.

**5.1. Prerequisites:**
*   Ensure Node.js is installed on the local machine.

**5.2. Setup Steps:**
1.  **Clone Repository:** Clone the project repository from the designated version control system to a local directory.
2.  **Configure Environment Variables:** Create or modify the environment configuration file (e.g., `.env`) to include all necessary variables. This must include the secret keys required for secure inter-service communication.
3.  **Install Dependencies:** Open a terminal in the project's root directory and run the package installation command (e.g., `npm install`).
4.  **Start the Server:** Run the server start command (e.g., `npm start`) to launch the local service.
5.  **Verification:** Confirm that the service is running correctly and can communicate with dependent services, such as the Azure AI endpoint.

### **6.0 Procedure: Standard Document Processing**

This procedure details the standard workflow for processing a document through the OCR engine.

1.  **Prepare Input Document:** Ensure the document for processing is in a supported format (PDF, JPEG, PNG, or TIFF). Note that system logic is primarily optimized for PDF files.
2.  **Submit Document:** Send the document to the appropriate API endpoint for the OCR service.
3.  **Monitor Status:** The system will update the document's status throughout the process. Monitor the status code to track progress (e.g., `processing`, `completed`, `error`).
4.  **Retrieve Output:** Upon successful completion (`completed` status), retrieve the output JSON file from the designated location.
5.  **Review Data:** Open the JSON file to review the extracted text, entities, and associated confidence scores.

### **7.0 Procedure: Error Handling and Troubleshooting**

This procedure provides guidance for identifying and resolving common issues. The primary tools for troubleshooting are the system logs and the locally stored JSON output files.

| **Issue / Observation** | **Potential Cause** | **Resolution Steps** |
| :--- | :--- | :--- |
| **Incorrect Entity Recognition** | 1. Low-quality source document (blurry, skewed).<br>2. Limitations of the current AI/custom model. | 1. Manually review the source document and the output JSON file to confirm the discrepancy.<br>2. Check the `confidenceScore` for the misidentified entity in the JSON.<br>3. If the document quality is poor, re-scan or obtain a higher-quality version.<br>4. If the model is at fault, log the issue for model retraining or updates. |
| **Missing Data in Output** | 1. Section of the document was unreadable by the OCR engine.<br>2. A processing error occurred mid-stream. | 1. Inspect the source document for sections that may be difficult to parse (e.g., tables, handwritten notes, complex layouts).<br>2. Review the system logs for any errors that occurred during the processing of that specific document. |
| **Processing Fails (Status: `error`)** | 1. Invalid or corrupted input file.<br>2. Incorrect or expired secret keys.<br>3. Network connectivity issues with the Azure AI service. | 1. Check the system logs for a detailed error message.<br>2. Verify that the input file is not corrupted and is in a supported format.<br>3. Validate that all environment variables, especially service URLs and secret keys, are correctly configured.<br>4. Ensure the system has a stable network connection to all external services. |

### **8.0 Security Considerations**

*   **Secure Communication:** All communication between internal services and with external APIs (like Azure AI) is secured using TLS encryption.
*   **Authentication:** Services authenticate with each other using secret keys. These keys must be stored securely as environment variables and must not be committed to the version control system. Access to these keys should be restricted to authorized personnel only.

### **9.0 References**

*   Meeting Q&A Document: "List of Questionnaire Covered in the Meeting"

### **10.0 Approval**

| **Role** | **Name** | **Signature** | **Date** |
| :--- | :--- | :--- | :--- |
| **Author** | SOP Generation Expert | | [Date] |
| **Head of Development** | [Name] | | [Date] |
| **Quality Assurance Lead**| [Name] | | [Date] |

***
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT - Receipt Generation-20250210_100555-Recap.txt
Of course. Based on the provided document, I will generate a professional Standard Operating Procedure for the most well-defined process described: **Automated Receipt Generation and Confirmation**.

***

### **Standard Operating Procedure: Automated Receipt Generation and Confirmation**

**SOP Number:** TEC-OPS-001
**Version:** 1.0
**Effective Date:** [Date]
**Author:** Technical Operations
**Approver:** [Approver Name/Title]

---

### **1.0 Purpose**

The purpose of this Standard Operating Procedure (SOP) is to document the standardized, automated process for generating, delivering, and confirming customer receipts. This document ensures consistency, reliability, and maintainability of the receipt generation system, reflecting the architecture migrated to the new API.

### **2.0 Scope**

This SOP applies to all development and operations personnel responsible for maintaining, monitoring, and troubleshooting the receipt generation workflow. It covers the end-to-end process, from initiation by a scheduled job to the final confirmation of receipt delivery. The key systems involved are the **Oscar** data source, the **Notary Service** for PDF creation, and the application's backend API.

### **3.0 Definitions**

*   **Cron Job:** A time-based job scheduler in a Unix-like operating system used to automate repetitive tasks.
*   **Oscar:** The legacy or primary system of record from which customer and transaction data is collected for receipt generation.
*   **Notary Service:** A dedicated microservice responsible for creating PDF documents from supplied data and templates.
*   **Twig:** A modern template engine for PHP, used to create the PDF receipt templates. It allows for flexible and dynamic document structure.
*   **API:** Application Programming Interface. In this context, it refers to the new, modular backend system that orchestrates the receipt generation process.

### **4.0 Responsibilities**

*   **Development Team:** Responsible for maintaining the source code of the services involved, updating Twig templates, and resolving bugs within the process logic.
*   **Operations Team:** Responsible for monitoring the cron jobs, ensuring the health of the Notary Service, and executing manual procedures for handling failures or special cases.

### **5.0 Procedure: End-to-End Receipt Generation**

This section outlines the automated, step-by-step process for generating a receipt.

**Step 5.1: Process Initiation via Cron Job**
The receipt generation process is initiated automatically by a scheduled cron job. This job runs at a predefined interval to check for transactions requiring a receipt.

**Step 5.2: Data Collection**
The script executed by the cron job connects to the **Oscar** system to collect all necessary data for the pending receipts. This includes customer information, transaction details, and any other required data points.

**Step 5.3: PDF Generation**
1.  The collected data is passed to the **Notary Service**.
2.  The Notary Service populates a pre-defined **Twig** template with the data.
    *   *Note:* The Twig template engine is used for its flexibility, allowing for custom filters and components to structure the receipt's layout and logic dynamically.
3.  The service renders the populated template into a final PDF document.

**Step 5.4: Receipt Confirmation**
Once the PDF is generated and associated with the customer record, the system performs a confirmation step. This marks the receipt as successfully generated and finalizes the process for that specific transaction.

### **6.0 Architectural Overview**

The current receipt generation architecture is designed for modularity and improved organization, representing a significant improvement over previous monolithic versions.

*   **Previous Architecture:** Logic was likely contained within a single application, making it difficult to debug and maintain.
*   **Current Architecture:** The process is broken down into distinct modules and services.
    *   Data retrieval is a discrete step.
    *   PDF generation is handled exclusively by the **Notary Service**.
    *   The core application API orchestrates the workflow between these components.
    *   This modularity simplifies maintenance, scaling, and troubleshooting.

### **7.0 Troubleshooting and Special Cases**

Operational issues and legacy data require specific handling procedures.

**7.1 Handling Pending or Failed Receipts**
Receipts can occasionally become stuck in a "pending" state due to transient errors.
*   **Procedure:** A repetitive, scheduled process must be run to re-attempt generation for any receipts that remain in a pending state. This ensures that temporary failures do not result in a permanently missed receipt.

**7.2 Handling Legacy Data (Pre-API System)**
For historical data created before the implementation of the current automated system, receipts may need to be created retroactively.
*   **Procedure:** A "fake receipt" generation process must be initiated. This involves manually triggering the workflow for older records to ensure they have a corresponding receipt document in the system, maintaining data integrity.

### **8.0 Revision History**

| Version | Date       | Author                | Summary of Changes                             |
| :------ | :--------- | :-------------------- | :--------------------------------------------- |
| 1.0     | [Date]     | Technical Operations  | Initial document creation based on process review. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT - Receipt Generation-20250210_100555.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure (SOP).

***

### **Standard Operating Procedure**

**SOP ID:** DEV-SOP-001
**Version:** 1.0
**Effective Date:** October 26, 2023
**Title:** Development Environment, UAT Access, and Troubleshooting Protocols

---

**1.0 PURPOSE**

This Standard Operating Procedure (SOP) outlines the standardized processes for the development team. The procedures detailed herein cover the setup of a local development environment, the protocol for accessing the User Acceptance Testing (UAT) environment, and the initial steps for troubleshooting critical application issues. The objective is to ensure consistency, reduce setup time, and maintain operational efficiency across the team.

**2.0 SCOPE**

This SOP applies to all new and existing members of the software development team. It is the primary reference for environment configuration, testing access, and issue diagnosis related to this project.

**3.0 RESPONSIBILITIES**

| Role | Responsibility |
| :--- | :--- |
| **Developer** | Responsible for following all procedures outlined in this document for environment setup, UAT access, and initial troubleshooting. |
| **Database (DB) Team** | Responsible for providing and maintaining the database backup required for local development and making it accessible to the team. |
| **Team Lead / Senior Developer** | Responsible for maintaining this SOP, providing necessary documentation (e.g., for Cato access), and resolving version conflicts or configuration issues. |

**4.0 DEFINITIONS**

*   **Vagrant:** An open-source software product for building and maintaining portable virtual software development environments.
*   **VirtualBox:** A free and open-source hosted hypervisor for x86 virtualization.
*   **UAT:** User Acceptance Testing. The final phase of the software testing process.
*   **Cato:** A network security client required for accessing secure environments like UAT.
*   **OCR:** Optical Character Recognition.

**5.0 PROCEDURES**

**5.1 Procedure 1: Local Development Environment Setup**

This procedure details the steps to configure a functional development environment on a local machine.

1.  **Prerequisites Installation:**
    *   Install **VirtualBox** on your local machine.
    *   Install **Vagrant** on your local machine.
    *   **Note:** It is critical to ensure that the installed versions of Vagrant and VirtualBox are aligned with the project's required specifications. Consult the Team Lead for the correct versions to prevent environment mismatch issues.

2.  **Obtain Database Backup:**
    *   The DB Team is responsible for generating a backup of the database.
    *   This backup file will be uploaded to a designated SharePoint folder.
    *   The Development Team will be notified of the file's location for download. The backup will contain the necessary structure and a minimal data set required for the application to function correctly.

3.  **Local Database Configuration:**
    *   Once the backup is downloaded, restore it to your local database instance.
    *   Configure the application's database connection settings with the specific IP addresses and credentials required for the local setup. Refer to the project's configuration documentation for these details.
    *   **Note:** The team is considering a dedicated tool to pull specific company data. Until this is available, the provided backup is the standard source.

4.  **Launch the Development Environment:**
    *   Navigate to the project's root directory in your terminal.
    *   Execute the `vagrant up` command to build and launch the virtual machine.

**5.2 Procedure 2: Accessing the UAT Environment**

This procedure covers the steps required to gain access to the UAT environment for testing purposes.

1.  **Install Access Client:**
    *   Download and install the **Cato** client on your local machine.

2.  **Obtain Access Documentation:**
    *   Request the UAT access documentation from the Team Lead. This document contains detailed setup instructions and necessary credentials.

3.  **Configure and Connect:**
    *   Follow the instructions provided in the documentation to configure the Cato client.
    *   Use the provided credentials to connect to the UAT environment.

**5.3 Procedure 3: Troubleshooting Chrome Unresponsiveness Issue**

This procedure provides the initial diagnostic steps for the known issue where the application becomes unresponsive following a Chrome browser update (e.g., v133).

1.  **Initial Investigation:**
    *   Open the application in the affected Chrome browser.
    *   Open Chrome Developer Tools (F12 or Ctrl+Shift+I).
    *   Inspect the **Console** tab for any JavaScript errors.
    *   Inspect the **Network** tab for failed or blocked requests.

2.  **Check for Library Conflicts:**
    *   The primary suspects for this issue are JavaScript library incompatibilities.
    *   Specifically, investigate potential conflicts with **Bootstrap 3** or other core JavaScript libraries and the new Chrome version.
    *   Review the application's front-end code to identify which libraries are being loaded and where potential blocks might occur.

3.  **Isolate, Fix, and Document:**
    *   Based on the findings, attempt to isolate the root cause.
    *   Once identified, implement a fix.
    *   Thoroughly test the solution to ensure it resolves the unresponsiveness without introducing new issues.
    *   Document the findings and the solution in the project's knowledge base.

**6.0 GUIDING PRINCIPLES & BEST PRACTICES**

While not a formal procedure, the following principles should guide all development work to improve the codebase's long-term health and maintainability:

*   **Modularize Code:** Break down large, monolithic code files into smaller, more manageable modules with single responsibilities.
*   **Create Reusable Components:** Identify repeated code blocks and refactor them into single, reusable files, components, or services.
*   **Improve Code Discoverability:** Structure the code logically so that components and services are easy to identify, maintain, and debug.

**7.0 REVISION HISTORY**

| Version | Date | Author | Summary of Changes |
| :--- | :--- | :--- | :--- |
| 1.0 | 2023-10-26 | SOP Bot | Initial document creation based on meeting notes. |

---
**End of Document**
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT - Receipt Generation-20250210_121329.txt
Of course. Based on the provided meeting summary, here is a professional Standard Operating Procedure (SOP) for setting up the UAT environment and troubleshooting common issues.

***

### **Standard Operating Procedure: UAT Environment Setup and Troubleshooting**

**SOP ID:** UAT-SOP-001
**Version:** 1.0
**Effective Date:** 2023-10-27
**Author:** SOP Generator
**Approved By:** [Approver Name/Title]

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) provides a step-by-step guide for users to set up their local environment for User Acceptance Testing (UAT). It also details standardized troubleshooting procedures for common access, authentication, and database connectivity issues related to the Polynom client, Cato, and the PostgreSQL database.

### **2.0 Scope**

This SOP applies to all team members, developers, and testers who require access to the UAT environment. It covers the initial client installation, UAT access, and troubleshooting for systems including the Polynom client, Cato VPN, and local PostgreSQL database connections.

### **3.0 Prerequisites**

Before beginning this procedure, the user must have:
*   A Polynom user account created by a System Administrator.
*   A Polynom email account. If you do not have one, contact the System Administrator. Note that additional licenses may be required.
*   Credentials for the Polynom user account (username, password).
*   Administrative rights on their local Windows machine to install software.

### **4.0 Procedure: Initial Environment Setup**

Follow these steps to install the required software and gain initial access to the UAT instance.

**4.1 Download and Install the Polynom Client**
1.  Obtain the download link for the Polynom client from the System Administrator.
2.  Download the installer file to your local machine.
3.  Run the installer and follow the on-screen prompts to complete the installation on your Windows operating system.

**4.2 Access the UAT Environment**
1.  Launch the newly installed Polynom client.
2.  You will be prompted to log in. Access the UAT environment using your Single Sign-On (SSO) credentials.
3.  Use the following URL to access the UAT instance when prompted:
    *   **UAT URL:** [Insert Specific UAT URL Provided by Administrator]

**4.3 Request Admin Access in UAT (If Required)**
1.  By default, users have standard access.
2.  If your testing role requires administrative privileges within the UAT instance (e.g., access to the admin menu), submit a request to the System Administrator or Team Lead.
3.  They will grant the necessary permissions to your user account.

### **5.0 Troubleshooting Procedures**

This section addresses common errors encountered during and after setup.

**5.1 Resolving Cato Authentication and Connection Errors**

**Symptom:** You encounter internal authentication errors, login failures, or cannot connect via the Cato client.

**Procedure:**
1.  **Clear Client Cache:**
    *   Open the Cato client application.
    *   Navigate to the settings or advanced options menu.
    *   Locate and execute the "Clear Cache" function.
2.  **Revoke Sessions:**
    *   Within the Cato client settings, find the option to manage sessions.
    *   Revoke all active sessions associated with your account.
3.  **Reconnect:**
    *   Close the Cato client completely.
    *   Re-launch the client and attempt to log in again.
4.  **Verify Subdomain and SSO Sync (If problem persists):**
    *   **Action:** Contact the designated Network Administrator (e.g., Emery) to confirm you are using the correct subdomain configuration in the Cato client.
    *   **Action:** Request that the administrator verify your user account is correctly synced with the appropriate SSO group for Cato access.

**5.2 Resolving Local PostgreSQL Database Connection Issues**

**Symptom:** The application is unable to connect to your local PostgreSQL database instance.

**Procedure:**
1.  **Verify Connection Parameters:** Ensure the database host, port, database name, username, and password in your application's configuration file are correct for your local PostgreSQL instance.
2.  **Edit the `pg_hba.conf` File:** This file controls client authentication.
    *   Locate the `pg_hba.conf` file in your PostgreSQL data directory.
    *   Open the file in a text editor with administrative privileges.
    *   Add or modify a line to allow connections from your local application. For standard local connections, ensure a line similar to the following exists:
      ```
      # TYPE  DATABASE        USER            ADDRESS                 METHOD
      host    all             all             127.0.0.1/32            md5
      ```
      *Note: `md5` forces password authentication. Adjust the parameters as needed for your specific setup.*
3.  **Restart PostgreSQL Service:**
    *   After saving changes to `pg_hba.conf`, you must restart the PostgreSQL service for the changes to take effect.
    *   Open the Windows Services application (`services.msc`), locate the `postgresql` service, and restart it.

### **6.0 Escalation Path**

If the procedures in this SOP do not resolve the issue, please escalate to the appropriate contact:

*   **For Polynom/UAT account setup, admin access, or email accounts:** Contact the System Administrator (e.g., Lidiexy, Luis).
*   **For Cato subdomain confirmation or SSO group sync issues:** Contact the Network Administrator (e.g., Emery).
*   **For database issues not resolved by this SOP:** Contact the Development Team Lead (e.g., Luis).

### **7.0 Revision History**

| Version | Date       | Author         | Change Description      |
| ------- | ---------- | -------------- | ----------------------- |
| 1.0     | 2023-10-27 | SOP Generator  | Initial document creation |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT Session-20250206_083751-Database (1).txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure for Database Management.

---

### **Standard Operating Procedure: Azure PostgreSQL Database Management**

| **Document ID:** | DB-MGMT-SOP-001 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Effective Date:** | [Date] | **Author:** | SOP Expert |
| **Approved By:** | [Approver Name] | **Review Cycle:** | 12 Months |

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) provides standardized guidelines for managing, maintaining, and troubleshooting the Azure PostgreSQL databases. The purpose is to ensure consistent practices that promote database performance, stability, data integrity, and disaster recovery readiness.

### **2.0 Scope**

This SOP applies to all personnel responsible for the administration, maintenance, and support of the production and non-production Azure PostgreSQL environments. It covers procedures for index management, data restoration, major version upgrades, disaster recovery, and performance monitoring.

### **3.0 Roles and Responsibilities**

*   **Database Administrator (DBA):** Responsible for executing all procedures outlined in this document, ensuring database health, and consulting with the Development Team on performance-related changes.
*   **Development Team:** Responsible for reviewing and approving database schema and index changes, providing context for query performance, and assisting in post-change validation.

### **4.0 Tools and Systems**

*   **Azure Portal:** Primary interface for managing database infrastructure, backups, disaster recovery, monitoring, and configurations.
*   **pgAdmin:** Standard tool for running SQL scripts, managing database objects, and performing administrative tasks.
*   **DB Forge for PostgreSQL:** Specialized tool used for schema/data comparison and efficient single-table restorations.

---

### **5.0 Procedures**

#### **5.1 Procedure: Index Tuning and Performance Review**

This procedure outlines the process for identifying and evaluating potential index optimizations to improve query performance.

**Trigger:** Proactive performance review or response to a reported performance degradation issue.

*   **Step 1: Identify Recommendations**
    *   Navigate to the Azure PostgreSQL instance in the Azure Portal.
    *   Access the "Query Performance Insight" and "Index Recommendations" features to identify potentially missing or inefficient indexes.

*   **Step 2: Analyze Impact**
    *   For each recommendation, analyze the associated queries and their performance impact (e.g., cost, frequency of execution).
    *   Do not apply indexes blindly. Evaluate the necessity of each index against the potential storage and write-performance overhead.

*   **Step 3: Consult Development Team**
    *   Initiate a formal discussion with the Development Team to review the recommended index changes.
    *   Provide the analysis from Step 2 and discuss the application-level benefits and potential risks.
    *   **Critical:** Obtain documented approval from the Development Team before proceeding.

*   **Step 4: Document Decision**
    *   Record the decision (apply or reject) and the justification in the change management system.

#### **5.2 Procedure: Applying New Database Indexes**

This procedure details the steps for applying an approved index to the database.

**Prerequisite:** The index change has been approved according to procedure **5.1**.

*   **Step 1: Prepare Script**
    *   Obtain or create the `CREATE INDEX` SQL script for the approved index.

*   **Step 2: Apply to Non-Production**
    *   Connect to the UAT (or relevant pre-production) database using **pgAdmin**.
    *   Execute the script.
    *   Monitor for any immediate errors or performance issues.

*   **Step 3: Evaluate Performance**
    *   Use the `EXPLAIN ANALYZE` command on relevant queries to confirm the new index is being used and has improved the query plan.
    *   Collaborate with the Development or QA team to perform functional testing against the affected application features.

*   **Step 4: Apply to Production**
    *   Schedule and execute the script on the production database during a low-traffic period or approved maintenance window.

*   **Step 5: Synchronize Environments**
    *   Ensure that any index applied directly to production is manually back-ported to all lower environments (UAT, Dev) to maintain schema consistency.

#### **5.3 Procedure: Restoring a Single Table from Backup**

This procedure is used to restore a single table that has been corrupted or unintentionally modified, leveraging Azure's point-in-time restore (PITR) and DB Forge.

**Context:** Azure automatically performs regular database backups. This process restores a full backup to a temporary instance to recover specific data without full database rollback.

*   **Step 1: Identify Restore Point**
    *   Determine the exact date and time (point-in-time) to which the table needs to be restored.

*   **Step 2: Restore to a Temporary Database**
    *   In the Azure Portal, navigate to the production database's "Restore" blade.
    *   Select the "Point-in-time" option and input the time identified in Step 1.
    *   Provide a unique name for the restored database (e.g., `[prod-db-name]-temp-restore-[date]`).
    *   Initiate the restore process. **Do not restore over the existing production database.**

*   **Step 3: Prepare for Data Transfer**
    *   Once the temporary database is available, open **DB Forge**.
    *   Establish connections to both the **live production database** and the **temporary restored database**.

*   **Step 4: Execute Single-Table Restore**
    *   Use the Data Comparison feature in **DB Forge** to compare the target table between the temporary and production databases.
    *   Generate and execute a synchronization script to copy the data from the table in the temporary database to the table in the production database.

*   **Step 5: Verify Data Integrity**
    *   Run queries against the production table to confirm the data has been restored correctly.
    *   Request the application owner or Development Team to validate the data from the application's perspective.

*   **Step 6: Decommission Temporary Database**
    *   After successful verification, delete the temporary restored database from the Azure Portal to avoid incurring unnecessary costs.

#### **5.4 Procedure: Major Version Database Upgrade**

This procedure covers the planned upgrade of the database to a new major version.

**Note:** Minor version updates and security patches are handled automatically by Azure and do not require this procedure.

*   **Step 1: Plan Upgrade**
    *   Research the new major version for compatibility issues with the application.
    *   Plan the upgrade first in a non-production environment (UAT) that mirrors production load and configuration as closely as possible.

*   **Step 2: Schedule Maintenance Window**
    *   Coordinate with all stakeholders to schedule an official maintenance window for the production upgrade. The database will be unavailable during this time.

*   **Step 3: Pre-Upgrade Backup**
    *   Although Azure performs automatic backups, manually trigger a final backup or confirm a recent successful point-in-time backup is available immediately before starting the upgrade.

*   **Step 4: Execute Upgrade**
    *   In the Azure Portal, navigate to the database instance and initiate the major version upgrade process, selecting the target version.

*   **Step 5: Post-Upgrade Validation**
    *   Once the upgrade is complete, perform a full suite of validation tests:
        *   Confirm application connectivity.
        *   Run critical queries to check for performance regressions.
        *   Have the Development Team and/or QA perform functional testing.

*   **Step 6: Communicate Completion**
    *   Notify all stakeholders that the maintenance is complete and the system is operational.

#### **5.5 Procedure: Disaster Recovery Failover**

This procedure outlines the steps to fail over to the secondary read-replica in the event of a primary region outage.

**Context:** The environment is configured with a geo-replica and a virtual endpoint, which allows for failover without changing application connection strings.

*   **Step 1: Declare Disaster**
    *   Following a confirmed, unrecoverable outage of the primary database or its region, the designated authority (e.g., IT Director, CTO) declares a disaster and authorizes a failover.

*   **Step 2: Initiate Failover**
    *   In the Azure Portal, navigate to the primary database instance.
    *   Initiate the planned or unplanned failover process to promote the secondary replica to the new primary.

*   **Step 3: Verify Failover**
    *   The virtual endpoint will automatically re-route traffic to the newly promoted primary. No connection string changes are required in the application.
    *   Monitor the application for successful reconnection and restoration of service.

*   **Step 4: Post-Failover Operations**
    *   Verify that application functionality is fully restored.
    *   Once the disaster is resolved, plan a failback to the original primary region during a future scheduled maintenance window.

#### **5.6 Procedure: Performance Monitoring and Troubleshooting**

This procedure describes how to use Azure's diagnostic tools to investigate performance issues.

*   **Step 1: Confirm Diagnostic Settings**
    *   Ensure that Azure Diagnostic Settings are enabled for the database instance, configured to send all relevant logs (e.g., PostgreSQLLogs, QueryStoreRuntimeStatistics) to a Log Analytics Workspace.

*   **Step 2: Access Logs**
    *   In the Azure Portal, navigate to the database instance and select the "Logs" blade under the "Monitoring" section. This opens the Log Analytics query interface.

*   **Step 3: Analyze Query Data**
    *   Use the Kusto Query Language (KQL) to query the collected logs.
    *   **Example:** To find the top 10 longest-running queries, use a query similar to:
        ```kql
        AzureDiagnostics
        | where Category == "QueryStoreRuntimeStatistics"
        | top 10 by duration_ms desc
        ```

*   **Step 4: Identify and Remediate**
    *   Analyze the query results to identify problematic queries, usage patterns, or errors.
    *   Correlate findings with application behavior.
    *   If a query can be optimized with an index, refer to procedure **5.1 (Index Tuning and Performance Review)**.
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT Session-20250206_083751-Database.txt
Of course. Here is a professional Standard Operating Procedure (SOP) based on the provided document.

***

### **Standard Operating Procedure: Database Management and Change Control**

| **SOP ID:** | DBM-001 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Effective Date:** | [Date] | **Approved By:** | [Approver Name/Title] |
| **Department:** | Information Technology / Database Administration | **Review Cycle:** | 12 Months |

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) establishes the standardized processes for managing the Sonnet system's Azure database. It provides clear, step-by-step instructions for applying database indexes, deploying schema changes across environments, and performing database restorations. The objective is to ensure database integrity, performance, stability, and a controlled change management lifecycle.

### **2.0 Scope**

This SOP applies to all Database Administrators, Developers, and IT personnel involved in the maintenance, management, and deployment of changes to the Azure database environments, including User Acceptance Testing (UAT) and Production.

### **3.0 Tools and Resources**

The following tools are required to perform the procedures outlined in this document:

*   **Azure Portal:** For managing the database server, monitoring, backups, and restorations.
*   **DB Forge:** Primary tool for schema visualization, management, and data comparison. It is installed on the production and QA jump servers.
*   **pgAdmin:** An alternative tool for database management.

### **4.0 Procedures**

#### **4.1 Procedure: Database Index Management and Application**

This procedure details the process for identifying, testing, and applying performance-improving indexes.

1.  **Monitor Recommendations:** Regularly monitor the Azure index tuning tool, which captures query logs and provides automated index recommendations.
2.  **Evaluate Impact:** Carefully evaluate each suggested index based on its potential benefit to query performance and the overall application. Not all recommendations may be suitable.
3.  **Deploy to UAT:** Apply any index deemed beneficial to the User Acceptance Testing (UAT) environment first. **DO NOT** apply new indexes directly to Production.
4.  **Test and Validate:** Conduct thorough testing in the UAT environment to confirm the performance improvement and identify any negative side effects.
5.  **Obtain Approval:** Once testing is successfully completed and the index is validated, seek formal approval to promote the change to Production.
6.  **Initiate Change Control:** Upon approval, follow the "Database Schema Change Deployment" procedure (Section 4.2) to schedule and apply the index to the Production environment.

#### **4.2 Procedure: Database Schema Change Deployment**

This procedure governs the promotion of any database change (including new indexes, table modifications, etc.) from a lower environment to Production.

1.  **UAT First Principle:** All database schema changes must be applied and thoroughly tested in the UAT environment before being considered for Production.
2.  **Create Change Control Ticket:** Once a change has been approved in UAT, create a formal change control ticket detailing the change, the reason for the change, the test results, and the deployment plan.
3.  **Schedule Deployment:** Work with the Change Advisory Board (CAB) or relevant stakeholders to schedule the change for a planned production maintenance window.
4.  **Manual Production Deployment:** During the scheduled window, a qualified administrator must manually apply the approved changes to the Production database.
    *   **Note:** The promotion of database changes is a deliberate, manual process. There is no automated sync or promotion between UAT and Production environments.

#### **4.3 Procedure: Database Restoration from Backup**

This procedure outlines the steps for restoring a database from the automated Azure backups. Azure automatically handles backups with a 30-day retention policy.

1.  **Initiate Restoration:** Access the Azure Portal to begin the restoration process. You can select either a full restore or a point-in-time restore.
2.  **Create New Server:** Provision a new, temporary database server to host the restored database. This new server **must** be given a unique name.
3.  **Execute Restore:** Perform the restoration to the newly created temporary server.
4.  **Compare and Verify (If Applicable):** For partial data recovery or validation, use a tool such as DB Forge to perform a schema and data comparison between the restored database and the live production database.
5.  **Migrate Data (If Applicable):** If data needs to be moved from the restored instance to the production instance, follow established and approved data migration protocols to ensure data integrity.

---

### **5.0 Approval**

| **Role** | **Name** | **Signature** | **Date** |
| :--- | :--- | :--- | :--- |
| **Author** | [Author Name] | | |
| **Approver** | [Manager/Director Name] | | |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT Session-20250206_100717-RulesEngine (1).txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure.

***

### **Standard Operating Procedure: Rules Engine Development and Operation**

**SOP ID:** SOP-RE-001
**Version:** 1.0
**Effective Date:** [Date]
**Owner:** Development Team
**Approver:** Lidiexy, Amanda Gilbert

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) outlines the standard procedures for the setup, operation, and maintenance of the dispute processing Rules Engine. This document details the technical environment setup, data processing workflow, and the protocol for implementing custom client logic to ensure consistent and efficient operations. The primary purpose of the Rules Engine is to ingest dispute data, apply a set of predefined or custom rules, and recommend appropriate responses, automating the process where possible.

### **2.0 Scope**

This SOP applies to all Python developers, data engineers, and operations personnel involved with the Rules Engine. This includes system setup, maintenance, testing, pull requests, and the implementation of custom logic for new and existing clients.

### **3.0 Responsibilities**

*   **Python Developers (e.g., Amanda Gilbert, Rules Engine Maintainer):** Responsible for maintaining the core Rules Engine, implementing custom logic for clients, performing testing, and managing pull requests.
*   **Operations Team:** Responsible for monitoring the overall data flow, including the dispute queue and the successful processing of disputes by the Rules Engine.

### **4.0 Definitions**

*   **Rules Engine:** The automated system that processes dispute data, applies logic, and recommends responses.
*   **Oscar Service:** The upstream service that provides the initial dispute data for processing.
*   **Dispute Queue:** The intermediary holding area where processed data is placed for the Rules Engine to retrieve and action.
*   **No-Touch Logic:** A specific set of rules that allows for the complete automation of a dispute response without human intervention, based on predefined criteria.
*   **Custom Logic:** Client-specific rules or modifications that override the default logic to meet unique business requirements.

---

### **5.0 Procedure: Development Environment Setup**

To work on the Rules Engine, developers must configure their local environment correctly.

**5.1. Install Python Versions:**
    *   Install Python 2.7.
    *   Install Python 3 (verified compatible with version 3.12).
    *   **Note:** The system requires both versions to be present in the development environment for full functionality and compatibility.

**5.2. Create a Virtual Environment:**
    *   Create a dedicated Python virtual environment for this project. This isolates project dependencies and avoids conflicts.
    *   Command (example): `python3 -m venv venv`

**5.3. Activate the Virtual Environment:**
    *   Activate the newly created environment before installing packages or running the application.
    *   Command (example): `source venv/bin/activate`

**5.4. Install Required Packages:**
    *   Install all necessary Python packages as defined in the project's dependency file (e.g., `requirements.txt`).
    *   Command (example): `pip install -r requirements.txt`

### **6.0 Procedure: Rules Engine Data Processing Flow**

The Rules Engine operates as part of a larger data processing pipeline.

**6.1. Data Ingestion:**
    *   The process begins with the downloading of dispute data from the **Oscar service**.

**6.2. Core System Processing:**
    *   The raw data is processed through the **core system**.

**6.3. Queuing for Rules Engine:**
    *   Once processed by the core, the dispute data is placed into the **dispute queue**.

**6.4. Engine Execution:**
    *   The Rules Engine actively monitors the dispute queue and picks up new items for processing.

**6.5. Logic Application and Response Recommendation:**
    *   The engine applies its logic (default or custom) to the dispute data to generate a recommended response.

### **7.0 Procedure: Implementing Custom Client Logic**

A key function of the development team is to apply custom logic for different clients.

**7.1. Establish Baseline:**
    *   All custom logic implementation begins with the **default logic**, which is defined in the application's DB models.

**7.2. Create Client-Specific Files:**
    *   For each client requiring custom rules, create a new, dedicated file. This practice isolates client logic and promotes clean, maintainable code.

**7.3. Implement Custom Rules:**
    *   Within the client-specific file, implement the required business logic. This may involve creating **custom queues** to route disputes for specific clients, often using the Company ID as a key.

**7.4. Testing and Deployment:**
    *   Thoroughly test the new custom logic to ensure it functions as expected and does not negatively impact the default logic or other clients.
    *   Once testing is complete, submit a **pull request** for peer review and merging, as per standard development protocol.

### **8.0 Procedure: "No-Touch" Automated Processing**

The "No-Touch" logic is designed to automate dispute resolution for specific, low-risk scenarios.

**8.1. Criteria for Automation:**
    *   Disputes are eligible for "No-Touch" processing if they meet a set of predefined criteria.

**8.2. Exclusion Criteria:**
    *   A dispute will be **excluded** from "No-Touch" processing and routed for manual review if it contains:
        *   **Images.**
        *   **FCRA (Fair Credit Reporting Act) relevant information.**

### **9.0 Reference: System Components and Codes**

**9.1. Response Codes:**
    *   The Rules Engine uses a standardized set of response codes to classify outcomes. Developers must familiarize themselves with these codes to ensure logic is implemented correctly. Refer to the internal documentation for a complete list and their specific use cases.

**9.2. AUD and Direct Rules Engines:**
    *   The AUD and Direct Rules Engines are separate but similar instances of the main Rules Engine. They share much of the same core logic but are configured to handle different data processing flows. Developers working on these systems should be aware of the minor differences in data handling.

---

### **10.0 Revision History**

| Version | Date       | Author(s)        | Summary of Changes     |
| :------ | :--------- | :--------------- | :--------------------- |
| 1.0     | [Date]     | [Author's Name]  | Initial document creation. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT Session-20250206_100717-RulesEngine.txt
Of course. Here is a professional Standard Operating Procedure based on the document provided.

***

### **Standard Operating Procedure: Rules Engine for Dispute Processing**

**SOP ID:** RE-DP-001
**Version:** 1.0
**Effective Date:** [Date]
**Author:** System Architect
**Approved By:** [Approver's Name/Title]

### 1.0 Purpose

The purpose of this Standard Operating Procedure (SOP) is to outline the standardized process for the setup, operation, and management of the automated rules engine. This document details the workflow for processing disputes, from initial setup to final resolution, ensuring consistent and accurate handling.

### 2.0 Scope

This SOP applies to all personnel involved in the development, maintenance, and operation of the dispute processing rules engine, including developers, system administrators, and quality assurance (QA) teams. It covers the entire lifecycle of a dispute within the automated system.

### 3.0 Prerequisites

Prior to operating the rules engine in a local environment, the following prerequisites must be met:

*   **Python Installation:** Both Python version 2.7 and Python version 3.x must be installed on the system.
*   **Virtual Environment:** A dedicated virtual environment must be created to isolate project dependencies.
*   **Package Installation:** All necessary packages, as listed in the `requirements` file, must be installed within the virtual environment.

### 4.0 System Components and Definitions

**4.1 Key Components**

*   **Dispute Table:** The primary table containing all dispute information.
*   **Base Segment:** Contains foundational data related to the disputes.
*   **Fax Data Snapshot:** A snapshot of data received via fax, relevant to the dispute.
*   **Oscar Response:** Data related to responses processed through the e-OSCAR system.
*   **Fax Response Table:** The table where system-generated responses are stored.

**4.2 Definitions**

*   **Dispute Queue:** The entry point for disputes to be processed. The rules engine is triggered when a new dispute enters this queue.
*   **No-Touch Logic:** Customer-defined criteria for automatically processing a dispute from start to finish without manual intervention.
*   **Compliance Condition Code (CCC):** A code that dictates how specific values in the dispute response are populated (e.g., using a value from the System of Record (SOR), leaving it blank, or using the original value).
*   **Response Codes:** System-defined codes (e.g., 01, 02, 03, 07, 21, 22, 23, 24) that indicate the outcome of the dispute investigation.

### 5.0 Procedure: Dispute Processing Workflow

This section outlines the step-by-step process the rules engine follows to handle a dispute.

**Step 1: Initiation**
A dispute enters the processing workflow by being placed into the **Dispute Queue**. This action triggers the rules engine to begin processing.

**Step 2: Triage and Status Check**
The rules engine retrieves the dispute from the queue and checks its current status.
*   **Eligible Statuses:** Disputes with a status of `new`, `active`, `WIP` (Work In Progress), or `QA` are eligible for processing.
*   **Ineligible Statuses:** Disputes with a status of `complete` are considered finalized and will be ignored by the engine to prevent reprocessing.

**Step 3: Application of Customer-Specific Logic**
The engine identifies the `company ID` associated with the dispute. This allows the system to load and apply a set of rules and settings customized for that specific customer. (See Section 6.0 for implementation details).

**Step 4: Rule Execution**
The engine evaluates the dispute against the applicable rule set.
1.  **Evaluate No-Touch Criteria:** The engine first determines if the dispute qualifies for "no-touch" processing based on customer-defined logic.
    *   **Exclusions:** No-touch logic typically excludes disputes containing images, FCRA-relevant information, or other specific conditions.
2.  **Determine Compliance Condition Code:** Based on customer settings, the engine sets the appropriate Compliance Condition Code for the response.
3.  **Assign Response Code:** The engine determines the final response code based on the specific fields being updated and the nature of the dispute codes involved.

**Step 5: Quality Assurance (QA) Sampling**
A statistically determined percentage of disputes are systematically routed for manual review.
1.  The engine uses a randomizing function (e.g., a random integer from 0-99).
2.  If the generated number falls below a predefined threshold (e.g., less than 5), the dispute’s status is updated to `QA`.
3.  Disputes flagged for `QA` are routed to a separate queue for manual review and are not processed further automatically.

**Step 6: Finalization**
For disputes that are not sent to QA, the engine finalizes the process.
1.  The determined response, including the Response Code and Compliance Condition Code, is recorded in the appropriate response table (e.g., Oscar Response, Fax Response).
2.  The dispute’s status is updated to `complete`.

### 6.0 Procedure: Handling Custom Logic for Customers

The rules engine is designed to be extensible through customer-specific logic files.

**Step 1: Create Customer File**
For each customer requiring custom logic, create a new, individual Python file.

**Step 2: Define Custom Rules**
Within the customer's file, define the specific rules, settings, and logic required. This includes defining custom "no-touch" criteria, Compliance Condition Code settings, and any unique response code handling.

**Step 3: Integrate with Main Engine**
The main engine script must be configured to import and call the customer-specific logic. The engine uses the `company ID` from the incoming dispute to dynamically select and execute the correct customer file.

***
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250204_083445-SonnetApplicationDemo1-Recap.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure for the dispute management process.

---

### **Standard Operating Procedure: Dispute Management and System Operations**

**SOP ID:** DM-SOP-001
**Version:** 1.0
**Effective Date:** October 26, 2023
**Approved By:** [Approver's Name/Title]

---

**1.0 PURPOSE**

This Standard Operating Procedure (SOP) outlines the standardized process for accessing the dispute management system, processing consumer disputes (including ACDVs), handling special cases like duplicates and notifications, and utilizing advanced system functions such as creating Automated Update Disputes (AUDs) and custom work queues. The goal is to ensure consistent, accurate, and efficient dispute resolution in compliance with regulatory requirements.

**2.0 SCOPE**

This SOP applies to all personnel, including dispute resolution specialists, quality assurance staff, and system administrators, who are responsible for processing, managing, and overseeing consumer disputes within the [System Name] platform.

**3.0 DEFINITIONS**

*   **ACDV (Automated Consumer Dispute Verification):** A standardized electronic transaction used to verify consumer dispute information with data furnishers.
*   **AUD (Automated Update Dispute):** An internal process initiated by a user to correct or update consumer information on a trade line within the system.
*   **Dispute State:** The status of a dispute within its lifecycle (e.g., New, Active, Work in Progress (WIP), QA).
*   **Queue:** A virtual waiting line in the system where disputes are organized based on their status or specific criteria (e.g., New Queue, Response Queue, Custom Work Queue).
*   **Response Code:** A code assigned by the system's rules engine that dictates the type of response to be sent back to the credit bureau.
*   **SSO (Single Sign-On):** An authentication method that allows users to log in with a single set of credentials. Access is often determined by the user's IP address.
*   **Trade Line:** An entry on a credit report representing a credit account.

**4.0 PROCEDURE**

**4.1 System Access and Dashboard Navigation**

1.  **Log In to the System:**
    *   **SSO Login:** If accessing the system from a recognized company IP address, the system will automatically log you in via SSO.
    *   **Username-Password Login:** If accessing from an external IP address, you will be prompted to enter your assigned username and password.

2.  **Navigate the Dashboard:**
    *   Upon login, the main dashboard will be displayed.
    *   The dashboard consists of various **tiles**. Each tile represents a specific work queue or a category of disputes (e.g., New Disputes, Response Queue, QA).
    *   Click on a tile to access the corresponding queue and view the disputes within it.

**4.2 Standard Dispute Processing Workflow (ACDV)**

This workflow follows a three-step data exchange process: (1) downloading the dispute, (2) receiving system of record information, and (3) sending the response.

1.  **Access New Disputes:**
    *   From the dashboard, navigate to the **New Disputes** queue. This queue contains disputes that have been received from the bureaus but have not yet been worked.

2.  **Review Dispute Information:**
    *   Open a dispute from the queue to view its details.
    *   Familiarize yourself with the **Consumer Information** tab, which includes the following key columns:
        *   **Oscar Column:** Displays the original dispute information as received from the credit bureau.
        *   **Primary Column:** Displays the corresponding information from the primary system of record.
        *   **Secondary Column:** Displays information from any secondary systems of record, if applicable.
        *   **Recommended Response Column:** Displays the response code automatically assigned by the system's rules engine. **Note:** A response code must be present for every dispute before it can be resolved.

3.  **Process the Dispute and Manage States:**
    *   The system moves disputes through several states based on user actions:
        *   **New:** The initial state upon receipt.
        *   **Active/WIP (Work in Progress):** The state when a user opens and begins working on the dispute.
        *   **QA (Quality Assurance):** The state after a user submits the dispute for review (if applicable to the workflow).
        *   **Response Queue:** The final state before the response is sent.
    *   Verify the information across the Oscar, primary, and secondary columns.
    *   Confirm the system-assigned **Response Code** is accurate based on your investigation.
    *   Once your review is complete, take the appropriate action to advance the dispute (e.g., "Submit," "Send to QA").

4.  **Submit the Final Response:**
    *   Disputes that are ready to be sent back to the bureau will move to the **Response Queue**.
    *   This action requires explicit user submission. The system does not automatically send responses.
    *   Monitor the Response Queue for any errors. If an error occurs, the dispute will be flagged. Open the dispute to investigate and resolve the error before resubmitting.

**4.3 Handling Special Cases and Notifications**

1.  **Managing Duplicate Disputes:**
    *   The system automatically identifies and groups **duplicate disputes** (i.e., multiple disputes received for the same account number).
    *   When you open a dispute that is part of a duplicate group, the system will indicate this.
    *   Process the group of disputes as a single unit to ensure a consistent response is provided for all related inquiries.

2.  **Handling Block Notifications:**
    *   **Block Notifications** are generated to block a trade line, typically in cases of reported identity theft.
    *   Access these notifications from the relevant queue on the dashboard.
    *   Review the block request and the associated trade line information.
    *   Take the required action as per company policy (e.g., apply the block, deny the request with justification).

3.  **Handling AUD and Other Notifications:**
    *   The system generates various other notifications (e.g., AUD notifications, Dr. notifications) that appear in designated queues.
    *   Routinely check these queues.
    *   Review and take the necessary action for each notification according to its type and instructions.

**4.4 Advanced Functions**

1.  **Creating an Automated Update Dispute (AUD):**
    *   Use the AUD function to manually correct or update inaccurate information in the system of record (e.g., fix a typo, update a trade line).
    *   **Step 1:** Identify a dispute or account requiring a data correction.
    *   **Step 2:** Navigate to the **Create AUD** function within the system.
    *   **Step 3:** Enter the corrected or updated information into the required fields.
    *   **Step 4:** Submit the AUD. The system will process the update and generate a notification upon completion.

2.  **Creating and Managing Custom Work Queues (Admins/Authorized Users):**
    *   Custom work queues allow for the filtering and organization of disputes based on user-defined criteria.
    *   **Step 1:** Navigate to the queue management section of the system.
    *   **Step 2:** Select the option to create a new custom work queue.
    *   **Step 3:** Define the filtering criteria for the queue (e.g., specific dispute codes, a particular data furnisher, a date range).
    *   **Step 4:** Assign a clear and descriptive name to the queue.
    *   **Step 5:** Save the queue. It will now appear on the dashboard for users with the appropriate permissions.

---

**5.0 REVISION HISTORY**

| Version | Date | Author | Summary of Changes |
| :--- | :--- | :--- | :--- |
| 1.0 | 10/26/2023 | SOP Generator | Initial document creation based on key topics from training session. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250204_083445-SonnetApplicationDemo1.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure (SOP).

***

### **Standard Operating Procedure: Sonnet Dispute Resolution and Data Exchange Process**

**SOP ID:** SON-DRP-001
**Version:** 1.0
**Effective Date:** [Date]
**Approved By:** [Approver Name/Title]

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) outlines the standardized process for accessing the Sonnet application, managing the eOscar data exchange, and resolving consumer credit disputes. The objective is to ensure consistent, accurate, and compliant handling of all dispute-related activities within the Sonnet platform.

### **2.0 Scope**

This SOP applies to all company personnel, including dispute analysts, Quality Assurance (QA) staff, and administrators, who are responsible for the investigation, processing, and resolution of consumer disputes received via the eOscar system.

### **3.0 Definitions**

*   **Sonnet:** The primary web application used for managing and resolving consumer credit disputes.
*   **eOscar:** The electronic system for the exchange of credit dispute information with credit reporting agencies (CRAs).
*   **SOR (System of Record):** The client's primary database containing account and consumer information.
*   **SSO (Single Sign-On):** An authentication method allowing users to log in with a single set of credentials.
*   **AUD (Automated Update Dispute):** A dispute type created to proactively update or correct consumer information with the credit bureaus after an initial response has been sent.
*   **Block Notification:** A notification from a credit bureau indicating a trade line has been blocked, often due to identity theft.
*   **BRR (Block Recission Request):** A request created in Sonnet to reinstate a trade line that was previously blocked.
*   **360 View:** A feature in Sonnet that consolidates all disputes associated with a single account number.

### **4.0 Prerequisites**

*   User must have a valid Sonnet user account.
*   User must be on an authorized network for SSO or have their username and password for standard login.
*   User must know which client company they are servicing to select the correct environment.

### **5.0 Procedure**

#### **5.1 System Access and Login**

1.  **Navigate to the Sonnet URL.**
2.  The system will automatically determine the appropriate login screen based on the user's IP address and the client's configuration.
    *   **SSO Login:** If the user's IP address is whitelisted at the Organization level for an SSO-configured client, the user will be directed to the SSO login page.
    *   **Standard Login:** If the user is outside the whitelisted network or is a non-SSO user, they will be presented with the standard username and password login screen.
3.  Enter the required credentials to log in.
4.  Upon successful login, if applicable, select the appropriate company being serviced to access the relevant work environment (e.g., Sonnet Admin or Sonnet Demo/Production).

#### **5.2 Automated Data File Exchange**

This process is largely automated by the system but is critical for users to understand.

1.  **Step 1: Initial Data Ingestion:** Sonnet receives an initial dispute file from eOscar. This file contains partial data necessary to identify the consumer and account.
2.  **Step 2: Data Enrichment:** Sonnet uses the data from the eOscar file to perform a lookup against the client’s System of Record (SOR). It retrieves and attaches the matching, complete account and consumer information to the dispute record within Sonnet.
3.  **Step 3: Response Transmission:** After a user completes the investigation and submits a response (see section 5.4), Sonnet packages the account/consumer information and the resolution into a response file and sends it back to eOscar for processing.

#### **5.3 Dispute Investigation Process**

1.  **Access Dispute:** From the work queue, open a dispute. A dispute's state will change throughout its lifecycle (e.g., New, Active, WIP, QA, Completed, Error) based on user actions.
2.  **Utilize 360 View:** Immediately upon opening a dispute, review the **360 View**. This view displays all historical and current disputes for the same account number, allowing for a comprehensive understanding and the ability to group responses if necessary.
3.  **Conduct Investigation:** Perform all necessary research and analysis to validate the dispute.
4.  **Complete Checklist:** Use the integrated **Checklist** feature within Sonnet to guide the investigation. Mark off each item as it is verified to ensure all required steps are completed and to maintain a clear audit trail.

#### **5.4 Response Submission and Error Handling**

1.  **Submit Response:** Once the investigation is complete and the checklist is finalized, submit the dispute response via the Sonnet interface.
2.  **Monitor Submission Status:**
    *   **Successful Submission:** The dispute status will update (e.g., to "Completed"), and the response is sent to eOscar as described in Step 3 of the data exchange process (Section 5.2).
    *   **Submission Error:** If an error occurs during transmission to eOscar, Sonnet will display an error message to the user. The dispute will remain in the response queue. The user must review the error, correct the data or configuration issue, and re-submit the response.

#### **5.5 Handling Special Cases**

1.  **Creating an Automated Update Dispute (AUD):**
    *   **Condition:** An AUD is required when information needs to be corrected or updated after an initial dispute response has already been sent to the bureaus.
    *   **Action:** Within Sonnet, initiate an AUD. Populate the required fields with the correct information and submit it to the bureaus.
2.  **Managing Block Notifications:**
    *   **Condition:** A Block Notification is received from a bureau when a trade line is blocked (e.g., due to reported identity theft).
    *   **Action:** Review the Block Notification in Sonnet. If the investigation determines the block should be lifted, create a **Block Recission Request (BRR)** to reinstate the trade line and submit it.

### **6.0 Responsibilities**

*   **Dispute Analysts:** Responsible for executing steps 5.1, 5.3, 5.4, and 5.5 in their daily work.
*   **System Administrators:** Responsible for managing user access, SSO configurations, and troubleshooting high-level system errors.
*   **QA Personnel:** Responsible for reviewing completed disputes to ensure adherence to this SOP.

### **7.0 References**

*   Meeting and Q&A Session on Sonnet Functionality, dated [Date of Meeting].

---
**End of Document**
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250204_110748-SonnectApplicationDemo2-Recap (1).txt
Of course. Based on the document provided, here is a professional Standard Operating Procedure (SOP) for managing credit bureau notifications and responses.

---

### **Standard Operating Procedure: Managing Credit Bureau Notifications and Responses**

**SOP ID:** FIN-CB-001
**Version:** 1.0
**Effective Date:** October 26, 2023
**Author:** SOP Generation Expert
**Approved By:** [Manager/Department Head Name]

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) outlines the required steps for receiving, reviewing, processing, and responding to various notifications from credit bureaus. The purpose is to ensure timely, accurate, and compliant handling of Automated Universal Dataform (AUD) submissions, Block Notifications, Block Re-insertion Requests (BRR), and other bureau-initiated data modifications.

### **2.0 Scope**

This SOP applies to all personnel responsible for data furnishing, credit reporting compliance, and dispute resolution who interact with the credit bureau notification platform. This includes reviewing notifications, updating internal systems, and submitting responses to the bureaus.

### **3.0 Definitions**

*   **AUD (Automated Universal Dataform) Notification:** A notification from a credit bureau informing the data furnisher of the processing status (successful or failed) of a submitted data transaction.
*   **Block Notification:** A directive from a credit bureau to block a consumer's information or specific trade lines, typically due to reported identity theft.
*   **BRR (Block Re-insertion Request):** A process initiated by the data furnisher to request that a previously blocked trade line be re-inserted into a consumer's credit file, with supporting evidence.
*   **Doctor Notification:** A general term for notifications from the bureau regarding any changes they have made to a trade line, including dispute responses, BRR outcomes, modifications, or deletions.
*   **Data Furnisher:** The entity (our organization) providing consumer credit information to the credit bureaus.
*   **Bureau:** A national credit reporting agency (e.g., Experian, Equifax, TransUnion).

### **4.0 Responsibilities**

*   **Data Analyst / Specialist:** Responsible for executing the procedures outlined in this SOP, including reviewing daily notifications, taking appropriate action, and documenting all steps.
*   **Compliance Manager / Supervisor:** Responsible for overseeing the process, ensuring adherence to regulatory timelines (e.g., 30-day dispute resolution), and providing guidance on complex cases.

### **5.0 Procedure**

#### **5.1 Handling AUD Notifications**

This procedure ensures that all submitted data transactions are successfully processed by the bureau.

1.  **Access Notifications:** Log in to the bureau interface and navigate to the AUD Notifications queue.
2.  **Review Status:** Review each notification to determine its processing status.
3.  **Process "Accepted" Notifications:** For notifications indicating the AUD was successfully processed, no further action is required. Archive the notification according to record-keeping policies.
4.  **Process "Rejected" Notifications:** If an AUD was not processed, carefully read the reason provided (e.g., "incorrect account number," "invalid data format").
5.  **Correct Data:** Locate the corresponding record in the internal system of record and correct the identified error.
6.  **Resubmit Transaction:** Create and submit a new, corrected AUD transaction for the consumer.
7.  **Document:** Log the error, the correction, and the resubmission date in the appropriate tracking system.

#### **5.2 Handling Block Notifications**

This procedure ensures compliance with bureau directives to block information related to identity theft.

1.  **Access Notifications:** Navigate to the Block Notifications queue.
2.  **Review Block Details:** Open each notification and review the specific consumer information and/or trade lines that the bureau has blocked.
3.  **Validate the Block:** Conduct an internal review to determine the validity of the block.
    *   **If the block is deemed valid:** Proceed to Step 4.
    *   **If the block is deemed incorrect or invalid:** Proceed to Section 5.3 (Initiating a BRR).
4.  **Update Internal Systems:** If the block is valid, update the internal system of record to flag the account/trade line. This flag must prevent any future re-reporting of the blocked information to the bureau.
5.  **Archive:** Once action is complete, archive the notification.

#### **5.3 Initiating a Block Re-insertion Request (BRR)**

This procedure is used when a data furnisher disputes the validity of a block and has proof to support its re-insertion.

1.  **Locate Original Block:** Find the original Block Notification corresponding to the trade line you intend to dispute.
2.  **Initiate BRR:** Select the option to initiate a BRR. The system will pre-populate the BRR form with information from the block notification.
3.  **Verify Information:** Carefully verify the accuracy of all pre-filled information.
4.  **Attach Proof:** Attach all necessary documentation and evidence proving that the block was applied in error and the debt is valid.
5.  **Complete Attestation:** Complete the required attestation statement, legally affirming the validity of the re-insertion request and the provided evidence.
6.  **Submit Request:** Submit the completed BRR form to the bureau.
7.  **Monitor for Response:** Monitor the Doctor Notifications queue for the bureau’s response to the BRR.

#### **5.4 Reviewing Doctor Notifications**

This procedure ensures that all bureau-initiated changes are reviewed and synchronized with internal systems.

1.  **Access Notifications:** Regularly monitor the Doctor Notifications queue.
2.  **Review Bureau Actions:** Review each notification to understand the changes made by the bureau. This includes:
    *   Dispute response outcomes.
    *   BRR decisions (approved or denied).
    *   Modifications or deletions of trade lines.
3.  **Update Internal Systems:** Update the internal system of record to align with the final action taken by the bureau.
4.  **Archive:** Archive the notification once the corresponding internal record is updated.

#### **5.5 Proactive Management and Reporting**

These features should be used for efficient workflow management and oversight.

1.  **Custom Queues:** As needed, create custom queues to filter and group specific transaction types (e.g., "All Open Block Notifications," "Rejected AUDs for Q3"). This allows for focused worklists.
2.  **Reporting:** Run reports from any queue for analysis or record-keeping. Reports can be viewed on-screen or downloaded as Excel files for further manipulation.
3.  **Look Ahead Feature:** On a regular basis (e.g., weekly), review the "Look Ahead" feature.
    *   Identify any disputes that are approaching or have exceeded the 30-day resolution window.
    *   Prioritize these items to ensure a timely response and maintain regulatory compliance.

---
### **6.0 Revision History**

| Version | Date           | Author                 | Summary of Changes |
|---------|----------------|------------------------|--------------------|
| 1.0     | 10/26/2023     | SOP Generation Expert  | Initial document creation. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250204_110748-SonnectApplicationDemo2.txt
Of course. Based on the document provided, here is a professional Standard Operating Procedure for managing credit bureau notifications and responses.

***

### **Standard Operating Procedure: Managing Bureau Notifications and Disputes**

| **SOP ID:** | DFC-001 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Department:** | Data Furnishing & Compliance | **Effective Date:** | [Date] |
| **Approved By:** | [Approver's Name/Title] | **Review Cycle:** | Annual |

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) outlines the required steps for reviewing, processing, and responding to various notifications received from the Credit Bureau. The objective is to ensure timely and accurate management of consumer data, dispute responses, and system reporting in compliance with regulatory standards.

### **2.0 Scope**

This SOP applies to all personnel within the Data Furnishing & Compliance department responsible for interacting with the Bureau's data management platform. This includes handling Automated Universal Data (AUD) notifications, Block notifications, Dispute Response (DR) notifications, and generating system reports.

### **3.0 Definitions**

*   **AUD (Automated Universal Data) Notification:** An automated communication from the Bureau confirming if a data submission for a consumer was successfully processed or rejected, including the reason.
*   **Block Notification:** A notification informing the data furnisher that a consumer's information has been blocked, typically due to reported identity theft.
    *   **Block Tradeline:** The entire account or trade line for a consumer is blocked.
    *   **Block ID:** A specific piece of consumer information (e.g., name, address, SSN) is blocked.
*   **BRR (Block Precision Request):** A formal request submitted by the data furnisher to the Bureau to re-insert a previously blocked trade line, supported by evidence.
*   **DR (Dispute Response) Notification:** A notification detailing actions taken by the Bureau on a trade line in response to a consumer dispute, a BRR, or other internal reviews. Actions may include modification or deletion.
*   **Trade Line:** An industry term for a credit account record on a consumer's credit report.

### **4.0 Procedures**

#### **4.1 Procedure: Reviewing and Processing Automated Universal Data (AUD) Notifications**

1.  **Access Notifications:** Navigate to the AUD notifications section within the system.
2.  **Review Details:** For each notification, carefully review the following key information:
    *   Consumer's Name and Account Information.
    *   Processing Status (Processed or Not Processed).
    *   Reason Code/Message provided by the Bureau.
3.  **Take Action:**
    *   **If Processed:** No further action is required unless internal reconciliation flags a discrepancy.
    *   **If Not Processed:** Analyze the reason for rejection. Take the necessary corrective action in the source system and resubmit the data as required.

#### **4.2 Procedure: Managing Block Notifications**

1.  **Access Notifications:** Navigate to the Block Notifications queue in the system.
2.  **Identify Block Type:** Determine if the notification is for a **Block Tradeline** or a **Block ID**.
3.  **Review and Update Systems:**
    *   Thoroughly review the consumer information and/or trade line specified in the block.
    *   Update internal systems immediately to cease reporting the blocked information to prevent re-reporting. This is a critical compliance step.
4.  **Evaluate and Respond:**
    *   **If the block is valid:** Confirm the update in the internal system and archive the notification.
    *   **If you disagree with the block and have valid evidence:** Initiate a Block Precision Request (BRR) to request re-insertion of the data. Proceed to Procedure 4.3.

#### **4.3 Procedure: Creating and Submitting a Block Precision Request (BRR)**

1.  **Initiate BRR:** Navigate to the BRR creation module within the system.
2.  **Enter Required Information:** Populate all mandatory fields with complete and accurate information:
    *   Subscriber Codes
    *   Consumer Information (Name, Address, SSN, etc.)
    *   Account Information (Trade line details)
3.  **Provide Attestation:** Attach or reference the evidence supporting the re-insertion request. This must be accompanied by a formal attestation certifying the accuracy and validity of the evidence.
4.  **Submit for Review:** Submit the completed BRR to the Bureau for processing and review. Monitor the status of the request via DR Notifications (see Procedure 4.4).

#### **4.4 Procedure: Reviewing Dispute Response (DR) Notifications**

1.  **Access Notifications:** Navigate to the DR Notifications section. These notifications report the final outcome of disputes, BRRs, or other Bureau-initiated changes.
2.  **Review Action Taken:** Identify the action performed by the Bureau on the trade line (e.g., "Modified," "Deleted").
3.  **Reconcile Records:** Update internal systems to align with the outcome reported in the DR notification. Document the change for audit and history purposes.

### **5.0 System Navigation and Reporting**

#### **5.1 Procedure: Searching and Filtering Transactions**

1.  **Perform Search:** Use the system's search functionality with specific fields (e.g., consumer name, account number, status) to locate individual transactions.
2.  **Create Custom Queues:** To manage workflow efficiently, build and save custom queues to filter for specific transaction types (e.g., all transactions with images attached, all transactions with an "Active" status).

#### **5.2 Procedure: Generating and Accessing Reports**

1.  **Access Reports Module:** Navigate to the "Reports" section of the platform.
2.  **Select a Report:** Choose a report based on transaction type (e.g., ACDV, BRR, Direct Notifications).
3.  **Generate and View:**
    *   Reports can be viewed directly on-screen for quick analysis.
    *   Reports can be downloaded as Excel files for offline analysis, sharing, or record-keeping.
4.  **Custom Reports:** If a standard report does not meet a specific need, submit a request for a custom report through the designated channel.

#### **5.3 Procedure: Utilizing the Look-Ahead Feature**

1.  **Access Feature:** Navigate to the "Look-Ahead" feature on the system dashboard.
2.  **Analyze Workload:** Review the 30-day rolling forecast, which displays the count of pending disputes organized by their due date.
3.  **Plan Resources:** Use this data to anticipate workload peaks, manage team capacity, and ensure all disputes are addressed within their required timeframes.

---
**End of SOP**
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250204_113032-LocalEnvironementSetup-Recap (1).txt
Of course. Here is a professional Standard Operating Procedure (SOP) based on the provided document.

***

### **Standard Operating Procedure: Local Development Environment Setup**

| | |
| :--- | :--- |
| **SOP ID:** | PAL-DEV-001 |
| **Title:** | Local Development Environment Setup for Palinode Web Application |
| **Version:** | 1.0 |
| **Effective Date:** | [Date] |
| **Author:** | Chip Steen, Senior Engineer |
| **Approved By:** | [Approver Name/Title] |

---

**1.0 PURPOSE**

This Standard Operating Procedure (SOP) provides a standardized, step-by-step guide for setting up a local development environment for the Palinode core web application. The objective is to ensure consistency, reduce setup time, and accurately replicate the production server environment on a local machine using Laravel Homestead and Vagrant.

**2.0 SCOPE**

This SOP applies to all software engineers and developers at Palinode responsible for developing, testing, or maintaining the core web application.

**3.0 PREREQUISITES**

Before beginning this procedure, the developer must have the following software installed on their local machine:

*   **Git:** For version control and cloning repositories.
*   **A Supported Virtualization Provider:** VirtualBox is the recommended provider for Vagrant.
*   **Vagrant:** For building and managing virtual machine environments.
*   **Composer:** A dependency manager for PHP.
*   **NVM (Node Version Manager):** To manage Node.js versions for JavaScript dependencies.

---

**4.0 PROCEDURE**

This procedure is divided into five main sections: initial project setup, Homestead configuration, virtual environment launch, application dependency installation, and final application configuration.

**4.1 Section 1: Initial Repository & Homestead Setup**

1.  **Clone the Web Application Repository:** Open a terminal or command prompt and navigate to your preferred development directory. Clone the Palinode web application project.
    ```bash
    git clone [URL_to_Palinode_Web_App_Repository]
    ```

2.  **Clone Homestead:** Clone the Laravel Homestead repository into the same parent directory.
    > **Important:** Ensure you check out the `release` branch to get the most recent stable configuration.
    ```bash
    git clone https://github.com/laravel/homestead.git
    cd homestead
    git checkout release
    cd ..
    ```
3.  **Initialize Homestead:** From within the `homestead` directory, run the initialization script. This will create the `Homestead.yaml`, `after.sh`, and `aliases` files.
    *   For macOS / Linux:
        ```bash
        bash init.sh
        ```
    *   For Windows:
        ```bash
        init.bat
        ```

**4.2 Section 2: Homestead Configuration (`Homestead.yaml`)**

1.  **Open the Configuration File:** Edit the `Homestead.yaml` file located in the `homestead` directory.

2.  **Configure System Resources:**
    *   Set the IP address for the virtual machine (VM).
        `ip: "192.168.56.4"`
    *   Allocate sufficient memory. A minimum of 4096MB (4GB) is recommended.
        `memory: 4096`

3.  **Map Folders:** Map your local project folder to a corresponding folder inside the Vagrant VM.
    ```yaml
    folders:
        - map: C:/path/to/your/local/code/palinode-webapp # Update with your local path
          to: /home/vagrant/code/palinode-webapp
    ```

4.  **Map Sites:** Map a local domain to the web application's public directory inside the VM.
    ```yaml
    sites:
        - map: palinode.test
          to: /home/vagrant/code/palinode-webapp/public
    ```
5.  **Configure Database:** Specify the name for the application's database.
    `databases:`
    `- palinode`

6.  **Enable Redis:** Enable Redis for caching purposes. This is the recommended default setting.
    `redis: true`

**4.3 Section 3: Launching and Accessing the Virtual Environment**

1.  **Update Hosts File:** To access the local site via the mapped domain (`palinode.test`), you must update your local machine's `hosts` file.
    *   **macOS/Linux:** `/etc/hosts`
    *   **Windows:** `C:\Windows\System32\drivers\etc\hosts`
    *   Add the following line, matching the IP from your `Homestead.yaml`:
        ```
        192.168.56.4  palinode.test
        ```

2.  **Start the Vagrant VM:** Navigate to the `homestead` directory in your terminal and run the `vagrant up` command. This will provision and start the VM.
    ```bash
    cd homestead
    vagrant up
    ```

3.  **Connect to the VM:** Once the VM is running, connect to it via SSH.
    ```bash
    vagrant ssh
    ```

**4.4 Section 4: Application and Dependency Installation (Inside the VM)**

1.  **Navigate to Project Directory:** Once inside the VM via SSH, navigate to the project directory you mapped in `Homestead.yaml`.
    ```bash
    cd /home/vagrant/code/palinode-webapp
    ```
2.  **Create Environment File:** Create the `.env` configuration file by copying the example file. This file stores environment-specific variables.
    ```bash
    cp .env.example .env
    ```

3.  **Install PHP Dependencies:** Install the required PHP packages using Composer.
    > **Note:** PHP 8.2 is the recommended version for package compatibility. The Homestead box will be pre-configured with the correct version. Use the `--no-scripts` flag to prevent artisan scripts from running before the application is fully configured.
    ```bash
    composer install --no-scripts
    ```
4.  **Install JavaScript Dependencies:**
    *   Use NVM to select and use the correct Node.js version for the project.
    *   Install the JavaScript packages using NPM.
    ```bash
    nvm use
    npm install
    ```

**4.5 Section 5: Final Application Configuration**

1.  **Run Artisan Commands:** Execute the following Artisan commands from the project root directory (`/home/vagrant/code/palinode-webapp`) to finalize the setup.
    *   **Generate Application Key:**
        ```bash
        php artisan key:generate
        ```
    *   **Clear Caches:**
        ```bash
        php artisan config:clear
        php artisan cache:clear
        php artisan view:clear
        php artisan route:clear
        ```
    *   **Run Database Migrations & Seeding:**
        ```bash
        php artisan migrate --seed
        ```
2.  **Compile Frontend Assets:** Compile the JavaScript and CSS assets.
    *   For development (with hot-reloading):
        ```bash
        npm run watch
        ```
    *   For a one-time build:
        ```bash
        npm run dev
        ```
3.  **Verify Setup:** Open a web browser on your local machine and navigate to the domain you configured (e.g., `http://palinode.test`). The application should now be running.

---

**5.0 SUPPORTING INFORMATION & APPENDICES**

**5.1 Appendix A: Accessing Server Logs**

To troubleshoot issues, Apache web server logs can be accessed from within the Vagrant VM at the following location:
`/var/log/apache2/`

**5.2 Appendix B: Directory Permissions**

It is critical to ensure that directory permissions within the local VM mirror the production server environment. Improper permissions can lead to application errors. Refer to project-specific documentation for required permissions on directories like `storage` and `bootstrap/cache`.

**5.3 Appendix C: Additional Resources**

The **Azure Configurator repository** contains scripts and configurations used for setting up various projects on the production Linux servers. This repository is a valuable reference for understanding the target server environment and its configurations.

---

**6.0 REVISION HISTORY**

| Version | Date | Author | Description of Changes |
| :--- | :--- | :--- | :--- |
| 1.0 | [Date] | Chip Steen | Initial document creation. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250204_113032-LocalEnvironementSetup.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure (SOP) for setting up the local development environment.

***

### **Standard Operating Procedure: Local Development Environment Setup**

| | |
| :--- | :--- |
| **SOP ID:** | DEV-SETUP-001 |
| **Version:** | 1.0 |
| **Effective Date:** | [Date] |
| **Author:** | SOP Generator |
| **Approved By:** | [Approver's Name/Title] |

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) provides detailed, step-by-step instructions for developers to set up a consistent and functional local development environment for the project. This procedure utilizes Vagrant and Homestead to create a virtualized environment that mirrors production, ensuring compatibility and stability.

### **2.0 Scope**

This SOP applies to all development team members responsible for writing, testing, or maintaining code for the project. It covers the complete setup process from cloning the repository to running the application locally.

### **3.0 Prerequisites**

Before beginning this procedure, ensure the following software is installed on your local machine:
*   Git
*   A supported virtualization provider: VirtualBox or Parallels
*   Vagrant
*   Homestead
*   Node Version Manager (NVM) for managing Node.js versions

### **4.0 Procedure**

This procedure is divided into five distinct phases. Follow each step in the specified order to ensure a successful setup.

#### **Phase 1: Initial Project and Environment Setup**

1.  **Clone Project Repository:** Open your terminal or command prompt and navigate to your desired development directory. Clone the project repository using Git.
2.  **Create `.env` File:** Navigate into the newly cloned project directory and create an empty environment configuration file.
    ```bash
    touch .env
    ```
3.  **Install Vagrant and Homestead:** Follow the official documentation to install Vagrant and add the Homestead Vagrant box.

#### **Phase 2: Homestead Configuration**

1.  **Locate `Homestead.yaml`:** Open the `Homestead.yaml` configuration file located in your Homestead installation directory.
2.  **Configure VM Resources:** Specify the resources for the virtual machine.
    *   `ip`: "192.168.56.56" (or another private IP)
    *   `memory`: 2048 (or higher)
    *   `cpus`: 2 (or higher)
    *   `provider`: `virtualbox` or `parallels`
3.  **Configure SSH Authorization:** Ensure the `authorize` key points to your public SSH key file (e.g., `~/.ssh/id_rsa.pub`).
4.  **Map Folders:** Map your local project folder to the corresponding folder inside the Vagrant environment.
    ```yaml
    folders:
        - map: ~/path/to/your/local/project/sonnet
          to: /home/vagrant/code/sonnet
    ```
5.  **Configure Sites:** Map a local domain to the public directory of your application within the VM.
    ```yaml
    sites:
        - map: sonnet.test
          to: /home/vagrant/code/sonnet/public
    ```
6.  **Enable Features:** It is recommended to enable Redis for caching.
    ```yaml
    features:
        - redis: true
    ```

#### **Phase 3: Launching the Virtual Machine**

1.  **Start the VM:** From your Homestead directory, run the following command to start and provision the virtual machine based on your `Homestead.yaml` configuration.
    ```bash
    vagrant up
    ```
2.  **Reload on Changes (If Applicable):** If you make significant changes to `Homestead.yaml` after the initial setup, run the following command to apply them.
    ```bash
    vagrant reload --provision
    ```
3.  **Connect to VM:** Once the machine is running, connect to it via SSH.
    ```bash
    vagrant ssh
    ```
    *All subsequent commands in Phase 4 should be run inside the Vagrant VM.*

#### **Phase 4: Application and Dependency Setup (Inside VM)**

1.  **Navigate to Project Directory:**
    ```bash
    cd /home/vagrant/code/sonnet
    ```
2.  **Set Directory Permissions:** Assign the correct ownership and permissions to ensure the application can write to necessary directories.
    ```bash
    # Set ownership for the entire project directory
    sudo chown -R vagrant:www-data .

    # Set writable permissions for cache and storage
    sudo chmod -R 777 bootstrap/cache
    sudo chmod -R 777 storage
    ```
3.  **Install PHP Dependencies:** The project requires **PHP 8.2**. Install all required packages using Composer.
    ```bash
    composer install
    ```
4.  **Install JavaScript Dependencies:** Use NVM to select the correct Node.js version and then install packages with NPM.
    ```bash
    # Example: nvm use 18
    npm install
    ```
5.  **Generate Application Key:** Create a unique application key. This command will automatically add the key to your `.env` file.
    ```bash
    php artisan key:generate
    ```
6.  **Finalize `.env` Configuration:** Manually review the `.env` file and populate any remaining values, such as database connections and service credentials, as required for the local environment.

#### **Phase 5: Running the Application**

1.  **Compile Assets:** From the project directory inside the VM, compile front-end assets and start the development server.
    ```bash
    npm run dev
    ```
2.  **Access Application:** Open a web browser on your host machine and navigate to the domain specified in your `Homestead.yaml` file (e.g., `http://sonnet.test`).

### **5.0 Additional Information & Troubleshooting**

*   **PHP Version Compatibility:** This project is strictly compatible with **PHP 8.2**. Using older versions (e.g., 7.2, 7.4) will lead to package installation failures.
*   **Apache Logs:** To troubleshoot server-side issues, Apache logs can be found within the Vagrant VM at `/var/log/apache2/`.
*   **Azure Configurator Repository:** For context, the Azure Configurator repository contains server-level scripts for production and staging environments, managing services like Apache and key management. This is separate from the local development setup.

***
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250204_134354-Architecture-Recap.txt
Of course. Based on the document provided, here is a professional Standard Operating Procedure for the software development lifecycle and release management process.

***

### **Standard Operating Procedure: Software Development Lifecycle and Release Management**

**SOP ID:** SDLC-RM-2024-01
**Version:** 1.0
**Effective Date:** October 26, 2023
**Owner:** Head of Engineering
**Approved By:** [Approver's Name/Title]

---

**1.0 PURPOSE**

This Standard Operating Procedure (SOP) defines the standardized process for software development, from initial feature development to final production deployment. Its purpose is to ensure code quality, maintain system stability, and provide a clear, repeatable workflow for all engineering team members. This procedure covers branching strategies, environment management, testing, and release protocols.

**2.0 SCOPE**

This SOP applies to all personnel involved in the software development lifecycle, including but not limited to Software Developers, Quality Assurance (QA) Engineers, DevOps Engineers, and Product Managers. It governs all code changes to the organization's PHP, Python, and Node.js services, including the web application, API, and core systems.

**3.0 DEFINITIONS**

*   **Repository:** A central location where all code and its revision history are stored (e.g., in Git).
*   **main branch:** The primary development branch that serves as the single source of truth for the upcoming release. All code is integrated here before being deployed to UAT.
*   **feature branch:** A temporary branch created from `main` to develop a new feature or non-urgent bug fix.
*   **release branch:** A stabilized branch created from `main` that is used for final testing in the CQA environment and deployment to Production. This branch is tagged with a version number.
*   **hotfix branch:** A branch created from a `release` tag to address a critical, urgent issue in the Production environment.
*   **Local Development Environment:** A developer's individual machine used for writing and testing code.
*   **UAT (User Acceptance Testing):** An environment where business stakeholders and end-users can test new features to ensure they meet requirements. Deployed from the `main` branch.
*   **CQA (Customer Quality Assurance):** A pre-production staging environment that mirrors Production as closely as possible. Used for final QA testing, regression testing, and performance validation before a release. This environment may be used for validating migrations (e.g., AWS to Azure).
*   **Production:** The live environment used by end-customers.

**4.0 RESPONSIBILITIES**

*   **Developers:** Responsible for creating `feature` and `hotfix` branches, implementing code changes, conducting unit tests, and submitting merge requests.
*   **Tech Leads / Senior Developers:** Responsible for conducting code reviews, approving merge requests into the `main` branch, and creating `release` branches.
*   **QA Engineers:** Responsible for executing test plans, regression testing, and validating functionality in the UAT and CQA environments.
*   **DevOps / Release Manager:** Responsible for managing deployments to all environments (UAT, CQA, Production) and tagging releases.

**5.0 PROCEDURE**

This procedure is divided into two workflows: the standard development lifecycle and the emergency hotfix process.

**5.1 Standard Development and Release Workflow**

**Step 1: Branch Creation**
1.1. Ensure your local `main` branch is synchronized with the remote repository.
1.2. Create a new `feature` branch from the `main` branch.
    *   **Naming Convention:** `feature/<ticket-number>-<short-description>` (e.g., `feature/PROJ-123-user-login-update`).

**Step 2: Local Development**
2.1. Implement all code changes and new functionality within the created `feature` branch.
2.2. Perform unit testing and local validation to ensure the changes meet requirements and do not introduce regressions.
2.3. Commit changes to the `feature` branch with clear, descriptive messages.

**Step 3: Code Review and Merge to `main`**
3.1. Once development is complete, push the `feature` branch to the remote repository.
3.2. Create a merge request (or pull request) to merge the `feature` branch into the `main` branch.
3.3. Assign the merge request to a Tech Lead or Senior Developer for code review.
3.4. The assigned reviewer will assess the code for quality, standards, and functionality. Once approved, the reviewer will merge the code into the `main` branch.

**Step 4: Deployment and Testing in UAT**
4.1. The DevOps team will automatically or manually deploy the latest version of the `main` branch to the UAT environment.
4.2. QA Engineers and relevant business stakeholders will perform user acceptance testing in the UAT environment to validate the new functionality.
4.3. Any bugs found will be documented, and a new `feature` branch will be created to address them, following this same process from Step 1.

**Step 5: Release Preparation and CQA Testing**
5.1. When the `main` branch is stable and ready for a release, the Tech Lead or Release Manager will create a `release` branch from `main`.
    *   **Naming Convention:** `release/v<version-number>` (e.g., `release/v4.1.0`).
5.2. The DevOps team will deploy this `release` branch to the CQA environment.
5.3. QA Engineers will conduct final, comprehensive testing in CQA, including regression tests, performance checks, and integration validation.
5.4. Only critical bug fixes are permitted on a `release` branch. Such fixes must be made in a separate branch and merged into both the `release` branch and the `main` branch to prevent code regression.

**Step 6: Production Deployment**
6.1. Upon successful validation in CQA, the `release` branch is approved for deployment.
6.2. The DevOps team will deploy the `release` branch to the Production environment during a scheduled maintenance window.
6.3. After deployment, the DevOps team will tag the corresponding commit in the `release` branch with the final version number (e.g., `v4.1.0`).
6.4. The `release` branch will be merged back into `main` to ensure any last-minute fixes are incorporated.

**5.2 Hotfix Workflow (Emergency Production Fixes)**

**Step 1: Branch Creation**
1.1. Identify the version tag of the current Production release (e.g., `v4.1.0`).
1.2. Create a `hotfix` branch from that specific release tag.
    *   **Naming Convention:** `hotfix/<ticket-number>-<short-description>` (e.g., `hotfix/PROJ-456-critical-api-error`).

**Step 2: Development and Testing**
2.1. Implement the minimal necessary code change to resolve the critical issue.
2.2. Urgently test the fix in a pre-production environment (ideally CQA) to ensure it resolves the issue without causing side effects.

**Step 3: Emergency Deployment**
3.1. Once validated, the `hotfix` branch is deployed directly to the Production environment.
3.2. After successful deployment, a new version tag is created from the `hotfix` branch (e.g., `v4.1.1`).

**Step 4: Synchronization**
4.1. To ensure the fix is not lost in future releases, the `hotfix` branch **must** be merged back into the `main` branch immediately after the production deployment is complete.

**6.0 REFERENCES**

*   Source Document: Meeting transcript discussing system architecture and development processes.
*   Code Repositories: [Link to Git Repository/Platform]
*   Project Management Tool: [Link to JIRA/Trello/etc.]

**7.0 REVISION HISTORY**

| Version | Date           | Author(s)             | Summary of Changes     |
|---------|----------------|-----------------------|------------------------|
| 1.0     | Oct 26, 2023   | SOP Generation Expert | Initial document creation. |

---
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250204_134354-Architecture.txt
Of course. Based on the document provided, here is a professional Standard Operating Procedure (SOP) for the process of handling batch client data submissions.

***

### **Standard Operating Procedure**

| **SOP Title:** | **Batch Client Data Submission via SFTP** |
| :--- | :--- |
| **SOP Number:** | SYS-PRO-009 |
| **Version:** | 1.0 |
| **Effective Date:** | October 26, 2023 |
| **Department:** | System Operations |
| **Author:** | Process Management |

---

### **1.0 Purpose**

The purpose of this Standard Operating Procedure (SOP) is to define the standardized process for batch clients to securely submit data files, including dispute information, images, and receipts, via the Secure File Transfer Protocol (SFTP) server. This procedure ensures data integrity, security, and the correct routing and processing of all submitted files.

### **2.0 Scope**

This SOP applies to all batch clients who submit data to the system and to the internal automated services responsible for ingesting, processing, and routing these files. The primary services involved are the `datafiles` service and the `move images or name strategy` service.

### **3.0 Definitions**

| Term | Definition |
| :--- | :--- |
| **SFTP Server** | The designated Secure File Transfer Protocol server used for the secure exchange of data files between batch clients and the system. |
| **Batch Client** | A customer who submits data in bulk files (e.g., Step 1, Step 2, Step 3 files) rather than through real-time API interactions. |
| **SSH Credentials** | Secure Shell credentials (e.g., username, private key) required for a client to authenticate and establish a secure connection with the SFTP server. |
| **Datafiles Service** | The automated system component responsible for managing the transfer and initial processing of the primary data files (Step 1, 2, 3) submitted by batch clients. |
| **Move Images or Name Strategy Service** | The automated system component responsible for processing associated dispute images and receipts. It moves and renames these files according to pre-configured, customer-specific settings. |

### **4.0 Responsibilities**

*   **Batch Client:** Responsible for securely connecting to the SFTP server using provided SSH credentials and uploading all required data files, images, and receipts to the correct directory.
*   **System Services (`datafiles`, `move images`):** Responsible for automatically detecting, ingesting, processing, renaming, and routing all submitted files to their correct final destinations within the system.

### **5.0 Procedure**

This procedure outlines the end-to-end flow for submitting and processing batch client files.

**Step 5.1: Client Authentication and Connection**
1.  The batch client must use their provided SSH credentials to establish a secure connection to the company's SFTP server.

**Step 5.2: File Upload**
1.  Once connected, the client navigates to their designated directory.
2.  The client uploads the required data files, which include **Step 1, Step 2, and Step 3 files**.
3.  Any associated dispute images and receipts must be uploaded during the same session to ensure proper linking.

**Step 5.3: Automated Data File Ingestion**
1.  The automated **`datafiles`** service continuously monitors the SFTP server for new file submissions.
2.  Upon detection of new files, the service initiates the transfer and ingestion process for the Step 1, 2, and 3 files into the core system.

**Step 5.4: Automated Image and Receipt Processing**
1.  Concurrently, the **`move images or name strategy`** service identifies the associated image and receipt files that were uploaded.
2.  The service references the pre-configured settings specific to that batch client to determine the correct naming convention and destination folder.
3.  The service automatically renames the files as required and moves them from the SFTP upload directory to the correct, secure customer folder.

**Step 5.5: Process Completion**
1.  The process is considered complete once the `datafiles` service has successfully ingested the data and the `move images or name strategy` service has correctly routed all associated files. The data is now ready for subsequent processing by the core system.

### **6.0 Associated Documents**

*   System Architecture Overview
*   Customer-Specific Configuration Guide
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250205_083736-CoreAPI-Recap.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure for the dispute processing and management workflow.

***

### **Standard Operating Procedure: End-to-End Dispute Management**

| **SOP ID:** | OPS-DM-001 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Process Owner:** | System Architect / Lead Developer | **Approval Date:** | October 26, 2023 |
| **Approved By:** | Management | **Effective Date:** | October 26, 2023 |

---

### **1.0 Purpose**

The purpose of this Standard Operating Procedure (SOP) is to document the standardized, end-to-end procedure for processing client disputes. This document outlines the automated and manual steps required, from initial data ingestion from the source system (Oscar) to final response submission, receipt generation, and ongoing monitoring.

### **2.0 Scope**

This SOP applies to the development and support teams responsible for maintaining and monitoring the dispute management system. It covers the entire lifecycle of a dispute within the system, including:
*   Automated download of dispute data.
*   Internal processing and client notification.
*   Client data retrieval via the Sonnet API.
*   Submission of responses to the Oscar system.
*   Generation of PDF receipts.
*   Procedures for manual monitoring and error handling.

This SOP acknowledges the system's current state, which includes a mix of legacy and modern architectural components.

### **3.0 Definitions**

*   **Oscar:** The primary external system of record and API provider for dispute information.
*   **Sonnet API:** The client-facing API used by clients to pull information regarding their disputes, notifications, and attachments.
*   **Rule Engine:** An internal component that analyzes dispute data and provides tentative, pre-formulated responses.
*   **PM2:** A process manager used for polling tasks, specifically for initiating the submission process to the Oscar API.
*   **Puppeteer:** A library used to programmatically generate PDF documents, such as receipts for submissions.
*   **System of Record (SOR) Connector:** A component used to query a client's own system of record directly for specific data.

### **4.0 Responsibilities**

| Role | Responsibility |
| :--- | :--- |
| **Automated System** | Executes scheduled tasks for data download, processing, submission, and receipt generation. |
| **Support / Operations Team** | Performs manual monitoring of system health, reviews alerts and logs, verifies data totals, and handles errors and exceptions. |
| **Development Team** | Maintains and improves system components, manages code migration, and addresses escalated technical issues. |

---

### **5.0 Procedure: Dispute Processing Workflow**

The dispute management process is divided into five primary phases, executed sequentially.

#### **Phase 1: Dispute Data Ingestion**

This phase covers the automated download of new dispute data from the Oscar system.

**Step 1.1: Initiate Scheduled Download**
*   A scheduled task (job) automatically initiates the dispute download process at a predefined interval.

**Step 1.2: Connect to Source System**
*   The system utilizes the **Oscar connector** to establish a secure connection with the Oscar API.

**Step 1.3: Download Dispute Information**
*   The connector pulls all new dispute data, including case details and associated attachments (e.g., images).

**Step 1.4: Process and Store Attachments**
*   The "move images component" processes and correctly stores all downloaded attachments for future access.

#### **Phase 2: Internal Processing and Client Notification**

This phase involves processing the new data and making it available to clients.

**Step 2.1: Data Staging**
*   The downloaded dispute data is stored in the central database.
    *   **Note:** Multiple services currently access the database directly. This is a known issue impacting synchronization and data consistency that is slated for future improvement via isolated core routes.

**Step 2.2: Apply Rule Engine**
*   The **Rule Engine** analyzes the new dispute and generates a tentative response based on predefined logic.

**Step 2.3: Notify Client**
*   The system executes a step process to formally notify the relevant client of the new dispute.
*   For clients requiring enhanced security, all notification data is encrypted.

**Step 2.4: Enable Client Data Access**
*   Clients can use the **Sonnet API** to pull detailed information about the new dispute, associated notifications, and attachments to inform their response.

#### **Phase 3: Response Submission to Oscar**

This phase covers the submission of the final dispute response back to the Oscar system.

**Step 3.1: Initiate Submission Process**
*   The **PM2** process manager polls the system to identify disputes that are ready for submission.

**Step 3.2: Submit Data via Oscar API**
*   The system calls the **Oscar API** to submit the finalized response data.

**Step 3.3: Verify Data Consistency**
*   Post-submission, a check is performed to ensure the data in the local system is consistent with the data recorded in Oscar.

#### **Phase 4: Receipt Generation**

This phase creates a formal record of the submission for archival and client purposes.

**Step 4.1: Trigger Receipt Generation**
*   Following a successful submission, the receipt generation process is initiated.

**Step 4.2: Create PDF Receipt**
*   The system uses **Puppeteer** to generate a PDF receipt containing all relevant submission details.

**Step 4.3: Store and Distribute Receipt**
*   The generated PDF is stored in the system and made available to the client as proof of submission.

#### **Phase 5: System Monitoring and Error Handling**

This is an ongoing manual oversight process to ensure system integrity and performance.

**Step 5.1: Monitor Automated Alerts**
*   The Support/Operations Team must actively monitor the designated support email account for automated system alerts indicating failures or anomalies.

**Step 5.2: Perform Manual Log Review**
*   The team lead will personally review system logs on a regular basis to proactively identify silent errors or performance degradation that may not trigger an alert.

**Step 5.3: Verify Data Totals**
*   Manually compare the total number of disputes downloaded against source system records to ensure no data was missed during the ingestion process.

**Step 5.4: Escalate and Resolve Issues**
*   If an issue is identified, the Support/Operations Team will perform initial troubleshooting. Issues that cannot be resolved are to be escalated to the Development Team with relevant logs and details.

---

### **6.0 System Considerations and Known Issues**

*   **Legacy Architecture:** The system is a hybrid of legacy and modern code. Care must be taken when implementing new features to ensure compatibility and understand the impact on legacy processes.
*   **Sequential Processing:** The current workflow is largely sequential. This is a known performance bottleneck, and efforts are ongoing to introduce parallelization.
*   **Database Access:** The practice of multiple services accessing the database directly is a known risk. Future development is focused on isolating database interactions through core routes to improve security, testability, and data consistency.

### **7.0 Revision History**

| Version | Date | Author | Summary of Changes |
| :--- | :--- | :--- | :--- |
| 1.0 | 2023-10-26 | SOP Generator | Initial document creation based on technical discussion. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250205_083736-CoreAPI.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure (SOP) for the Sonnet system's operational workflow.

***

### **Standard Operating Procedure: Sonnet System Operational Workflow**

| **SOP ID:** | SON-OPS-001 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Effective Date:** | [Date] | **Author:** | SOP Generation Service |
| **Approved By:** | [Approver's Name/Title] | **Next Review Date:** | [Date + 1 Year] |

---

### **1.0 Purpose**

The purpose of this Standard Operating Procedure (SOP) is to document the end-to-end operational workflow of the Sonnet system. This document outlines the key components, data flow, processing logic, and error handling mechanisms to ensure consistent understanding and management of the system by all relevant personnel.

### **2.0 Scope**

This SOP applies to all technical and operational teams responsible for the maintenance, monitoring, and development of the Sonnet system, including its connectors, APIs, and associated services. It serves as a primary reference for understanding how the system functions as an interface for E-Oscar.

### **3.0 Definitions**

| Term | Definition |
| :--- | :--- |
| **Sonnet System** | The primary application, which serves as an interface to E-Oscar for fetching and processing dispute information for client consumption. |
| **E-Oscar** | The external system of record from which Sonnet fetches data. |
| **System of Record (SOR)** | Client-side systems that may connect to Sonnet for data exchange. |
| **Sonnet API** | The Application Programming Interface that allows clients to programmatically interact with Sonnet for data retrieval and actions. |
| **Rules Engine** | An automated component that analyzes dispute data and generates a tentative response, facilitating faster processing and enabling "no touch" automation. |
| **Move Images Service** | A dedicated service responsible for processing and relocating image files (attachments) to their final destination for client access. |
| **VIPs** | Virtual Image Print System; a technology used for converting and extracting image formats (e.g., TIFF to JPEG). |

### **4.0 Responsibilities**

| Role | Responsibility |
| :--- | :--- |
| **Operations Team** | Monitors system health, manages scheduled jobs (cron jobs), and executes recovery procedures in case of process failure. |
| **Development Team** | Maintains and enhances Sonnet components, including the API, connectors, and Rules Engine. Manages the migration from direct database access to API-centric architecture. |
| **System Administration** | Manages the underlying infrastructure, database security, and access controls. |

### **5.0 Procedure: System Workflow**

This section details the standard operational flow of the Sonnet system, from data ingestion to client presentation.

#### **5.1 Data Ingestion and Initial Processing**

1.  **Data Fetching:** The **E-Oscar Connector** establishes a connection to the E-Oscar system to fetch new or updated information (e.g., disputes).
2.  **Data Structuring:** Ingested data is stored in the Sonnet database. While the database contains `organization`, `company`, and `team` entities, all artifacts are primarily owned and led by the `company` entity.
3.  **Automated Response Generation:** The **Rules Engine** automatically analyzes the newly ingested data.
    *   It generates a *tentative response* for the dispute.
    *   Under specific, pre-defined conditions, it may apply a "no touch" response, allowing for complete automation.
4.  **Workflow Progression:** The data, now enriched with a tentative response, proceeds through the workflow, which also involves the **Notary Service**.

#### **5.2 Data Access and Client Interaction**

Clients can access and interact with the processed data through two primary methods:

1.  **UI-Based Interaction (Front Tab):**
    *   Authorized users access the **Front Tab**, the system's user interface.
    *   Users can review the information and the tentative response provided by the Rules Engine.
    *   Users can then validate, modify, or approve the response before it is finalized.
2.  **API-Based Interaction (Sonnet API):**
    *   Clients utilize the **Sonnet API** for direct, programmatic interaction with the system.
    *   This method allows clients to retrieve active disputes, check responses, receive notifications, and access attachments without relying on manual file transfers.

#### **5.3 Attachment and Image Handling**

1.  **File Conversion:** All incoming attachments and images associated with a case are converted into the standardized **TIFF** file format.
2.  **Image Extraction:** The system uses **VIPs** to process the TIFF files and extract them as **JPEG** images.
3.  **File Relocation:** The **Move Images Service** is triggered to handle the processed JPEGs. This service moves the image files from a temporary or processing location to the final, designated storage location.
4.  **Client Availability:** Once relocated, the images are made available for client consumption via the UI (Front Tab) or the Sonnet API.

#### **5.4 Data Synchronization and Security**

1.  **Synchronization:** System and data consistency are maintained via automated, scheduled processes. These include **periodic triggers** and **cron jobs** that handle data synchronization tasks sequentially.
2.  **Security Protocol:** To enhance data security and system stability, direct access to the Sonnet database is being phased out. All data interactions must be conducted through the secure and controlled **Sonnet API endpoints**.

#### **5.5 Error Handling and Recovery**

The Sonnet system is designed to be resilient. The following procedure applies in the event of a processing failure.

1.  **Identify Failure:** The Operations Team monitors system logs and alerts to identify any failed process or component.
2.  **Initiate Restart:** Most processes are designed to be restartable. The Operations Team can restart the failed process or job.
3.  **System Recovery:** Upon restart, the process is designed to resume from a stable state, ensuring data integrity and preventing adverse effects on other system components.
    *   **Note:** Due to a current dependency on sequential processing, manual intervention may be required to resolve certain failures before a process can be successfully restarted.

### **6.0 System Architecture Overview**

The Sonnet system is composed of several key components that work in concert:

*   **E-Oscar Connector:** The entry point for external data.
*   **Sonnet API:** The primary interface for client interaction and data exchange.
*   **System of Record Connectors:** Facilitates communication with client-side systems.
*   **Rules Engine:** Provides intelligent automation for response generation.
*   **Notary Service:** A component integrated into the core processing workflow.
*   **Front Tab:** The web-based user interface for manual review and interaction.

### **7.0 Revision History**

| Version | Date | Author | Change Description |
| :--- | :--- | :--- | :--- |
| 1.0 | [Date] | SOP Generation Service | Initial document creation based on meeting summary. |
<ctrl63>
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250205_110344-SonnetAPIDocumentation-Recap.txt
Of course. Based on the document provided, here is a professional Standard Operating Procedure (SOP) for the described processes.

***

### **Standard Operating Procedure**

**SOP Title:** BRR Data Exchange and Dispute Resolution via the Sonnet Platform

**SOP Number:** `[SOP-BRR-001]`
**Version:** 1.0
**Effective Date:** `[Date]`
**Department/Owner:** `[Client Operations / Technical Integration]`

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) defines the standardized process for managing credit reporting disputes and other related communications using the Sonnet platform. The procedure covers the end-to-end lifecycle of a dispute, from initial receipt from E-Oscar to final resolution and reporting, including handling direct disputes, notifications, and associated images.

### **2.0 Scope**

This SOP applies to all client users, operations staff, and technical integration teams responsible for processing, managing, and troubleshooting credit dispute data exchanged through the Sonnet API and user interface. This includes handling Automated Consumer Dispute Verifications (ACDVs), Direct Disputes, Notifications, and Block Rescissions.

### **3.0 Definitions**

| Term | Definition |
| :--- | :--- |
| **ACDV** | **Automated Consumer Dispute Verification.** The standard electronic process for handling a consumer dispute received from a credit reporting agency via E-Oscar. |
| **BRR** | **Bureau Reporting and Response.** The overall data exchange functionality and process framework. |
| **Sonnet** | The software platform used to receive, manage, and respond to disputes. |
| **E-Oscar** | The electronic, automated system that facilitates communication between credit reporting agencies and data furnishers for resolving consumer credit disputes. |
| **Sonnet ID** | A unique identifier assigned by the Sonnet system to each dispute record. This ID is critical for tracking and retrieving dispute details throughout the process. |
| **Step 2** | The stage in the process where client-side data is provided or refreshed within Sonnet to be used for dispute resolution. |
| **Step 3** | The stage in the process where an active dispute is worked on, completed, and the resolution is sent back to E-Oscar. |
| **Direct Dispute** | A dispute initiated directly by a consumer to the data furnisher (the client), rather than through a credit reporting agency. |
| **Notification** | A read-only communication item from E-Oscar that does not require a response but must be acknowledged and processed. |

### **4.0 Responsibilities**

*   **Client Users:** Responsible for reviewing disputes, providing necessary documentation and data, making resolution decisions, and processing disputes within the Sonnet platform.
*   **System Administrator/Integration Team:** Responsible for initial setup, managing API authentication, and providing technical support, including use of the debug functionality.
*   **Sonnet Platform:** Responsible for automated ingestion from E-Oscar, data processing, assigning Sonnet IDs, and transmitting responses back to E-Oscar.

---

### **5.0 Procedure**

#### **5.1 System Authentication and Authorization**

1.  **Primary Authentication:** All API interactions with the Sonnet platform must be authenticated using a client-specific API token.
2.  **Enhanced Security (Optional):** For clients requiring an additional layer of security, Mutual TLS (mTLS) authentication can be implemented in addition to the API token.

#### **5.2 Standard ACDV Dispute Workflow**

This workflow outlines the process for disputes received electronically from E-Oscar.

1.  **Step 1: Dispute Ingestion**
    *   The Sonnet platform automatically downloads new ACDVs from E-Oscar.
    *   Each new dispute is assigned a unique **Sonnet ID** for tracking.

2.  **Step 2: Data Refresh and Enrichment**
    *   To ensure Sonnet contains the most current information for decision-making, clients must regularly send updated data to the platform.
    *   **Action:** Send updated "Step 2" information via the designated API endpoint. This keeps the client's internal data synchronized with the dispute records in Sonnet.

3.  **Step 3: Dispute Resolution**
    *   **Action:** Access the Sonnet user interface to view all disputes in an "Active" status.
    *   **Action:** For each dispute, review the details provided by the consumer and the internal data refreshed in Step 2.
    *   **Action:** Make a resolution decision based on internal policies and procedures.
    *   **Action:** Complete the dispute within the Sonnet platform. Upon completion, Sonnet automatically generates and sends the appropriate response back to E-Oscar.
    *   **Note:** The **Sonnet ID** can be used at any time to retrieve the full details of a specific dispute.

#### **5.3 Direct Dispute Workflow**

This workflow is for disputes received directly from consumers (e.g., via mail, phone).

1.  **Action:** For written disputes, scan and upload all relevant consumer-provided documents into the Sonnet platform.
2.  **Action:** For verbal disputes, document the necessary information as per internal policy and prepare it for entry.
3.  **Action:** Within Sonnet, review the uploaded documents or entered information.
4.  **Action:** Initiate a "Step 2 Post" to formally log the dispute and associated data into the Sonnet system, which then follows a resolution path similar to the ACDV workflow.

#### **5.4 Handling Special Communications**

1.  **Notifications**
    *   Notifications are automatically downloaded from E-Oscar into Sonnet.
    *   These items are **read-only** and do not require a response.
    *   **Action:** Review the notification. The item is automatically processed and moved to the "Step 3" (completed) state for record-keeping.

2.  **Block Rescissions**
    *   The process is similar to handling notifications.
    *   **Action:** Create and complete the block rescission within the Sonnet platform.
    *   The item is then moved to the "Step 3" (completed) state for record-keeping.

#### **5.5 Supporting Processes**

1.  **Image Handling**
    *   Images associated with a dispute are downloaded and attached to the corresponding record in Sonnet.
    *   **Limitation:** A maximum of two (2) image files can be associated with a single dispute.
    *   **Troubleshooting:** If an image fails to download or is corrupted, users have the ability to trigger a re-download of the image files for that dispute.

2.  **Troubleshooting via Debug Functionality**
    *   A debug function is available to assist with troubleshooting during initial implementation and for production issues.
    *   **Action:** Clients can use this feature to generate a "debug record" for a specific transaction or dispute.
    *   This record provides detailed technical information that can be provided to support teams for faster issue resolution.

#### **5.6 First Party vs. Third Party Dispute Considerations**

*   Users must be aware of the distinction between first-party and third-party disputes.
*   **First-party disputes** often require more complex decisioning and may have different required data fields compared to third-party disputes.
*   **Action:** Ensure all required fields are populated correctly based on the dispute type and that the investigation is conducted according to the specific compliance requirements for that type.
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250205_110344-SonnetAPIDocumentation.txt
Of course. Here is a professional Standard Operating Procedure (SOP) based on the provided document.

***

### **Standard Operating Procedure: Sonnet System Data Exchange and Dispute Management**

| **SOP ID:** | IT-INT-001 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Department:** | Information Technology / Client Integration | **Effective Date:** | [Date] |
| **Author:** | SOP Generator | **Approved By:** | [Approver Name] |

---

### **1.0 Purpose**

This document outlines the standard procedures for integrating with and utilizing the Sonnet system for managing credit reporting disputes and data exchanges. The procedures herein provide technical specifications for IT users to understand system workflows, endpoints, and transaction types.

### **2.0 Scope**

This SOP applies to all IT personnel, developers, and third-party integrators responsible for building, implementing, and maintaining the data exchange interface with the Sonnet system.

### **3.0 Definitions**

| Term | Definition |
| :--- | :--- |
| **Sonnet** | The primary system for managing disputes and data exchanges. |
| **ACDV** | Automated Consumer Dispute Verification. An indirect dispute originating from the Oscar system. |
| **AUD** | Automated Universal Dataform. A transaction intended to update a consumer's trade line between regular reporting cycles. |
| **BRR** | Bureau Re-Report. A type of data exchange. |
| **CQA** | Client Quality Assurance. The development/testing environment. |
| **SOR** | System of Record. The client's internal system that holds the source data for disputes. |
| **Direct Dispute** | A dispute initiated directly by the consumer with the data furnisher, not through a credit bureau. |
| **Oscar** | The e-OSCAR (Online Solution for Complete and Accurate Reporting) system used by credit bureaus to manage disputes. |

---

### **4.0 Prerequisites: Environment Setup and Authorization**

Before executing any procedures, the user must be configured for the correct operational environment.

1.  **Identify the Environment:** Determine if you are operating in the Production or Development (CQA) environment.
2.  **Obtain Credentials:** Each environment has a unique URL and a specific authorization token. Secure the correct URL and token for the target environment.
3.  **Authentication:** All API calls to the Sonnet system must be authenticated using the environment-specific token.

---

### **5.0 Procedures**

#### **5.1 Handling Indirect Disputes (ACDVs)**

This two-step process is the primary workflow for managing disputes that Sonnet receives from the credit bureaus.

**5.1.1 Step 1: Retrieve Pending Dispute List**
1.  **Action:** Make a GET request to the designated Step 1 endpoint.
2.  **Purpose:** To retrieve a list of all disputes for which Sonnet has not yet received System of Record (SOR) information from the client.
3.  **Outcome:** The system returns a list of pending disputes, each with a unique identifier.

**5.1.2 Step 2: Post Dispute Details**
1.  **Action:** For each dispute retrieved in Step 1, gather the required information from your internal SOR.
2.  **Action:** Make a POST request to the designated Step 2 endpoint, including the detailed information for the specific dispute.
3.  **Purpose:** To provide Sonnet with the necessary data to resolve the dispute.
4.  **Handling Associated Images:**
    *   If a dispute includes associated images (up to five per dispute), they will be provided by Sonnet as Base64 encoded strings.
    *   Use the provided image IDs to make separate calls to download each image file for review.
5.  **Optional - Step 2 Refresh:**
    *   If the SOR data for a dispute has changed since the initial Step 2 post (e.g., due to time elapsed while working the dispute), a Step 2 post can be sent again for the same dispute.
    *   This "refresh" function updates Sonnet with the most current information.

#### **5.2 Handling Direct Disputes**

Direct disputes are managed using a similar process to ACDVs but with different transaction types and endpoints.

*   **Method 1: File Upload**
    1.  The user uploads the direct dispute documentation directly into the Sonnet user interface.
    2.  Once reviewed, Sonnet processes the dispute.
*   **Method 2: Verbal Dispute via API**
    1.  To create a verbal dispute directly, initiate a Step 2 post to the appropriate direct dispute endpoint.
    2.  The post must include a specific transaction type that identifies it as a new verbal dispute.

#### **5.3 Handling Automated Update Documents (AUDs)**

AUDs are used to update a consumer's trade line and are processed differently from disputes.

1.  **Endpoint:** Use the specific endpoint designated for AUDs.
2.  **Required Fields:** The API call must include, at minimum, the following fields:
    *   Transaction Type (to identify it as an AUD)
    *   Account Number
3.  **Action:** Post the AUD transaction to the endpoint to update the trade line in the Sonnet system.

#### **5.4 Processing Read-Only Notifications (Step 3)**

Sonnet issues several types of notifications that are for informational purposes only and do not require a response.

1.  **Notification Types:** Includes AUD notifications, DR (Dispute Resolution) notifications, and block notifications.
2.  **Process Flow:** These notifications bypass Steps 1 and 2 and are available directly via the Step 3 endpoints.
3.  **Action:**
    *   Make a GET request to the Step 3 list endpoint to retrieve a list of all available notifications.
    *   Make a subsequent GET request using a specific notification ID to retrieve the full details of that notification.

---

### **6.0 Troubleshooting**

#### **6.1 Debug Functionality**

The debug function provides enhanced, detailed logging for Step 2 posts to assist with troubleshooting during implementation and production issues.

1.  **Lower Environments (CQA):** The debug flag is **always on** by default in the CQA environment to facilitate development and testing.
2.  **Production Environment:** The debug flag is off by default. To enable it for troubleshooting a specific issue, it must be manually triggered for the relevant Step 2 post.

---

### **7.0 Additional Information**

*   **BRR Data Exchange:** The Bureau Re-Report (BRR) data exchange functionality is live in production. However, client adoption is currently limited. Official documentation is being updated to reflect the latest version.

---

### **8.0 Document Revision History**

| Version | Date | Author | Summary of Changes |
| :--- | :--- | :--- | :--- |
| 1.0 | [Date] | SOP Generator | Initial document creation based on meeting analysis. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250205_113721-APIManagement-Recap.txt
Of course. Here is a professional Standard Operating Procedure (SOP) based on the provided document.

***

### **Standard Operating Procedure: New Client API Onboarding and Configuration**

**SOP Number:** CLD-SEC-004  
**Version:** 1.0  
**Effective Date:** [Date]  
**Owner:** Cloud Infrastructure Team  
**Approved By:** [Approver Name/Title]

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) outlines the standardized, step-by-step process for onboarding a new client for secure API access. The procedure ensures that all configurations for the Azure API Gateway, API Management, Web Application Firewall (WAF), and associated security components are implemented consistently and securely across all environments.

### **2.0 Scope**

This document applies to all personnel responsible for configuring cloud infrastructure, including Cloud Engineers and Security Analysts. It covers the end-to-end setup for new client API integrations in Quality Assurance (QA), User Acceptance Testing (UAT), and Production environments.

### **3.0 Definitions**

*   **API Gateway:** The primary entry point for all external API requests. It is responsible for request routing, security enforcement, and mTLS termination.
*   **API Management (APIM):** The Azure service used to publish, manage, and analyze APIs. It acts as the backend target for the API Gateway.
*   **mTLS (Mutual TLS):** A certificate-based authentication method where both the client and the server validate each other's identity before establishing a secure connection.
*   **WAF (Web Application Firewall):** A security layer that inspects HTTP/S traffic and protects against common web vulnerabilities as defined by standards like the OWASP Top 10.
*   **NSG (Network Security Group):** An Azure resource that filters network traffic to and from Azure resources in an Azure virtual network.

### **4.0 Responsibilities**

*   **Cloud Engineer:** Responsible for executing the technical steps outlined in this procedure, including the configuration of the API Gateway, NSG, and APIM.
*   **Security Analyst:** Responsible for reviewing and approving WAF policies and NSG rules to ensure compliance with security standards.
*   **Project/Account Manager:** Responsible for liaising with the client to gather prerequisite information.

---

### **5.0 Procedure**

This procedure must be followed sequentially for each new client integration.

#### **Step 1: Prerequisite Gathering**

1.1. **Obtain Client Certificate:** Request and receive the public key of the client's certificate. This certificate is required for client authentication at the API Gateway.

1.2. **Obtain Client IP Addresses:** Request and receive a definitive list of all source IP addresses or CIDR blocks from which the client will initiate API requests.

1.3. **Confirm Header Requirements:** Discuss with the client and internal application teams to confirm if the backend API server requires the client certificate information to be passed in a specific HTTP header.

#### **Step 2: Environment Provisioning**

2.1. Confirm that a dedicated API Management service has been provisioned for the target environment (e.g., QA, UAT, Production). UAT and Production environments must be distinct instances.

#### **Step 3: Network and Security Configuration (NSG & WAF)**

3.1. **IP Whitelisting:**
    3.1.1. Navigate to the Azure Portal and locate the Network Security Group (NSG) associated with the API Gateway's subnet.
    3.1.2. Create a new inbound security rule with a priority number that allows it to be evaluated correctly.
    3.1.3. Set the `Source` to the client's IP addresses/CIDR blocks obtained in Step 1.2.
    3.1.4. Set the `Action` to `Allow`.
    3.1.5. Provide a descriptive name for the rule (e.g., `Allow_Inbound_ClientName_UAT`).

3.2. **Web Application Firewall (WAF) Verification:**
    3.2.1. Confirm that a WAF policy is attached to the API Gateway listener.
    3.2.2. Ensure the WAF is set to **Prevention** mode.
    3.2.3. Verify that the policy includes the most current OWASP core rule set to protect against common vulnerabilities and ensure customer data protection.

#### **Step 4: API Gateway Configuration**

4.1. **Frontend Listener & mTLS Setup:**
    4.1.1. Configure a new frontend listener on the API Gateway for the client.
    4.1.2. Associate the appropriate SSL profile for server-side TLS.
    4.1.3. Configure the listener to require and authenticate a client certificate (mTLS). Upload the client's public certificate (from Step 1.1) to the trusted client certificate store on the gateway. This step ensures mTLS is terminated at the gateway.

4.2. **Request Rewrite Rule for Client Certificate:**
    4.2.1. Create a rewrite rule within the API Gateway configuration.
    4.2.2. Configure the rule to capture the authenticated client certificate information (e.g., thumbprint, subject name).
    4.2.3. Add a new HTTP header to the request (e.g., `X-Client-Certificate-Thumbprint`) and populate it with the certificate data. This ensures the backend APIM instance and API server can identify the originating client.

4.3. **Backend Routing:**
    4.3.1. Configure the gateway's routing rule to forward requests from the new listener to the appropriate backend pool, which points to the environment-specific API Management (APIM) service.

#### **Step 5: API Management (APIM) Configuration**

5.1. **Review Inbound Policies:**
    5.1.1. Navigate to the target API in the APIM instance.
    5.1.2. Review the inbound processing policies.
    5.1.3. **Crucially, ensure that the policies do not require a subscription key.** Authentication is fully managed by the API Gateway via mTLS, so APIM-level key validation is redundant and should be disabled for these flows.

5.2. **Verify Custom Domain and Versioning:**
    5.2.1. Confirm that any required custom domains and API versioning schemas are correctly configured within APIM to match the client's expectations.

### **6.0 Logging, Monitoring, and Troubleshooting**

6.1. **Enable Diagnostics:** Ensure diagnostic settings for both the API Gateway and the API Management service are enabled to stream logs and metrics to an Azure Monitor Log Analytics workspace.

6.2. **Detailed Logging:** Configure logging to capture comprehensive request and response data, **including all HTTP headers**. This level of detail is critical for troubleshooting client-side issues and providing definitive proof of where a fault lies during a dispute.

6.3. **Cost Management:** Periodically review the data ingestion and retention costs for the Log Analytics workspace. Adjust data retention policies as needed to manage storage costs effectively while retaining sufficient data for troubleshooting.

### **7.0 Post-Implementation Review**

7.1. **Validation:** Conduct an end-to-end test with the client to validate connectivity and successful API transaction processing.

7.2. **Resource Cleanup:** After a successful implementation, review the Azure resources to identify and remove any redundant or temporary components created during the setup process to optimize costs.
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250205_113721-APIManagement.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure (SOP).

---

### **Standard Operating Procedure: Client API Onboarding and Configuration**

| **SOP ID:** | CLD-SEC-004 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Title:** | Client API Onboarding via Azure Application Gateway | **Effective Date:** | [Date] |
| **Department:** | Cloud Operations / Engineering | **Author:** | SOP Expert |
| **Approved By:** | [Approver's Name] | **Review Cycle:** | 12 Months |

---

### **1.0 Purpose**

This document outlines the standard procedure for onboarding new clients to access internal APIs through the Azure Application Gateway. The process ensures a secure, consistent, and reliable configuration for client communication, including security hardening, traffic management, and troubleshooting.

### **2.0 Scope**

This SOP applies to all Cloud Operations and Engineering personnel responsible for configuring and managing the Azure network and application infrastructure. It covers the end-to-end process from initial client information gathering to final configuration verification and monitoring. This procedure assumes the core Azure Application Gateway and API Management instances are already deployed.

### **3.0 Definitions**

*   **Application Gateway:** The managed Azure service that acts as the primary ingress point for client API requests. It provides Web Application Firewall (WAF) capabilities and handles SSL/TLS termination.
*   **API Management (APIM):** The Azure service acting as a proxy between the Application Gateway and the backend API server. It manages policies, custom domains, and API versioning.
*   **Network Security Group (NSG):** A virtual firewall for Azure resources that contains a list of security rules to allow or deny network traffic.
*   **mTLS (Mutual TLS):** A method of authentication where both the client and server present digital certificates to verify each other's identity.

### **4.0 Responsibilities**

*   **Client Onboarding Team:** Responsible for gathering technical requirements from the new client, including IP addresses and security certificates.
*   **Cloud Engineer:** Responsible for executing the technical configuration steps detailed in this SOP within the Azure environment.
*   **Security Team:** Responsible for auditing and approving NSG rule changes and certificate configurations.

### **5.0 Procedure**

#### **5.1 Phase 1: Client Information Gathering**

1.  **Obtain Client IP Addresses:** Request and receive the client's public source IP addresses or CIDR blocks that will be used to access the API. This information is mandatory for whitelisting.
2.  **Obtain Client Certificates:** Request and receive the client's public **Root and Intermediate certificates**.
    *   **NOTE:** The client's specific end-user (leaf) certificate is not required for the Application Gateway configuration. The gateway validates the client's request using the trusted certificate chain.

#### **5.2 Phase 2: Azure Application Gateway Configuration**

1.  **Update SSL Profile for Client Authentication:**
    a. In the Azure Portal, navigate to the primary Application Gateway instance.
    b. Go to **SSL profiles** under the **Settings** section.
    c. Select the appropriate SSL profile used for client authentication or create a new one.
    d. Under the "Client Authentication" tab, upload the client's Root and Intermediate certificates to the "Trusted client CA certificate chain."
    e. Save the changes to the SSL profile.

2.  **Verify Front-End Listener:**
    a. Go to **Listeners** under the **Settings** section.
    b. Ensure the listener is configured to use the SSL profile updated in the previous step.
    c. Confirm the listener is active and associated with the correct public front-end IP address and port.

#### **5.3 Phase 3: Network Security Group (NSG) Whitelisting**

1.  **Identify the Correct NSG:** Navigate to the Network Security Group associated with the Application Gateway's subnet.
2.  **Add Inbound Security Rule:**
    a. Select **Inbound security rules** from the NSG menu.
    b. Click **+ Add**.
    c. Configure the rule as follows:
        *   **Source:** `IP Addresses`
        *   **Source IP addresses/CIDR ranges:** Enter the client IP addresses gathered in step 5.1.1.
        *   **Source port ranges:** `*`
        *   **Destination:** `Any`
        *   **Service:** `Custom`
        *   **Destination port ranges:** `443` (or as required)
        *   **Protocol:** `TCP`
        *   **Action:** `Allow`
        *   **Priority:** Assign a priority number that ensures it is evaluated correctly (e.g., lower number for higher priority).
        *   **Name:** Use a descriptive name (e.g., `Allow-Inbound-[ClientName]-API-Access`).
    d. Click **Add** to create the rule.

#### **5.4 Phase 4: Verification and Monitoring**

1.  **Confirm API Management Path:** Ensure the API Management instance is correctly configured to receive traffic from the Application Gateway and route it to the appropriate backend API server. Verify that any necessary inbound policies or custom domain settings are in place.
2.  **Enable Comprehensive Logging:**
    a. Navigate to **Diagnostic settings** for both the Application Gateway and the API Management instance.
    b. Ensure logging is enabled and configured to send data to an Azure Monitor Log Analytics workspace.
    c. Set sampling to **100%** to capture all requests, errors, source IPs, and headers for effective troubleshooting.
3.  **Conduct End-to-End Test:** Coordinate with the client to perform a test request to validate the entire connection flow.

### **6.0 Troubleshooting Common Issues**

#### **6.1 Issue: Malformed JSON Request Body**

*   **Symptom:** The client reports successful API calls, but the backend application fails to process the request. Logs in Azure Monitor show a valid request at the Application Gateway, but application logs indicate a parsing error.
*   **Diagnosis:**
    1.  Use the Log Analytics workspace to query the logs from the API Management or Application Gateway.
    2.  Inspect the request headers and body for the failed transaction.
    3.  Confirm if the `Content-Type` header is `application/json` but the body contains unexpected encoding (e.g., it has been HTML encoded). This can be caused by an intermediary proxy on the client's side (e.g., Navy Federal Credit Union).
*   **Resolution:**
    1.  Modify the backend API code for the specific endpoint to be more resilient.
    2.  Allow the endpoint to accept a `Content-Type` of `text/plain`.
    3.  Implement logic within the application code to treat the incoming plain text payload as a JSON string and parse it accordingly. This ensures compatibility without requiring changes from the client.

### **7.0 Future Considerations**

*   As part of the continuous improvement process, periodically evaluate the architecture. There is a potential to simplify the configuration and reduce costs by replacing the API Management instance with a direct connection from the Application Gateway to the backend API server. This should be considered for future architectural reviews.

---
### **8.0 Revision History**

| **Version** | **Date** | **Author** | **Summary of Changes** |
| :--- | :--- | :--- | :--- |
| 1.0 | [Date] | SOP Expert | Initial document creation based on the meeting held on [Meeting Date]. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250205_120708-APIandDataFile-Recap.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure for setting up the local development environment.

***

### **Standard Operating Procedure: Local Development Environment Setup**

**SOP Number:** DEV-SOP-001
**Version:** 1.0
**Effective Date:** [Date]
**Prepared By:** SOP Expert
**Approved By:** [Approver Name, Title]

---

**1.0 Purpose**

The purpose of this Standard Operating Procedure (SOP) is to provide a clear, step-by-step guide for developers to set up a standardized local environment for the Sonar application and related services. Adherence to this procedure ensures consistency across the team, minimizes configuration-related errors, and facilitates a smooth onboarding and development workflow.

**2.0 Scope**

This SOP applies to all new and existing developers on the project team who require a local instance of the Sonar application for development, testing, or debugging purposes.

**3.0 Responsibilities**

*   **Developer:** Responsible for allocating time and diligently following this SOP to configure their local machine.
*   **Team Lead / Senior Developer:** Responsible for providing and maintaining the necessary resources (e.g., guideline documents, database files) and offering support.

**4.0 Prerequisites**

Before beginning this procedure, the developer must have:
*   A fully functional local development stack (e.g., LAMP, WAMP, Valet) including a web server, PHP, and a database server.
*   Access to the project's code repositories.
*   Received the necessary setup resources from the team lead, specifically:
    *   The environment setup guidelines document (originated by "Chip").
    *   The empty Sonar database file (provided by "Chandan").

**5.0 Procedure**

Follow these steps meticulously to ensure a correct and complete setup.

**Step 1: Allocate Dedicated Time**
*   **Action:** Block out a sufficient amount of time dedicated to this setup process.
*   **Details:** As per team communications, setting up the local environment is a high-priority task. It should be completed before proceeding with feature development or attending subsequent practical training sessions.

**Step 2: Review Official Setup Guidelines**
*   **Action:** Locate and thoroughly read the official setup guidelines document.
*   **Details:** This document contains the primary and most detailed instructions for configuring the application stack. Pay close attention to any specific version requirements or environment variable settings.

**Step 3: Set Up Sonar Application Codebase**
*   **Action:** Clone the Sonar application repository (a Laravel API) to your local development directory.
*   **Details:** Install all required dependencies using the appropriate package manager (e.g., `composer install`).

**Step 4: Configure the Local Database**
*   **Action:** Import the provided "empty Sonar database" file into your local database server.
*   **Details:** This step is critical for establishing a clean, consistent, and functional data structure for the application to interact with.

**Step 5: Configure Application Environment**
*   **Action:** Configure the application's environment file (typically `.env` in a Laravel project).
*   **Details:** Update the configuration to reflect your local setup. Key settings to verify include:
    *   **Database Connection:** Point the application to the local database created in Step 4.
    *   **Application URL:** Set the local URL for your project.
    *   **API Settings:** Review settings related to API authentication. While production uses IP whitelisting, understand the mechanism for local authentication.
    *   **Service Connections:** Ensure any connections to external services, such as the "Encryption as a Service," are correctly configured for a local/development mode (e.g., pointing to a mock service or a development instance if available).

**Step 6: Verify the Environment**
*   **Action:** Start your local web server and attempt to access the application.
*   **Details:** Perform a basic smoke test to confirm the setup was successful. Check for the following:
    *   The application loads without critical errors.
    *   The application successfully connects to the database.
    *   Review initial application logs to ensure there are no immediate, recurring configuration errors.

**Step 7: Seek Assistance if Needed**
*   **Action:** If you encounter issues, re-review the guidelines and your steps. If the problem persists, reach out to the team for support.
*   **Details:** Do not spend an excessive amount of time troubleshooting alone. The goal is to get the environment running efficiently.

**6.0 References**

*   Local Environment Setup Guidelines (as provided by Chip)
*   Empty Sonar Database File (as provided by Chandan)
*   Project Code Repository

---
**End of SOP**
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250205_120708-LocalSetup.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure for setting up a local development environment.

***

### **Standard Operating Procedure: Local Development Environment Setup**

**SOP ID:** DEV-API-001
**Version:** 1.0
**Effective Date:** October 26, 2023
**Approved By:** [Approver Name/Department]

---

**1.0 PURPOSE**

This Standard Operating Procedure (SOP) outlines the standardized process for setting up a local development environment for the Laravel API. The purpose is to ensure that all developers can consistently and efficiently run, test, and debug the API and its associated data processing commands on their local machines.

**2.0 SCOPE**

This SOP applies to all new and existing developers on the software engineering team who are required to work on the Laravel API codebase. This includes tasks related to API endpoint development, data file processing, and general maintenance.

**3.0 DEFINITIONS**

*   **API:** Application Programming Interface.
*   **PHP Artisan:** The command-line interface included with the Laravel framework.
*   **CQA Database:** The database used for the Central Quality Assurance environment.
*   **PII:** Personally Identifiable Information, such as Social Security numbers and dates of birth.
*   **Cron Job:** A time-based job scheduler in Unix-like computer operating systems.
*   **.env file:** A file used in Laravel to store environment-specific variables, such as database credentials and API keys.

**4.0 RESPONSIBILITIES**

*   **Developers** are responsible for following this procedure to set up and maintain their local development environment.
*   **The Lead Developer / DevOps Team** is responsible for maintaining the integrity of the CQA database and ensuring necessary access credentials are available.

**5.0 PROCEDURE**

This procedure is divided into two main sections: setting up the web-facing API and setting up the console-based data file processing.

**5.1 Part 1: Setting Up the Local API Server**

This part details the steps to get the API running locally for testing endpoints.

| Step | Action | Details |
| :--- | :--- | :--- |
| **5.1.1** | **Clone the Repository** | Clone the latest version of the Laravel API project from the designated Git repository to your local machine. |
| **5.1.2** | **Install Dependencies** | Navigate to the project's root directory in your terminal and run `composer install` to install all required PHP packages. |
| **5.1.3** | **Configure Environment** | 1. Copy the `.env.example` file to a new file named `.env`.<br>2. Open the `.env` file and update the `DB_` connection variables (`DB_HOST`, `DB_PORT`, `DB_DATABASE`, `DB_USERNAME`, `DB_PASSWORD`) to point to your local or a designated CQA database instance. |
| **5.1.4** | **Generate Application Key** | Run the command `php artisan key:generate` to set the `APP_KEY` in your `.env` file. |
| **5.1.5** | **Run Database Migrations** | Execute `php artisan migrate` to create the necessary database schema based on the project's migration files. If test data is required, run any applicable database seeders. |
| **5.1.6** | **Start the Local Server** | Run the command `php artisan serve --port=<port_number>` (e.g., `php artisan serve --port=8000`). This will start the local development server. The API will be accessible at `http://localhost:<port_number>`. |
| **5.1.7** | **Verify API Access** | To test authenticated endpoints, obtain a valid API token. Per the system design, tokens are generated in the admin interface. For local testing, use a pre-existing token from a seeded user or generate one via a custom artisan command if available. Access an endpoint using the token in the URL to confirm the setup is working. |

**5.2 Part 2: Setting Up Local Data File Processing**

This part details the steps to test console commands responsible for data file operations.

| Step | Action | Details |
| :--- | :--- | :--- |
| **5.2.1** | **Prepare Test Data** | Place any required test files (e.g., image files, data files) in the appropriate local directories that the console commands are configured to monitor. |
| **5.2.2** | **Run Commands Manually** | To test a specific data processing command, execute it directly from the terminal using `php artisan <command_name>`. For example: `php artisan images:move`. |
| **5.2.3** | **Simulate Scheduled Tasks** | To test the full schedule of cron jobs, you can either:<br>  a) Run `php artisan schedule:run` manually to trigger a single run of all due commands.<br>  b) Set up a local cron job on your machine (macOS/Linux) or a task in Task Scheduler (Windows) to execute `php artisan schedule:run` on a regular interval (e.g., every minute). |
| **5.2.4** | **Monitor for Errors** | Console command errors are logged to the Laravel log file located at `storage/logs/laravel.log`. If a command fails to execute as expected, review this log file for detailed error messages. Failed commands will be automatically retried on the next scheduled run. |

**6.0 REFERENCES**

*   Meeting Questionnaire & Detailed Answers (Source Document)
*   Laravel Framework Documentation

---
**End of SOP**
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250207_083042-Connectors (1).txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure for the E Oscar Connector.

---

### **Standard Operating Procedure**

**SOP Number:** EOC-001
**Version:** 1.0
**Title:** E Oscar Connector: Monitoring and Manual Recovery of Failed Dispute Jobs
**Effective Date:** [Date]
**Author/Owner:** Technical Operations / Engineering

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) defines the process for monitoring the E Oscar connector, identifying failed dispute processing jobs, and executing the manual recovery procedure. The objective is to ensure the timely and successful processing of all disputes by addressing failures caused by network issues, missing data, or other exceptions.

### **2.0 Scope**

This SOP applies to all Technical Operations personnel and engineers responsible for the maintenance, monitoring, and support of the E Oscar connector and its integration with the Sonnet system.

### **3.0 Definitions**

*   **E Oscar Connector:** The software service responsible for fetching dispute tasks from the database, processing their attachments, and submitting them to the Sonnet system.
*   **Dispute Job:** A single, trackable unit of work within the connector, representing the processing of one dispute from E Oscar.
*   **Sonnet:** The target internal system to which processed disputes are submitted.
*   **Job Starvation:** A condition where a job remains in the queue indefinitely and is never processed, often due to resource contention or misconfiguration.
*   **Manual Recovery Job:** A specific process initiated by an operator to re-attempt a failed Dispute Job.

### **4.0 Prerequisites**

*   Authorized access to the application server(s) hosting the E Oscar connector.
*   Access to the E Oscar connector's application and download logs. The log location is [Specify Log File Path or Log Management System, e.g., Splunk, ELK Stack].
*   Read/write access to the application database to query job statuses and trigger recovery tasks.
*   Valid API user credentials for the E Oscar interface must be configured and active.
*   Familiarity with company-specific configuration files or database tables that manage dynamic criteria for the connector.

### **5.0 Standard Operating Workflow (Overview)**

The E Oscar connector follows an automated workflow for processing standard dispute jobs. Understanding this "happy path" is critical for identifying deviations.

1.  **Task Creation:** Dispute tasks are created in the application database, either automatically by the system or manually by an operator.
2.  **Job Fetching:** The E Oscar connector periodically polls the database for new or pending tasks to process.
3.  **Data Processing:** For each fetched job, the connector:
    a. Downloads the dispute and any associated attachments from E Oscar.
    b. Converts attachments into the required format for the Sonnet system.
4.  **Submission:** The connector submits the processed dispute and converted attachments to Sonnet via API.
5.  **Status Updates:** The connector updates the job's status in the database throughout the process (e.g., `IN_PROGRESS`, `COMPLETED`, `FAILED`). It uses an event-driven system to communicate progress and completion status to other system components.

### **6.0 Procedure: Failure Detection and Manual Recovery**

This procedure outlines the manual steps required to detect and recover jobs that have failed during the standard workflow.

#### **6.1 Step 1: Detection of Failed Jobs**

Failed jobs must be identified through proactive monitoring of system logs.

1.  **Access Logs:** Navigate to the E Oscar connector's download logs located at [Log File Path/System].
2.  **Query for Keywords:** Perform a search for keywords indicative of a failure. Check logs for the last 24-hour period or since the last review. Keywords include, but are not limited to:
    *   `FAILED`
    *   `ERROR`
    *   `Duplicate Dispute`
    *   `Missing Attachment`
    *   `Network Issue`
    *   `Timeout`
3.  **Identify Job Details:** From the log entries, identify the unique `Dispute ID` or `Job ID` for each failed task.
4.  **Verify Status in Database:** For each identified ID, query the jobs table in the application database to confirm its status is marked as `FAILED` or is stuck in an `IN_PROGRESS` state for an unusually long time.
    ```sql
    -- Example Query
    SELECT jobId, status, createdAt, updatedAt 
    FROM dispute_jobs 
    WHERE jobId = '[Identified_Job_ID]';
    ```

#### **6.2 Step 2: Investigation and Root Cause Analysis**

Once a failed job is confirmed, investigate the root cause using the information from the logs.

1.  **Review Error Message:** Analyze the full log entry for the specific error message.
2.  **Categorize the Issue:** Determine the cause of failure based on the error. Common causes include:
    *   **Network Issues:** Connection timeouts or DNS failures when contacting the E Oscar API.
    *   **Data Issues:** The dispute in E Oscar is missing a required attachment, or a duplicate dispute was detected.
    *   **Configuration Issues:** Invalid API credentials or incorrect company-specific criteria.

#### **6.3 Step 3: Remediation and Manual Recovery**

Based on the root cause, perform the appropriate remediation steps before initiating recovery.

**A. For Network-Related Failures:**
1.  Verify network connectivity between the connector's host and the E Oscar endpoints.
2.  Once connectivity is restored, proceed to initiate the manual recovery job (Section 6.4).

**B. For Missing Attachment Failures:**
1.  Notify the responsible business unit that a dispute from E Oscar is missing a required attachment.
2.  The business unit must resolve the issue within the E Oscar platform.
3.  Once the attachment is confirmed to be present, proceed to initiate the manual recovery job (Section 6.4).

**C. For Duplicate Dispute Failures:**
1.  Investigate both the new and existing dispute records to determine validity.
2.  If the new dispute is erroneous, update its status in the database to `CANCELLED` with a note explaining why.
3.  If the new dispute is the correct one, investigate why the original was not processed or marked correctly. Escalate to the engineering team if necessary.

#### **6.4 Step 4: Initiating the Manual Recovery Job**

1.  **Trigger Recovery:** After remediation, initiate the manual recovery process. This is accomplished by executing a designated function, API endpoint, or database update to re-queue the job.
    *   **Action:** [Describe the specific action, e.g., "Update the job's status from 'FAILED' to 'PENDING' in the `dispute_jobs` table."]
    ```sql
    -- Example Update
    UPDATE dispute_jobs 
    SET status = 'PENDING', retryCount = retryCount + 1 
    WHERE jobId = '[Identified_Job_ID]';
    ```
2.  **Monitor the Recovered Job:** Actively monitor the logs and database for the re-queued job to ensure it runs through the standard workflow successfully and its final status is `COMPLETED`.
3.  **Document the Incident:** Log the incident in the team's ticketing or tracking system [e.g., Jira, ServiceNow]. Include the Job ID, the root cause of the failure, the steps taken to remediate, and confirmation of successful recovery.

### **7.0 References**

*   E Oscar Connector System Architecture Document
*   Company-Specific Configuration Guide
*   API Credentials Management Policy

### **8.0 Revision History**

| Version | Date       | Author(s)             | Summary of Changes     |
| :------ | :--------- | :-------------------- | :--------------------- |
| 1.0     | [Date]     | Technical Operations  | Initial document creation. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250207_083042-Connectors-L-200008-13Sep.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure for managing and recovering failed E Oscar connector jobs.

***

### **Standard Operating Procedure: E Oscar Connector - Manual Recovery of Failed Dispute Downloads**

**SOP ID:** EOC-OPS-001
**Version:** 1.0
**Effective Date:** October 26, 2023
**Author:** SOP Generation AI
**Approved By:** [Approver Name/Title]

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) defines the standard process for identifying, investigating, and manually recovering E Oscar disputes that have failed to download automatically via the E Oscar connector. The objective is to ensure timely and complete processing of all disputes, even in the event of system or network failures.

### **2.0 Scope**

This procedure applies to all Technical Operations personnel and Development Team members responsible for monitoring and maintaining the health and performance of the E Oscar connector and its integration with the Sonnet system.

### **3.0 Overview of Normal Operation**

The E Oscar connector is designed to automate the retrieval and processing of credit disputes. The standard workflow is as follows:

1.  **Task Creation:** A new task is created in the system, either automatically or manually.
2.  **Task Fetching:** The E Oscar connector periodically fetches pending tasks from the application database.
3.  **Dispute Download:** The connector interfaces with the E Oscar system via API (using designated user credentials) to download the dispute details and any associated attachments.
4.  **Processing & Submission:** The connector converts attachments to the required format and submits the complete dispute package to the Sonnet system.
5.  **Job Status Update:** The connector updates the job's status in the database throughout the process (e.g., 'In Progress', 'Complete', 'Failed') using system events to ensure visibility and prevent job starvation.

Failures can occur during the "Dispute Download" step due to network issues, duplicate entries, missing attachments, or other errors. This SOP addresses the remediation of such failures.

### **4.0 Prerequisites**

Before executing this procedure, the user must have:
*   Appropriate permissions to access the server(s) where the E Oscar connector runs.
*   Read access to the E Oscar connector's application and download logs.
*   Database client and credentials with permissions to query the job management tables.
*   Authorization and knowledge of the procedure to initiate a manual recovery job.

### **5.0 Procedure: Identification and Recovery**

This procedure is divided into two phases: **Detection** of the failed job and **Manual Recovery**.

#### **Phase 1: Detection of Failed Downloads**

1.  **Monitor Logs:** On a regular basis, or in response to a system alert, access the E Oscar connector's download logs.
2.  **Search for Failure Keywords:** Perform a search within the log files for keywords that indicate a download failure. These keywords may include, but are not limited to:
    *   `ERROR`
    *   `FAILED_DOWNLOAD`
    *   `DUPLICATE_DISPUTE`
    *   `MISSING_ATTACHMENT`
    *   `TIMEOUT`
    *   `NETWORK_ISSUE`
3.  **Identify Specific Failed Job:** From the log entry, identify the unique job ID, dispute ID, or other primary identifiers associated with the failed transaction.
4.  **Verify Status in Database:**
    *   Connect to the application database.
    *   Query the job status table using the identified job ID.
    *   Confirm that the job is in a non-completed state (e.g., 'Failed', 'Stalled', 'Error'). This step validates that the system has not already recovered automatically.

#### **Phase 2: Manual Recovery**

1.  **Investigate Root Cause:** Based on the log message from Step 5.1.2, perform a brief investigation to understand the cause of failure. Note whether the issue was transient (e.g., temporary network outage) or persistent (e.g., a consistently missing attachment on the source system).
2.  **Initiate Manual Recovery Job:**
    *   Once the root cause is understood, trigger the manual recovery job for the specific dispute(s) identified.
    *   **Note:** The exact command or interface for this action is documented separately. Follow the established protocol for initiating a manual run.
3.  **Monitor the Recovery Job:** Actively monitor the logs and database for the progress of the newly initiated manual job.
4.  **Confirm Successful Completion:** Verify that the recovery job completes successfully. Confirmation includes:
    *   The job status is updated to **'Complete'** in the database.
    *   The dispute data and its corresponding attachments are confirmed to exist in the Sonnet system.
5.  **Document Incident:** Create or update an entry in the incident log or ticketing system. The entry should include:
    *   The Job/Dispute ID.
    *   The date and time of the failure.
    *   The root cause identified.
    *   Confirmation that the manual recovery was successfully completed.

### **6.0 Troubleshooting**

*   **Credential Failures:** If logs indicate an authentication or authorization error, verify that the API user credentials for the E Oscar connector are correct and active.
*   **Persistent Failures:** If a manual recovery job fails with the same error, escalate the issue to the Development Team. The problem may be related to company-specific configurations or require a code-level change.
*   **Duplicate Disputes:** If a dispute is consistently flagged as a duplicate, investigate the source data in E Oscar and the existing data in Sonnet to confirm. Do not force reprocessing without confirming the dispute is not, in fact, a duplicate.

### **7.0 Revision History**

| Version | Date | Author | Change Description |
| :--- | :--- | :--- | :--- |
| 1.0 | 10/26/2023 | SOP Gen. AI | Initial document creation based on technical discussion. |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250207_083042-Connectors.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure for the E Oscar Connector.

---

### **Standard Operating Procedure: E Oscar Connector - Operations and Management**

**SOP Number:** TEC-SOP-081A
**Version:** 1.0
**Effective Date:** [Date]
**Author:** [Your Name/Department]
**Approved By:** [Approver's Name]

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) outlines the standardized process for operating, monitoring, troubleshooting, and managing the E Oscar Connector. The purpose is to ensure consistent and reliable integration between the Sonnet system and the external E Oscar platform for handling credit disputes.

### **2.0 Scope**

This SOP applies to all technical staff, including developers, system administrators, and IT operations personnel responsible for the maintenance and oversight of the Sonnet system and its associated connectors. This document covers the primary functions, error handling protocols, and configuration management of the E Oscar Connector.

### **3.0 Definitions**

*   **E Oscar Connector:** The middleware application responsible for interfacing between Sonnet and E Oscar. It manages the download and submission of dispute data.
*   **Sonnet:** The primary internal system that initiates and receives data from the E Oscar Connector.
*   **E Oscar:** The external, third-party platform for managing credit disputes.
*   **Job:** A specific task executed by the connector, such as "Download Disputes" or "Submit Disputes."
*   **CLI (Command-Line Interface):** A text-based interface used for manually executing commands to operate or troubleshoot the connector.
*   **Company ID:** A unique identifier for a company within the system, used for configuration and data management.

### **4.0 Responsibilities**

*   **IT Operations/System Administrators:** Responsible for monitoring job execution, performing initial troubleshooting, executing recovery procedures, and managing system resources.
*   **Development Team:** Responsible for advanced troubleshooting, resolving code-level errors, and managing company-specific configurations and connector enhancements.

### **5.0 Procedure**

#### **5.1 Core Job Execution (Automated)**

The E Oscar Connector automates the transfer of data between Sonnet and E Oscar. The primary jobs are downloading new disputes and submitting responses.

1.  **Job Initiation:** Jobs are initiated within Sonnet (e.g., a scheduled "Download Disputes" task).
2.  **Connector Action:** The E Oscar Connector receives the command and interacts directly with E Oscar's API endpoints to perform the requested action.
3.  **Data Processing:**
    *   **Downloads:** The connector retrieves dispute data from E Oscar.
    *   **Submissions:** The connector sends dispute responses from Sonnet to E Oscar.
    *   **Attachments:** During processing, any associated attachments are converted to TIFF format and extracted as JPEGs for use in the Sonnet UI. These files are moved to designated storage locations.
4.  **Status Communication:** The connector provides continuous feedback to Sonnet, updating the job's status (e.g., Started, Completed, Failed) and relevant metrics (e.g., number of disputes found/processed).

#### **5.2 Monitoring Job Status**

Proactive monitoring is critical to ensure the health and efficiency of the dispute processing workflow.

1.  **Primary Monitoring:** Check the job status dashboards within the Sonnet system. Look for jobs with a "Failed" or "In Progress" status that has been running for an unusually long time.
2.  **Log Review:** Access the connector's logs for detailed information. The logger utilizes dynamic file paths, so ensure you are referencing the correct log file for the job in question. Logs provide specific error messages and processing details.
3.  **Key Metrics to Monitor:**
    *   Job status (Started, Completed, Failed).
    *   Number of disputes found.
    *   Number of disputes successfully processed.
    *   Error messages or exceptions.

#### **5.3 Error Handling and Recovery Procedure**

The connector is designed to be resilient, but manual intervention may be required for certain failures.

1.  **Automatic Retry:** The connector has a built-in retry mechanism for transient errors. A job will be automatically retried a set number of times. If it consistently fails, it will be marked as "Failed" to prevent job execution starvation and allow other jobs to proceed.
2.  **Failure Detection:** Identify failed jobs through the monitoring steps outlined in section 5.2.
3.  **Initial Analysis:** Review the job's logs in Sonnet and the connector's log files to diagnose the root cause. Common issues include:
    *   Failed downloads for specific disputes.
    *   Data duplication errors.
    *   Connectivity issues with E Oscar.
4.  **Manual Recovery Initiation:**
    *   For issues like failed downloads, a manual recovery job must be set up.
    *   Use the appropriate system tools or commands to initiate a "recovery job" targeting the specific disputes or time frame that failed.
5.  **Recovery Verification:** Monitor the recovery job closely. If the recovery job also fails, it requires escalation to the Development Team for in-depth analysis and manual intervention.

#### **5.4 Managing Company-Specific Configurations**

The connector supports unique configurations for different companies to handle special cases or dynamic criteria.

1.  **Identify Requirement:** Determine if a company requires special handling (e.g., excluding certain dispute types, unique data mapping).
2.  **Locate Company ID:** The `Company ID` is the primary key for all configurations. Ensure you have the correct `Company ID` for the client.
3.  **Modify Configuration:**
    *   Update the relevant job description to include the special criteria.
    *   For more complex logic, create or modify the "extra configuration files" associated with that `Company ID`.
4.  **Deploy and Test:** Deploy the configuration changes and run a test job for that company to verify that the new logic is being applied correctly.

#### **5.5 Manual Operations via Command-Line Interface (CLI)**

The CLI is used for executing specific commands manually for troubleshooting, testing, or handling edge cases not covered by automated jobs.

1.  **Access CLI:** Open a terminal or console with access to the connector's execution environment.
2.  **Identify Command:** Refer to the connector's documentation to determine the correct command and required parameters for the task (e.g., forcing a download for a specific company, reprocessing a single dispute).
3.  **Execute Command:** Enter the command with all necessary arguments (e.g., `Company ID`, `JobID`).
4.  **Monitor Output:** Observe the CLI output for real-time progress and confirmation of success or failure. Use this output for immediate troubleshooting if the command does not complete as expected.

---

### **6.0 Revision History**

| Version | Date       | Author               | Summary of Changes |
| :------ | :--------- | :------------------- | :----------------- |
| 1.0     | [Date]     | [Your Name/Department] | Initial release.   |
--------------------------------------------------------------------------------
Title: SOP_Sonnet KT-20250207_103608-Interfaces.txt
Of course. Based on the provided document, here is a professional Standard Operating Procedure for managing the customer data interfaces.

***

### **Standard Operating Procedure: Management of Customer Data Interfaces**

| **SOP Number:** | TEC-INT-001 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Department:** | Engineering / Technical Operations | **Effective Date:** | October 26, 2023 |
| **Approved By:** | [Approval Authority Name] | **Title:** | [Approval Authority Title] |

---

### **1.0 Purpose**

This Standard Operating Procedure (SOP) provides a standardized framework for understanding, managing, and interacting with the various customer data interfaces. The objective is to ensure operational consistency, maintain data integrity, and provide clear guidelines for implementation, customization, and troubleshooting.

### **2.0 Scope**

This SOP applies to all technical personnel, including developers, integration specialists, and operations staff, who are involved in the design, development, support, and maintenance of the company's data interfaces. This includes, but is not limited to, batch interfaces, API-integrated interfaces, and internal interfaces such as the XP-2, J Exchange, SIM Exchange, and Correlation connectors.

### **3.0 Definitions**

*   **System of Record (SoR):** The authoritative data source for a given data element; typically the customer's primary system.
*   **Internal Interface:** An interface responsible for accessing a customer's SoR to insert, update, or retrieve consumer, account, or other supporting data. Utilizes technologies such as Node.js, Express, and Nest.js.
*   **Batch Interface:** An interface designed to handle the transfer of large volumes of data in scheduled batches.
*   **API-Integrated Interface:** An interface that facilitates real-time data exchange between systems via Application Programming Interfaces (APIs).

### **4.0 Responsibilities**

*   **Development Team:** Responsible for implementing new interfaces, handling customer-specific customization requests, and resolving code-level bugs.
*   **Operations Team:** Responsible for monitoring the daily data refresh process, managing interface configurations, and performing initial troubleshooting of connectivity or data flow issues.
*   **All Technical Personnel:** Responsible for adhering to the procedures outlined in this document to ensure secure and reliable interface operation.

### **5.0 Procedure**

This procedure outlines the standard operational principles and specific guidelines for the different types of data interfaces.

#### **5.1 General Operating Principles**

All interfaces must adhere to the following core principles to ensure data accuracy and security.

**5.1.1 Data Refresh Process**
1.  **Purpose:** To ensure that the data within our system accurately reflects the most recent information from the customer's SoR.
2.  **Frequency:** The refresh process shall run daily at a customer-specified time.
3.  **Action:** The process connects to the customer's SoR and updates all relevant data fields.
4.  **Monitoring:** The Operations Team is responsible for monitoring the success of the daily refresh and escalating any failures for investigation.

**5.1.2 Session Management and Authentication**
1.  **Requirement:** All interfaces connecting to customer systems must use secure authentication methods.
2.  **Implementation:** Interfaces, such as the Correlation interface, shall use session IDs to manage authentication.
3.  **Security:** Session IDs must be refreshed at a regular frequency to prevent expiration and maintain a secure connection, ensuring authorized data access only.

**5.1.3 Logging and Debugging**
1.  **Standard:** All interfaces must implement extensive logging to capture requests, responses, and errors.
2.  **Requirement:** For certified interfaces like J Exchange, this logging is mandatory for compliance and traceability.
3.  **Purpose:** Logs are the primary tool for debugging interface issues and must be detailed enough to reconstruct interactions with the customer's system.

#### **5.2 Specific Interface Guidelines**

The following sections detail the unique characteristics and operational procedures for specific interfaces.

**5.2.1 XP-2 Connector**
*   **Function:** Primarily used for *fetching* account information from the customer SoR. It is not designed for submitting data.
*   **Structure:** A simple, straightforward connector with a minimal feature set.
*   **Limitations:** Lacks built-in scripts and tooling for advanced functionalities. Relies on a command-line interface (CLI) utility for parameter translation.

**5.2.2 J Exchange Interface**
*   **Function:** Designed for data exchange, but with known limitations.
*   **Challenge:** Has difficulty retrieving specific critical fields, such as payment history profiles.
*   **Usage:** Due to its limitations, this interface is not widely implemented. Customers should be encouraged to integrate via a direct API connection instead.
*   **Logging:** Requires comprehensive logging for certification and debugging purposes.

**5.2.3 SIM Exchange Interface**
*   **Structure:** A complex connector with multiple endpoints for different data types.
*   **Initialization:** Upon startup, the interface loads *all* company properties from the database.
*   **Dependency:** A correct and complete database configuration is critical. The interface will fail to initialize if the setup is incorrect.

**5.2.4 Correlation Interface**
*   **Structure:** A flexible and lightweight connector.
*   **Initialization:** Fetches configuration data dynamically from the system during runtime, rather than loading everything at startup. This makes it more resilient to configuration changes.
*   **Authentication:** Manages secure access using session IDs, as described in section 5.1.2.

#### **5.3 Handling Customer Customization Requests**

Follow this procedure to manage requests for interface customizations.

1.  **Identify Request:** Work with the customer to clearly define the customization requirements. Common requests include:
    *   Specific data transformations.
    *   Custom account status rules.
    *   Unique payment history formatting.
2.  **Implementation:** The Development Team will implement the required custom logic within the service methods specific to that customer's interface instance.
3.  **Testing:** Thoroughly test the customization to ensure it meets the customer's requirements without causing regressions.
4.  **Deployment & Documentation:** Deploy the changes and document the custom logic and its function for future reference and support.

### **6.0 References**

*   Meeting Debrief: "Questionnaire on the Topics Covered in the Meeting"

### **7.0 Approval**

| **Name** | **Signature** | **Date** |
| :--- | :--- | :--- |
| [Approval Authority Name] | | |
--------------------------------------------------------------------------------
Title: SOP_SSO and GPG.txt
Of course. Here is a professional Standard Operating Procedure (SOP) based on the provided document.

---

### **Standard Operating Procedure: Client Security Configuration**

**SOP ID:** TEC-SOP-007
**Effective Date:** June 10, 2025
**Version:** 1.0
**Owner:** Technical Operations Department
**Author:** James Maki

---

### **1.0 Purpose**

This document outlines the standard procedures for configuring and managing client-specific security features, including Single Sign-On (SSO) and GPG file encryption.

### **2.0 Scope**

This SOP applies to all Technical Support, Implementation, and Operations personnel responsible for setting up, managing, or troubleshooting client accounts within the Sonnet platform.

### **3.0 General Policy: Development Team Engagement**

For complex security configurations, troubleshooting, or any step not explicitly detailed in this SOP, personnel are required to engage the Development Team. This ensures that security protocols are implemented correctly and consistently. Do not proceed with an unfamiliar or failing process without escalating for assistance.

### **4.0 Procedure: Single Sign-On (SSO) Setup**

SSO allows users from a client organization to log into the Sonnet platform using their existing corporate credentials.

**4.1 Initial Client Request and Communication**

1.  When a client requests to enable SSO, locate the standardized setup document:
    *   **Document Name:** `SSO Setup Instructions`
    *   **Location:** Shared Documents > New Client Setup Information
2.  Send this document to the client's technical contact.
    *   **Note:** The provided documentation is designed specifically for Microsoft Azure, which is our internal standard. If a client uses a different Identity Provider (e.g., Okta, Ping), inform them that the principles are the same, but they will need to adapt the steps for their software.

**4.2 Configuration**

1.  The client will provide the necessary configuration details, typically including:
    *   Login URL
    *   Logout URL
    *   Identity Provider (IdP) Issuer URL
    *   X.509 Certificate (as a text block)
2.  Navigate to the client’s `Company` screen in the Sonnet administrative interface.
3.  Locate the **Single Sign-On** section.
4.  Carefully copy and paste each URL provided by the client into the corresponding field.
5.  Open the certificate file provided by the client using a plain text editor (e.g., Notepad, Notepad++).
6.  Copy the entire text block of the certificate, including the `-----BEGIN CERTIFICATE-----` and `-----END CERTIFICATE-----` lines, and paste it into the **Certificate** field.

**4.3 Activation and Deactivation**

1.  SSO functionality is controlled by the **SSO ID** field.
2.  To activate SSO, enter the client’s company abbreviation (alias) into the **SSO ID** field. Once this ID is saved, SSO is active for that client.
3.  To deactivate SSO (e.g., for troubleshooting or at the client's request), simply clear the **SSO ID** field and save the changes.

**4.4 Troubleshooting**

1.  If a client reports that SSO is not working after the configuration has been entered and activated, do not attempt to resolve the issue independently.
2.  Escalate the issue immediately to the Development Team by creating a dev task with all relevant details, including client communications and the information they provided.

---

### **5.0 Procedure: GPG Encryption Management**

GPG provides an extra layer of security by encrypting files, primarily STEP files, transferred between the client and Sonnet.

**5.1 New Client GPG Setup**

The initial setup of GPG encryption for a new client is a sensitive process that **must** be handled in collaboration with the Development Team.

1.  Upon receiving a request from a client to use GPG encryption for file transfers (e.g., STEP files, images), create a dev task.
2.  Assign the task to the appropriate developer (e.g., Natish, Vinay) for handling key generation and exchange.
3.  Act as the liaison between the client and the Development Team to ensure all necessary keys are exchanged and configured correctly in the backend systems.
    *   **Note:** Requests to encrypt non-standard files, such as images, are considered custom work and require explicit dev team involvement.

**5.2 Decrypting a GPG-Encrypted File for Validation**

This procedure is used for internal data validation and troubleshooting, allowing you to view the contents of an encrypted file received from a client.

1.  **Prerequisites:** Access to the application server command line is required.
2.  **Log in as Service User:** Open a terminal session to the server and elevate your privileges to the `sonnet` user by running the following command:
    ```bash
    sudo su sonnet
    ```
3.  **Navigate to File Directory:** Change to the directory containing the encrypted file you need to inspect (e.g., `ftpdir/[client_name]/processed/`).
    ```bash
    cd /ftpdir/snap_on_credit/processed/
    ```
4.  **Execute Decryption Command:** Use the following command template to decrypt the file.

    **Command Template:**
    ```bash
    gpg --batch --yes -o [output_file_name].csv --passphrase-file /home/sonnet/.private/pass1.key --decrypt [original_encrypted_file_name].gpg
    ```
    *   `[output_file_name].csv`: Replace with the desired name for the decrypted CSV file. It is best practice to use the original filename without the `.gpg` extension.
    *   `[original_encrypted_file_name].gpg`: Replace with the exact name of the file you are decrypting.

    **Example:**
    ```bash
    gpg --batch --yes -o FCHRWELL_20240409.csv --passphrase-file /home/sonnet/.private/pass1.key --decrypt FCHRWELL_20240409.gpg
    ```
5.  **Verify Decryption:** After the command executes successfully, a new, decrypted `.csv` file will appear in the directory. You can now open this file to view its contents for validation or troubleshooting.

**5.3 Providing Sonnet's Encryption Key to a Client**

If a client needs Sonnet's key to encrypt files they send to us, follow this process.

1.  **Important:** Consult with the Development Team before sending any key files to a client to ensure the correct key (typically a **public key**, not a private/secret key) is shared.
2.  The key referenced for internal decryption processes is located at:
    *   **File Path:** `/home/sonnet/.private/pass1.key`
3.  Work with the Development Team to obtain the correct public key file required by the client for them to add to their keyring.

### **6.0 References**

*   **SSO Setup Instructions:** `[Shared Documents]/New Client Setup Information/`
*   **GPG Decryption Command Reference:** `[Shared Documents]/` (A copy of the command has been saved for easy access).
--------------------------------------------------------------------------------
Title: SOP_Stuck_Challenging Tickets Discussion & Knowledge Sharing with Amanda (Mon_Wed_Fri) 16th July.txt
Of course. Here is a professional Standard Operating Procedure (SOP) based on the process detailed in the provided document.

---

### **Standard Operating Procedure: Creating a DevOps User Story from Client Feedback**

**SOP Number:** SUP-014
**Version:** 1.0
**Effective Date:** 07/16/2025
**Author:** Process Excellence Team
**Approved By:** Amanda Gilbert, Support Manager

---

### 1.0 Purpose

To provide a standardized procedure for support team members to convert actionable client feedback, specifically regarding feature improvements or performance issues (e.g., OCR results), into a formal User Story within the DevOps system. This ensures that client feedback is properly tracked, assigned to the development team, and communicated back to the client.

### 2.0 Scope

This SOP applies to all Support Team members responsible for triaging client tickets and liaising with the Development Team. The procedure begins when a client provides feedback that requires development work and concludes when the client is updated with the new DevOps work item.

### 3.0 Definitions

*   **DevOps:** The platform used for tracking development work, including bugs, tasks, and user stories.
*   **User Story:** A formal work item that describes a software feature from an end-user's perspective. It represents a request for a new feature or an improvement to an existing one.
*   **Sprint:** A set, time-boxed period during which specific work has to be completed and made ready for review.
*   **ZDT:** Zendesk Ticket (assumed from context `zdt` prefix).

### 4.0 Procedure

#### **4.1 Identifying the Need for a User Story**

When client feedback is received that cannot be resolved through existing configuration or troubleshooting and represents a request for product improvement (e.g., "OCR is working less than 50%"), a User Story must be created to log this for the Development Team.

#### **4.2 Creating the User Story in DevOps**

1.  Navigate to the DevOps portal.
2.  Click the **+ (plus) icon** in the top navigation bar to create a new work item.
3.  From the dropdown menu, select **User Story**.
4.  **Populate the Title Field:**
    *   Use a clear, descriptive title that summarizes the request.
    *   Include a reference to the source support ticket.
    *   **Format:** `[Feature Area] Improvement Needed - ZDT-[Ticket Number]`
    *   **Example:** `OCR Improvement Needed based on user feedback - ZDT-23192`
5.  **Populate the Description Field:**
    *   Navigate to the client support ticket.
    *   Copy the exact text of the client's feedback or a concise summary of the issue.
    *   Paste this information directly into the **Description** field of the User Story.
6.  **Assign to the Correct Sprint:**
    *   Locate the **Iteration** field.
    *   Assign the User Story to the appropriate upcoming Sprint as directed by team leadership (e.g., Sprint 101).
7.  Click **Save** to create the User Story.

#### **4.3 Linking the User Story to the Support Ticket**

1.  After saving, locate the newly created User Story in DevOps (e.g., via the Sprint backlog or by searching).
2.  Click the **... (ellipses) menu** in the top right corner of the User Story view.
3.  Select **Copy link**.
4.  Navigate back to the original support ticket.
5.  Paste the DevOps link into an internal note or a designated field for tracking purposes. This ensures the development work is tied directly to the client request.

#### **4.4 Updating the Client**

1.  Compose a public reply to the client within the support ticket.
2.  Use the following template to ensure consistent communication:
    > "Hi [Client Name],
    >
    > Thank you for your feedback. We have created a work item for our development team to review and work on improving the OCR results. This has been scheduled for resolution in an upcoming development cycle, with an estimated completion around [Provide Timeline, e.g., mid-August].
    >
    > We will update you once the improvements have been deployed. Please let us know if you have any other questions."
3.  Submit the response to the client. The ticket can then be set to a "Pending" or "On-hold" status until the development work is complete.

### 5.0 Associated Documents

*   Client Support Ticket (Zendesk)
*   DevOps User Story Work Item

---
**End of SOP**
--------------------------------------------------------------------------------
Title: SOP_Ticket backlog 20250619.txt
Of course. Based on the document provided, here is a Standard Operating Procedure for investigating user claims of unsaved changes.

---

### **Standard Operating Procedure: Investigating "Changes Not Saved" Claims**

| **SOP ID:** | SUP-TS-011 | **Version:** | 1.0 |
| :--- | :--- | :--- | :--- |
| **Process Owner:** | Support Lead | **Effective Date:** | June 20, 2025 |
| **Applies To:** | Support Analysts | **Last Reviewed:** | June 20, 2025 |

---

#### **1.0 Purpose**

To provide a standardized procedure for investigating, verifying, and responding to client reports where a system user's changes to a dispute are allegedly not being saved. This SOP ensures a consistent and efficient diagnostic approach.

#### **2.0 Scope**

This procedure applies to all Support Analysts responsible for troubleshooting user-reported issues within the production or QA environments of the dispute management platform.

#### **3.0 Prerequisites**

*   Analyst must have access to the support ticketing system.
*   Analyst must have access to the relevant client environment (e.g., QA) on the platform.
*   Analyst must have a working knowledge of navigating disputes, including the "Account" and "History" tabs.

#### **4.0 Procedure**

When a ticket is received reporting that changes made by a user are not being saved, follow these steps to diagnose the issue.

**4.1 Initial Ticket Analysis**
1.  Review the ticket to identify the user who is experiencing the issue (e.g., user "Anna") and the specific environment (e.g., QA).
2.  Check if the client has provided a specific Dispute ID for an example of the failure. If no ID is provided, proceed with the steps below to find a relevant example.

**4.2 Locate and Open a Sample Dispute**
1.  Navigate to the client's dispute queue in the specified environment (e.g., QA queue).
2.  Identify and open a recent dispute that was last modified by the user in question. If this is not immediately clear, select the first dispute in the queue for a preliminary investigation.

**4.3 Review the Dispute History for Changes**
1.  Within the selected dispute, navigate to the **History** tab.
2.  Carefully review the audit log to find the entries corresponding to the user's modifications.
3.  For each relevant entry, document the following:
    *   The field that was changed (e.g., `Actual Payment Amount`).
    *   The value it was changed *from* (e.g., `74`).
    *   The value it was changed *to* (e.g., `0`).

**4.4 Validate Changes on the Account Tab**
1.  Navigate to the **Account** tab of the same dispute.
2.  Locate each field that was identified as changed in the History tab (Step 4.3).
3.  Verify if the current value displayed for each field matches the new value recorded in the history log.
4.  Confirm that all changes noted in the history are correctly reflected on the account details.

**4.5 Communicate Findings and Update Ticket**
1.  **If all changes were successfully saved:**
    1.  Copy the full **Sonnet ID / Dispute ID** from the URL of the dispute you reviewed.
    2.  Draft a public reply on the support ticket.
    3.  In the reply, state that you have reviewed the specified dispute (include the ID) and have verified that the user's changes are still saved on the dispute.
    4.  Politely ask the client to provide a specific Dispute ID where the changes are *not* saved, so you can investigate an active example of the issue.
2.  **If changes were NOT successfully saved:**
    1.  Document the specific fields that failed to save.
    2.  Gather screenshots of the History tab and the Account tab showing the discrepancy.
    3.  Escalate the ticket to the development team by creating a bug/dev task with all documented findings.
3.  Update the ticket status to **Pending** to await a response or to **On Hold** if a dev task was created.
4.  **Crucially:** Before moving to the next task, ensure you have properly exited the dispute by clicking **Return to Queue**. This action unlocks the dispute, making it available for other users.
--------------------------------------------------------------------------------
Title: SOP_Ticket backlog 20250620.txt
Of course. Here is a professional Standard Operating Procedure based on the document provided.

---

### **SOP: Investigating Reports of Missing Dispute Files (Receipts & Images)**

**SOP ID:** SV-OPS-043
**Version:** 1.0
**Effective Date:** 2025-06-21
**Author:** SOP Bot
**Approver:** James Maki, Lead Analyst

---

### 1.0 Purpose

This Standard Operating Procedure (SOP) provides a standardized methodology for investigating and responding to client reports of missing dispute-related files, specifically receipts and attached images. The procedure ensures consistent and accurate verification of whether files are truly missing or were processed and filed under a different date due to system delays.

### 2.0 Scope

This SOP applies to all Technical Support and Operations Analysts responsible for troubleshooting file delivery and processing issues within the Sonnet application and its associated file servers.

### 3.0 Definitions

*   **Sonnet:** The primary application for managing and processing disputes.
*   **Control Number:** A unique identifier assigned to each dispute record.
*   **Receipt File:** A document generated upon the completion of a dispute, serving as a record of the action taken. Its filename contains the date of generation.
*   **Image File:** Supporting documentation (e.g., from a credit bureau) attached to a dispute, typically in .tiff format.
*   **Completed Date:** The date a dispute's workflow was finished in Sonnet.
*   **Received Date:** The date a dispute was initially received and ingested into Sonnet.

### 4.0 Procedure

This procedure is divided into three parts based on the type of missing file reported.

#### **Part A: Investigating Missing Image Files**

Use this procedure when a client reports that image files for a specific credit bureau and date are missing.

1.  **Log in to Sonnet.**
2.  **Initiate a Dispute Search:**
    *   Navigate to the dispute search screen.
    *   Set the **Received Date** field to the specific date the images were reported missing.
    *   Select the checkbox for **"With Images"**.
    *   Select the relevant **Credit Bureau** (e.g., TransUnion, Experian) from the dropdown menu.
    *   Execute the search.
3.  **Analyze Search Results:**
    *   **If no results are found:** This indicates that no disputes with images were received from that credit bureau on the specified date. No files are missing. Proceed to Section 5.0 Communication.
    *   **If results are found:** This indicates that images were received. The files may have been saved to the server on a subsequent day due to processing delays. Proceed to the next step to locate the file.
4.  **Locate the File on the Server:**
    *   From the search results, open any dispute record.
    *   Copy the **Control Number**.
    *   Establish a connection to the production server via a terminal or SSH client.
    *   Navigate to the directory corresponding to the correct credit bureau (e.g., `.../Experian/`, `.../TransUnion/`).
    *   Execute a `find` command to search for the file using the copied control number. The control number is typically at the end of the filename.
        *   **Command:** `find . -name "*[Control_Number].tiff"`
        *   *Example:* `find . -name "*2464246016.tiff"`
5.  **Verify the File's Actual Date:**
    *   Once the file is located, run the `ls -ltr` command in the directory to list all files in chronological order of their modification time.
    *   Scan the output to find the file and note its timestamp. This confirms the actual date the file was written to the server. This date is what the client should look for.
    *   Proceed to Section 5.0 Communication.

#### **Part B: Investigating Missing Receipt Files**

Use this procedure when a client reports that receipt files for a specific date range are missing.

1.  **Log in to Sonnet.**
2.  **Initiate a Dispute Search:**
    *   Navigate to the dispute search screen.
    *   Set the **Completed Date** field to the date range for which receipts are reported missing (e.g., 13th to 15th).
    *   Execute the search.
3.  **Investigate the Receipt Generation Date:**
    *   From the search results, open any dispute record.
    *   Navigate to the **Account History** tab.
    *   Review the history log and locate the entry titled **"Receipt Generated"**.
    *   Note the date and time of this entry. This is the date that will appear in the receipt's filename and determines its location on the server, not the `Completed Date`.
4.  **Formulate Conclusion:** Conclude that the receipts were generated on a later date due to a processing delay. Proceed to Section 5.0 Communication.

#### **Part C: Verifying No Disputes Received**

Use this procedure when a client reports receiving no disputes at all over a period.

1.  **Log in to Sonnet.**
2.  **Navigate to the Correct Company Profile.** Be diligent to select the exact company reported in the ticket.
3.  **Access Download History:**
    *   Within the company's profile, go to the **Admin** section.
    *   Click on the **View Downloads** tab.
4.  **Review Download Logs:**
    *   This screen displays the company's recent download history, including dates and the total number of disputes downloaded.
    *   Use this log to confirm whether any disputes were received and processed for the client on the dates in question.
    *   Proceed to Section 5.0 Communication.

### 5.0 Communication and Resolution

1.  **Draft a Response:** Based on the findings from Section 4.0, compose a clear and precise response to the client.
    *   **For Delayed Files (Images or Receipts):** Inform the client that the files are not missing. Explain that due to a processing delay, the files were generated on a later date. State the exact date the files were generated (e.g., "The receipts for disputes completed from the 13th-15th were generated on the 16th and will be filed under that date.").
    *   **For No Files Found:** Inform the client that after a thorough review, the system confirms that no files of the specified type (e.g., "TransUnion images") were received on the date in question.
2.  **Update the Ticket:**
    *   Post the response to the ticket.
    *   Set the ticket status to **Pending** to await confirmation from the client that they have located the files or understand the findings.
--------------------------------------------------------------------------------
Title: SOP_Ticket backlog 20250623.txt
Here is the Standard Operating Procedure (SOP) based on the document provided.

***

## Standard Operating Procedure: New Client Setup in Development Environment

**SOP ID:** SNET-DEV-001
**Version:** 1.0
**Effective Date:** June 24, 2025
**Owner:** Technical Support Team
**Approval:** James Maki

---

### 1.0 Purpose

This document outlines the standard procedure for setting up a new client company in the Sonnet development (dev) environment. This process includes creating the company profile, configuring the necessary server-side scripts and directories, generating initial test data (disputes), and creating user accounts.

### 2.0 Scope

This SOP applies to all Technical Support Team members responsible for configuring the development environment for new or existing clients for API testing and integration purposes.

### 3.0 Prerequisites

Before beginning this procedure, ensure you have the following:

*   Access to the Sonnet development environment URL.
*   A valid ticket with the client's company name, user details, and IP addresses for whitelisting.
*   The `EC2-access.pem` key file saved to a local directory (e.g., `C:\Users\[your_name]\Downloads\dev`). **Note:** Avoid using a OneDrive-synced directory as it may cause path-related connection issues.
*   Git Bash software installed on your local machine.
*   Access to the dev server via SSH.
*   An RFC must be created and completed for whitelisting the client's IP addresses in AWS.

---

### 4.0 Procedure

#### 4.1 Phase 1: Create the Company in the Sonnet Dev UI

1.  Navigate to the Sonnet dev environment URL.
2.  Go to the **Admin** section.
3.  In the left-hand menu, click on **Organizations**.
4.  In the top-right corner, click the **Add New Customer** button.
5.  Complete the company information form:
    *   **Organization:** Enter the company name (e.g., Finvy Velocity).
    *   **Email Domain:** Enter the client's email domain without the "@" symbol (e.g., `finv.com`).
    *   **Location:** Enter a placeholder location (e.g., New York, NY).
    *   **Collection System:** Select **API**.
6.  Click **Create**.
7.  The system will create the company and assign a new Company ID. Take note of this ID (e.g., `24600`) as it is required for subsequent steps.

#### 4.2 Phase 2: Connect to the Dev Server

1.  Navigate to the local folder where your `.pem` key file is stored.
2.  Right-click inside the folder and select **Open Git Bash here**.
3.  Establish a connection to the dev server using the following command. Replace the bracketed placeholders with the correct file path and server address.

    ```bash
    ssh -i "[path/to/your/local/folder/EC2-access.pem]" ec2-user@[dev-server-address]
    ```
    **Example:**
    ```bash
    ssh -i "C:/Users/Manjunath.S/Downloads/dev/EC2-access.pem" ec2-user@ec2-XX-XXX-XX-XXX.compute-1.amazonaws.com
    ```
4.  If prompted to continue connecting, type `yes` and press **Enter**.

#### 4.3 Phase 3: Configure Server-Side Image Directory

1.  Once connected to the server, navigate to the images directory.

    ```bash
    cd /sonnet/images
    ```
2.  Switch to the `sonnet` user. This user is required for most file/directory operations.

    ```bash
    sudo su sonnet
    ```
3.  Create a new directory named after the client. Use a simple, lowercase abbreviation (e.g., `finvy`).

    ```bash
    mkdir finvy
    ```
4.  Exit the `sonnet` user to change group ownership.

    ```bash
    exit
    ```
5.  Change the ownership of the newly created directory to the `www-data` group. This is critical for web server permissions.

    ```bash
    sudo chown -R sonnet:www-data finvy
    ```
6.  Switch back to the `sonnet` user.

    ```bash
    sudo su sonnet
    ```
7.  Navigate back to the `/sonnet/images` directory.
8.  Copy the template image files (`.tif`) into the new client directory.

    ```bash
    cp *.tif ./finvy/
    ```
9.  Verify the files were copied successfully.

    ```bash
    ls -l finvy
    ```
    You should see the list of `.tif` files inside the directory.

#### 4.4 Phase 4: Create and Configure the Dispute Generation Script

1.  Navigate to the database scripts directory.

    ```bash
    cd /sonnet/db-scripts
    ```
2.  Copy the template script to create a new script for the client. Name the new script `make_api_[clientname].php`.

    ```bash
    cp make_api_template.php make_api_velocity.php
    ```
3.  Open the new script for editing using the `vi` editor.

    ```bash
    vi make_api_velocity.php
    ```
4.  Inside `vi`, perform the following edits:
    a.  Turn on line numbers for easier navigation: `:set nu` and press **Enter**.
    b.  Press `i` to enter Insert Mode.
    c.  **Line 11:** Update the `$companyId` variable with the ID noted in step 4.1.7.
    d.  **Lines ~107-109:** Update the `$organizationId`, `$companyId`, and `$teamId` variables with the same ID.
    e.  (Optional) **Line ~59:** Adjust the range in `mt_rand(50, 50)` to control the number of disputes generated per run.
    f.  Press **Esc** to exit Insert Mode.
    g.  Save and quit the editor: `:wq` and press **Enter**.
5.  Run the script once to generate the initial batch of disputes.

    ```bash
    php make_api_velocity.php
    ```
    The script should run without errors.

#### 4.5 Phase 5: Schedule the Dispute Generation (Cron Job)

1.  Ensure you are operating as the `sonnet` user.
2.  Open the crontab for editing. The `-e` flag stands for edit.

    ```bash
    crontab -e
    ```
3.  Press `i` to enter Insert Mode.
4.  Add a new section for the client. Copy an existing schedule line to use as a template.
5.  Add a comment header for clarity: `## Fin V Velocity ##`.
6.  Paste and edit the schedule line:
    *   **Schedule:** The first five fields (`* * * * *`) control the timing (minute, hour, day of month, month, day of week). Use a tool like [cronguru.com](https://cronguru.com) to validate your schedule. **Note:** The server operates in GMT.
    *   **Command:** Update the script path to point to the one created in step 4.4.2.
    **Example:**
    ```cron
    ## Fin V Velocity ##
    9 6 * * 1-5 /usr/bin/php /sonnet/db-scripts/make_api_velocity.php > /dev/null 2>&1
    ```
7.  Press **Esc** to exit Insert Mode.
8.  Save and quit: `:wq` and press **Enter**.

#### 4.6 Phase 6: Final Configuration in Sonnet Dev UI

1.  **Add Whitelisted IP Addresses for User Access:**
    a.  In the Sonnet Dev UI, navigate to the **Admin** section.
    b.  In the left menu, click **IP Addresses**.
    c.  Scroll to the bottom and click **Add New IP Address**.
    d.  Enter one of the whitelisted workstation IP addresses from the ticket.
    e.  For **Description**, enter the company name.
    f.  From the **Company** dropdown, select the new client.
    g.  Click **Add IP Address**.
    h.  Repeat for all required user workstation IP addresses.
2.  **Generate API Token:**
    a.  Navigate back to **Admin -> Organizations**.
    b.  Find the new company in the list.
    c.  In the **API Token** column, click the refresh icon to generate a new token.
    d.  Copy this token. It must be provided to the client.
3.  **Add Subscriber Codes:**
    a.  On the **Organizations** page, click the client's name to enter their profile.
    b.  Scroll down to the **Subscriber Codes** section.
    c.  Click **Add/Edit**.
    d.  In a separate browser tab, open the profile of a known working client (e.g., Mountain America) and navigate to their subscriber codes.
    e.  Copy each code from the working client and paste it into the corresponding field for the new client, one by one.
    f.  Click **Save Changes**.
4.  **Create User Accounts:**
    a.  On the client's company profile page, click **View Users**.
    b.  Click **Add User**.
    c.  Fill in the user's details (First Name, Last Name, Email).
    d.  From the **IP Address** dropdown, select one of the whitelisted IPs you added.
    e.  Click **Add User**.
    f.  Repeat for all users listed in the ticket.

#### 4.7 Phase 7: Verification and Communication

1.  **Verify Setup:**
    *   In the Sonnet UI, select the new company and click **Visit Sonnet**.
    *   Confirm that the disputes generated in step 4.4.5 are visible in the Step 1 queue.
2.  **Update the Ticket:**
    *   Respond to the client on the ticket.
    *   Confirm that the company and user accounts have been created.
    *   State that test disputes have been generated and are scheduled to run daily.
    *   Paste the **API Token** copied in step 4.6.2.
    *   Mention that their IP addresses have been whitelisted for access.
    *   Set the ticket status to **Pending** to await client confirmation.
--------------------------------------------------------------------------------
Title: SOP_Ticket backlog 20250624.txt
Based on the document provided, here is a Standard Operating Procedure (SOP) for the identified process.

***

### **Standard Operating Procedure: Manual File Retrieval from Client-Hosted SFTP Servers**

**Document ID:** SOP-SUPPORT-074
**Version:** 1.0
**Effective Date:** 25-JUN-2025
**Author:** Technical Support Lead
**Approved By:** James Maki, Manager

---

### **1.0 Purpose**

This SOP outlines the standard procedure for manually connecting to a client-hosted SFTP server to retrieve files that were not successfully processed by automated systems. This situation typically occurs when files are from a past date that automation is not configured to retrieve.

### **2.0 Scope**

This procedure applies to all Technical Support personnel responsible for investigating and resolving issues related to missing files where the client hosts the SFTP server.

### **3.0 Prerequisites**

*   A valid support ticket documenting the missing file issue.
*   Administrative access to a command-line terminal or SFTP client.
*   Securely stored credentials (hostname, username, password) for the client's SFTP server.

### **4.0 Procedure**

**4.1 Initial Triage**
1.  **Confirm File Location:** Verify that the missing file is located on a client-hosted server, not a Sonnet-hosted server.
2.  **Identify Need for Manual Retrieval:** Determine that the automated process failed to retrieve the file. A common cause is that the file’s date falls outside the automation’s processing window (e.g., automation only picks up files from the current day).

**4.2 SFTP Connection and File Retrieval**
1.  **Open Terminal:** Launch a command-line interface (CLI).
2.  **Construct Connection Command:** Prepare the SFTP connection command.
    *   **Syntax:** Use the standard `sftp` command format: `sftp <username>@<hostname>`
    *   **Password Handling:** You will be prompted for the password after executing the command.
    *   **IMPORTANT:** Do not include extraneous parameters or escape characters (e.g., `-b`) in the command or password, as this can cause login failure.

3.  **Execute Connection:** Run the command and enter the password when prompted.

**4.3 Handling Connection Failures**
1.  **Identify Failure:** If the connection is refused and you receive a `Permission denied` error, the client's server may have high-security settings that block IP addresses after failed login attempts.
2.  **Cease Attempts:** Immediately terminate the process by pressing `Control + C`. **Do not make repeated, immediate attempts to log in.**
3.  **Observe Cool-Down Period:** Client security systems may temporarily block your IP address after a failed login. You must wait for an unspecified cool-down period before trying again.
4.  **Re-attempt Connection:** After a sufficient waiting period, carefully re-attempt the connection, ensuring the credentials and command syntax (as per step 4.2) are correct.

### **5.0 Escalation Path**

If manual retrieval is unsuccessful after following the above steps, or if the issue is more complex than a simple retrieval, proceed with the following escalation path.

1.  **Internal Consultation:** Consult with a senior team member or the subject matter expert on the client account for guidance.
2.  **Consult Previous Ticket Owner:** If the ticket was previously handled by another team member (e.g., Amanda), contact them to gather context and history, especially for ongoing or recurring issues.
3.  **Developer Escalation:** For persistent, complex, or API-related issues that require developer-level investigation, flag the ticket to be discussed during the next scheduled developer sync meeting. Ensure you have all relevant details (ticket number, error logs, steps taken) prepared for the discussion.
4.  **Ticket Update:** Document all actions taken, including failed connection attempts and all escalation steps, in the corresponding support ticket.
--------------------------------------------------------------------------------
Title: SOP_tickets 20250630.txt
Based on the document provided, here is a Standard Operating Procedure (SOP) for troubleshooting and escalating persistent FTP connection failures.

***

### **Standard Operating Procedure: Troubleshooting and Escalating FTP Connection Failures**

**SOP ID:** SOP-SUPPORT-045
**Effective Date:** July 1, 2025
**Version:** 1.0
**Approved By:** Management

---

**1.0 Purpose**

To establish a standardized process for diagnosing, documenting, and escalating persistent client FTP connection failures. This procedure ensures that connection issues are systematically tested, evidence is properly collected, and the appropriate networking team is engaged for timely resolution, especially when the responding team lacks direct firewall access.

**2.0 Scope**

This SOP applies to all Support and Development team members responsible for investigating and resolving client-reported data transfer and connectivity issues.

**3.0 Prerequisites**

*   Access to the relevant application server (e.g., Web 01).
*   Access to the client's support ticket containing details of the issue.
*   Client's FTP host IP address.

**4.0 Procedure**

When a client reports a persistent FTP connection failure that has not been resolved through initial troubleshooting, follow these steps to test the connection and escalate appropriately.

**Step 1: Assess the Situation and Confirm Priority**
1.1. Review the ticket history to confirm the duration of the issue.
1.2. Recognize that a prolonged outage (e.g., one week) is a high-priority issue impacting client data delivery and must be escalated.

**Step 2: Prepare for a Telnet Connection Test**
2.1. Log in to the designated application server (e.g., `Web 01`).
2.2. Identify the client's FTP IP address from the ticket or system configuration.
2.3. Identify the port number required for the connection.
    *   If the client has specified a port number in the ticket, use it.
    *   If no port number is provided, assume the standard SFTP/FTP port: **22**.

**Step 3: Execute the Telnet Command**
3.1. Open a command line interface on the server.
3.2. Execute the `telnet` command using the following format:
     `telnet [Client IP Address] [Port Number]`
     *Example:* `telnet 123.45.67.89 22`
3.3. Observe the output. A failure is indicated by a "Connecting To..." message that times out or an "Could not open connection" error.

**Step 4: Document the Test Results**
4.1. Capture the results of the `telnet` test.
4.2. Copy the full text from the command prompt, including the command you entered and the complete output message. This will serve as evidence for both the client and the internal escalation team.

**Step 5: Initiate Escalation to the Networking Team**
5.1. **Determine that escalation is necessary.** A failed `telnet` test combined with a persistent issue confirms that the problem is beyond the scope of the support team's access (i.e., a firewall or network path issue).
5.2. **Contact the networking team (e.g., Cato group) via internal chat/messaging.** Do **not** add a team member to the ticket without consulting them first.
5.3. In your message, provide a concise summary of the issue and the steps taken.
    *   *Example Message:* "Hi team. We are investigating a persistent FTP connection failure for [Client Name] that has been ongoing for a week. The `telnet` test from `Web 01` to their IP ([Client IP]) on port 22 is failing. We need network-level assistance to investigate, as we do not have firewall access. Who is the best person to add to the ticket to help resolve this?"
5.4. Await a response from the networking team to identify the correct point of contact.

**Step 6: Update the Client Ticket**
6.1. Draft a reply to the client in the support ticket.
6.2. State that you have performed a connection test from your server and it has failed.
6.3. Paste the captured `telnet` command and output into the ticket as evidence.
6.4. Inform the client that you are engaging your internal networking team to investigate further.
6.5. Once the networking team has provided a contact, add that person to the CC list on the ticket to ensure they are included in all further communication.

---
**5.0 Revision History**

| Version | Date         | Author      | Change Description      |
|---------|--------------|-------------|-------------------------|
| 1.0     | July 1, 2025 | System AI   | Initial document creation |
--------------------------------------------------------------------------------
Title: SOP_tickets followup 20250614.txt
Of course. Here is a professional Standard Operating Procedure based on the document provided.

---

### **Standard Operating Procedure: How to Re-enable a Disabled Cron Job**

**SOP ID:** TSK-SVR-006  
**Version:** 1.0  
**Effective Date:** 13-JUN-2025  
**Author:** Technical Operations  
**Approved By:** Management

---

**1.0 Purpose**

This SOP outlines the standard procedure for investigating and re-enabling a disabled cron job on a Linux server. Cron jobs are scheduled tasks that run automatically. When a scheduled process (e.g., notification downloads, file transfers) is not running, it may be because its corresponding cron job has been intentionally disabled (commented out). This procedure details how to verify and re-activate the job.

**2.0 Scope**

This procedure applies to all Technical Support and Development personnel who are responsible for maintaining and troubleshooting automated system tasks and have the required server access permissions.

**3.0 Prerequisites**

*   Secure Shell (SSH) access to the target server (e.g., RPA 01, RPA 02).
*   Sudo privileges to switch to the user account that runs the cron jobs (e.g., the `sonnet` user).
*   Knowledge of the specific task or job that is failing, which will help identify the correct cron job entry.

**4.0 Procedure**

**4.1. Identify the Correct Server and User Context**

1.1. Determine the server on which the cron job is expected to run. Note that different jobs may run on different servers (e.g., RPA 01 vs. RPA 02).

1.2. Identify the specific user account under which the system's cron jobs are executed. In the context of this system, jobs typically run under the `sonnet` user.

**4.2. Access the Server and Assume the Correct User Profile**

2.1. Establish an SSH connection to the correct server.

2.2. Switch to the user that owns the crontab. This is a critical step, as cron jobs are user-specific.
    *   Execute the command: `sudo su - sonnet`

**4.3. List and Verify the Cron Job Status**

3.1. Navigate to the directory where the scripts are located (e.g., `/sonnet/download`) for context, if necessary.

3.2. To view the list of all scheduled jobs for the current user, execute the following command:
    *   `crontab -l`

3.3. Review the output. Locate the line corresponding to the job that is not running. A job is disabled if its line is "commented out" with a pound/hash symbol (`#`) at the beginning.

    *   **Example of an active job:** `0 4 * * * /usr/bin/script.sh`
    *   **Example of an inactive (commented out) job:** `# 0 4 * * * /usr/bin/script.sh`

**4.4. Edit the Crontab to Re-enable the Job**

4.1. To edit the crontab file, execute the following command. This will open the file in the system's default command-line text editor (e.g., `vi`, `nano`).
    *   `crontab -e`

4.2. In the editor, navigate to the line of the cron job you identified in step 4.3.

4.3. Remove the leading pound/hash symbol (`#`) from the beginning of the line. This action "un-comments" the line and makes the job active again.

**4.5. Save Changes and Exit the Editor**

5.1. Save the modified file and exit the text editor.
    *   **For `vi` editor:** Press `Esc` to ensure you are in command mode, then type `:wq` and press `Enter`.
    *   **For `nano` editor:** Press `Ctrl+X`, then `Y` to confirm changes, and `Enter` to save.

5.2. Upon successfully saving, the system will automatically install the new crontab and display a confirmation message, such as: `crontab: installing new crontab`.

**4.6. Final Verification**

6.1. To confirm the change was successful, list the cron jobs one more time:
    *   `crontab -l`

6.2. Verify that the line for the job you edited no longer has a `#` at the beginning. The job is now active and will execute at its next scheduled time.

---
**5.0 Revision History**

| Version | Date          | Author(s)             | Summary of Changes     |
|---------|---------------|-----------------------|------------------------|
| 1.0     | 13-JUN-2025   | Technical Operations  | Initial document creation. |
--------------------------------------------------------------------------------
Title: SOP_tickets followup 20250617.txt
**Standard Operating Procedure: Company Deactivation**

**SOP ID:** TEC-SOP-014
**Version:** 1.0
**Effective Date:** June 17, 2025
**Author:** SOP Generation Bot
**Approved By:** James Maki

---

### 1.0 Purpose

This Standard Operating Procedure (SOP) provides a standardized, step-by-step process for the complete deactivation and offboarding of a client company from the Sonnet platform and its associated infrastructure. Following this procedure ensures all user access is revoked, scheduled tasks are disabled, and server data is cleanly removed.

### 2.0 Scope

This SOP applies to all Technical Support and Operations personnel authorized to perform client deactivations. It covers procedures for FTP (Sonnet-hosted and client-hosted) and API clients.

### 3.0 Prerequisites

*   An official deactivation request from an authorized manager (e.g., via a support ticket).
*   Administrative access to the Sonnet UI.
*   SSH access to the following servers: `web01`, `RPA01`, `RPA02`, and `API02` (for API clients).
*   `sudo` privileges on the servers to assume the `sonnet` user identity.
*   (Recommended) Access to the `data-files` repository in Azure DevOps for cleaning up client-specific scripts.

### 4.0 Procedure

The deactivation process involves verification, UI-based deactivation, and server infrastructure cleanup. Perform these steps in the prescribed order.

#### 4.1. Initial Verification and Preparation

1.  **Check for Recent Activity:** Before proceeding, verify if the company has recent activity to avoid disrupting active work.
    *   In the Sonnet Admin UI, navigate to the company's profile.
    *   Check the **Users** tab for recent login dates.
    *   Check the **Dashboard** or **Disputes** section for any files or disputes currently being processed.
2.  **Confirm Deactivation:** If recent activity is found, obtain explicit, written confirmation from the requesting manager (e.g., via support chat or ticket comment) before proceeding.

#### 4.2. Identify Client Type

Determining the client's integration type is critical for the server cleanup phase.

1.  Navigate to the company's profile in the Sonnet Admin UI and click **Edit Company**.
2.  Select the **Additional Settings** tab.
3.  Identify the type based on the settings:
    *   **Client-Hosted FTP:** The "Push and Pull" options are enabled. These clients require script removal from the `data-files` repo.
    *   **Sonnet-Hosted FTP:** The "Push and Pull" options are disabled.
    *   **API Client:** An API token is present. These clients require cleanup on the `API02` server.

#### 4.3. Deactivate in the Sonnet UI

This step disables all user access and automated jobs within the Sonnet application.

1.  In the company's **Edit Company** screen, go to the **General** tab.
2.  Enter the official **Termination Date** as specified in the deactivation request.
3.  Uncheck the **Is Active** checkbox.
    > **CAUTION:** This action will immediately disable all users and scheduled actions for the company. It is a critical step that should only be performed with full confidence and authorization.
4.  Click **Save Changes** to apply the deactivation.

#### 4.4. Server Infrastructure Cleanup

This phase involves removing all company-related folders and files from the production servers.

**Note:** For **Sonnet-Hosted FTP** clients, wait 24 hours after UI deactivation before performing this step. This allows the client time to retrieve any final files (e.g., Step 3 reports) from their FTP folder.

**General Commands:**
*   Log into each server via SSH.
*   Switch to the `sonnet` user: `sudo su - sonnet`
*   Navigate directories: `cd [directory_name]`
*   Navigate up one level: `cd ..`
*   List directory contents: `ls`
*   Remove empty directories: `rmdir [directory_name]`
*   Remove files: `rm [file_name]` or `rm *`

**Cleanup Principle:** A directory must be empty before it can be removed with `rmdir`. You must delete all files and subdirectories first.

1.  **Remove from RPA Servers (`RPA01` and `RPA02`)** - *Required for all client types.*
    1.  SSH into `RPA01`.
    2.  `sudo su - sonnet`
    3.  `cd /sonnet/images/`
    4.  `cd [company_folder]` (e.g., `cd revsolve`)
    5.  Remove all subdirectories: `rmdir *`
    6.  `cd ..`
    7.  Remove the primary company folder: `rmdir [company_folder]`
    8.  Repeat steps 1.1-1.7 on the `RPA02` server.

2.  **Remove from Web Server (`web01`)** - *Required for FTP clients.*
    1.  SSH into `web01`.
    2.  `sudo su - sonnet`
    3.  `cd /sonnet/ftp/`
    4.  `cd [company_folder]`
    5.  Recursively empty the directory. Start by removing files, then empty subdirectories.
        *   `rm .*` (Removes hidden files like `.ftpaccess`)
        *   `rm *` (Removes other files)
        *   `rmdir *` (Removes empty directories)
    6.  If `rmdir` fails on a subdirectory (e.g., `images`), it means that subdirectory is not empty. You must navigate into it (`cd images`), empty it using the same commands, navigate back up (`cd ..`), and then remove it (`rmdir images`).
    7.  Repeat this process until the primary `[company_folder]` is completely empty.
    8.  `cd ..`
    9.  Remove the primary company folder: `rmdir [company_folder]`

3.  **Remove from API Server (`API02`)** - *Required for API clients.*
    1.  The process is identical to the RPA server cleanup.
    2.  SSH into `API02`, `sudo su - sonnet`, and navigate to the directory containing API client folders (e.g., `/sonnet/api/`).
    3.  Follow the same procedure to remove the company's directory and its contents.

#### 4.5. Repository Cleanup (Optional)

*If you have access*, remove the client-specific scripts from the `data-files` repository in Azure DevOps to maintain a clean codebase. This is primarily for **Client-Hosted FTP** clients.

#### 4.6. Finalization and Communication

1.  Update the original request ticket with the status of the deactivation.
    *   Example: *"The deactivation for [Company Name] has been completed. User access has been revoked and all associated data has been removed from the servers."*
2.  If you are waiting 24 hours to clean up a Sonnet-Hosted FTP client's folder, update the ticket accordingly and set a reminder to complete the task.
3.  Once all steps are fully completed, close the ticket.
--------------------------------------------------------------------------------
Title: Steps to run the rules engine.txt
Steps to run the rules engine
First connect to the rules engine server prdre01:
az ssh vm --vm-name prdre01 --resource-group rg-PaliPRD-LAN --prefer-private-ip --subscription Sonnet_Production_Environment

Then sudo to the sonnet user:
$sudo su sonnet

Change directories to the rules-engine-python folder:
$cd /sonnet/rules-engine/rules-engine-python/

Run the rules engine command:
$python rules_engines_mod.py
--------------------------------------------------------------------------------
Title: Stuck_Challenging Tickets Discussion & Knowledge Sharing with Amanda (Mon_Wed_Fri) 21 July.txt
StuckChallenging Tickets Discussion & Knowledge Sharing with Amanda (MonWedFri)-20250721_223408-Meeting Recording
July 21, 2025, 5:03PM
2h 13m 6s

Supriya Siddappa Kulageri started transcription

Sagar Gurudatta Pai   0:04
Having a conversation with Liddy that this is working as expected and what they're expecting would be an enhancement.
And.
We are struggling to communicate in which IT will be convincing for The customer to understand what what we are trying to say.

Supriya Siddappa Kulageri   0:27
Thanks.

Amanda Gilbert   0:28
OK, so it's the mid Florida ticket. Let me look. I see it on your screen, but I have a hard time following when you're scrolling, so I'm just gonna look on my screen.

Sagar Gurudatta Pai   0:39
Yeah, I'm not stable when I'm presenting. I know that I've got that feedback many times, I know.

Amanda Gilbert   0:41
You're OK.

Supriya Siddappa Kulageri   0:52
1.
Yeah.

Amanda Gilbert   1:29
So you're talking specifically about 22046 only, correct?

Sagar Gurudatta Pai   1:38
I guess The related incidents are also The same because on DevOps I believe nothing has been done. One second, I was going through IT 8119.

Amanda Gilbert   1:55
Mhm.

Sagar Gurudatta Pai   1:57
Because I did not see any communication, but I see directly. Uh.
Enhancement request where The child parenting parent child link linked dispute should follow The same queue and IT should give what do you call?
There was additional information there. I should give A. note indicating why IT was sent to The QAQ.

Amanda Gilbert   2:28
I see, yeah.
So I'm.

Sagar Gurudatta Pai   2:37
Because I.
Yes, please go ahead. Sorry.

Amanda Gilbert   2:39
Mm-hmm. I'm creating another one because it looks like it wasn't addressed fully.

Sagar Gurudatta Pai   2:46
OK.

Amanda Gilbert   2:46
I remember meeting with him about the disputes that are going to QA because I was under the impression they they were all going to QA and he said only the children were going to QA and that's how it was set up.

Sagar Gurudatta Pai   2:53
Mhm.

Amanda Gilbert   3:02
So I created a successor user story for an enhancement, but I don't see where the grouping is addressed.

Sagar Gurudatta Pai   3:12
Even I did not see that.

Amanda Gilbert   3:15
I don't either. I'm putting it in 101 and I'll give you a new ID, so just a second.

Sagar Gurudatta Pai   3:21
OK.

Amanda Gilbert   4:05
OK, 8503.
And I'm checking the two incidents there.
OK, same thing.

Sagar Gurudatta Pai   5:08
Then I was looking at this one as well. Can we move to next one?

Amanda Gilbert   5:14
Yeah.

Sagar Gurudatta Pai   5:15
8159.
Where they wanted to copy The custom queue from The consumer queue from 24200 to this organization 24201.

Amanda Gilbert   5:31
OK.

Sagar Gurudatta Pai   5:32
I see this year.
Not there.

Amanda Gilbert   5:49
OK.
So there's two things.

Sagar Gurudatta Pai   5:51
This is not.
OK.

Amanda Gilbert   5:54
There's two things that have to happen.

Sagar Gurudatta Pai   5:58
Mhm.

Amanda Gilbert   5:58
For a custom queue, the first thing is that it has to be built in the rules engine.

Sagar Gurudatta Pai   6:04
OK.

Amanda Gilbert   6:04
The second thing is you have to build the queues for the UI, so either they're not built in the rules engine or they're not built in the UI, or both.
So we need we can find out. I can show you how to find out or you can just ask the person who did the task.

Sagar Gurudatta Pai   6:19
Uh.
I have pinged Vinay basically for it.

Amanda Gilbert   6:30
Mhm.

Sagar Gurudatta Pai   6:32
8159.
I was already on it. My bad, sorry.
I'm waiting for him to ping me. I'm just waiting for his confirmation because there isn't any information which I can see here. There are many linked items here there.
So I'll guess I'll wait for him to get back to me.

Amanda Gilbert   7:03
OK.

Sagar Gurudatta Pai   7:05
And what was The other item? This one again, yeah, this is again related to rules engine where we said that IT is fixed, but The customer got back stating that IT is not fixed.

Amanda Gilbert   7:06
Mm.
100.

Sagar Gurudatta Pai   7:24
So multiple items in this DevOps #8240.

Amanda Gilbert   7:33
OK, so.
We so this one was closed. The original was closed. The client came back and said no, it's not fixed.

Sagar Gurudatta Pai   7:43
Mm-hmm. No.

Amanda Gilbert   7:51
OK.
What was the number for that one? The ticket number?

Sagar Gurudatta Pai   7:59
22670.

Amanda Gilbert   8:15
OK, so a couple things #1.

Sagar Gurudatta Pai   8:18
Mhm.

Amanda Gilbert   8:21
Anytime we change their no touch, we should be turning off their no touch.
So Vinay should be doing that. Whether or not he's doing it, I don't know. But we make the change. So we make the change. We turn off the no touch. They validate the change. Once it's good, we turn it back on. It looks like we left it on.

Sagar Gurudatta Pai   8:28
OK.
Mhm.

Amanda Gilbert   8:43
Which is. Does that make any sense to you?
I'm trying to make sure we're on the same page.

Sagar Gurudatta Pai   8:47
So The check.
I got IT that you are saying that whenever we are deploying any, making any changes related to no touch, no touch needs to be turned off. We make The changes, The customer validates IT and then we turn on The no touch, correct. So by keeping IT on, does IT mean that The changes never got into effect?

Amanda Gilbert   8:57
Yes.
Yes.
No, it means the customer wasn't able to validate the changes.

Sagar Gurudatta Pai   9:14
OK.

Amanda Gilbert   9:16
So it doesn't make sense for us to change automation and leave the automation on, right? They have to check it. They have to make sure because otherwise we can be held liable for issues. And I don't know about you, but I don't want to be liable for a client not being able to validate automation.

Sagar Gurudatta Pai   9:16
OK.
And.

Amanda Gilbert   9:35
So that's the first thing, and that would be on the dev's responsibility because they're the ones they know when they're going to make the change.

Sagar Gurudatta Pai   9:39
Um.
OK.

Amanda Gilbert   9:44
Um.
We should leave the work item that is closed as closed, but yeah, that's fine. The end for it is what I meant. We should leave it as is, but I think we need to.

Sagar Gurudatta Pai   9:50
It is resolved, not closed.
Mm-hmm.

Amanda Gilbert   10:00
Do a new one.

Sagar Gurudatta Pai   10:02
Mhm.
OK, I will do that.

Amanda Gilbert   10:08
All right. And make sure hold, hold on, let me let me do it because I want to make sure that it's attached to the original one, which is 8240. I just want it to be a successor of 8240. So if you can, if you can make sure that that happens.
So we yeah, just do the one above it add link cause yeah right there and then new and then just select successor.

Sagar Gurudatta Pai   10:26
OK.
It will not let me copy anything, right?

Amanda Gilbert   10:52
What do you mean?

Sagar Gurudatta Pai   10:55
It will pick up the details automatically or I wanted to copy the details.

Amanda Gilbert   11:00
No, it's. You'll have to copy the details. It's completely separate.

Sagar Gurudatta Pai   11:33
We would have to change the due date again as well for this putting a due date there because I remember while prioritization we did add that so we should accommodate it in the IT in the current sprint or the next one. Ideally I guess this sprint.

Amanda Gilbert   11:39
Mhm.
And we don't have any room in this spread. There's zero space, so you'll have to put it in the next one, yeah.

Sagar Gurudatta Pai   11:55
OK, so I'm not adding anything.
101.

Amanda Gilbert   12:33
Yes.

Sagar Gurudatta Pai   13:09
OK.
I can.
So any more I wanted to talk about?
I have to get back to this customer.
No, I guess just two.
I don't have anything else. These these were the only one which I wanted to talk.

Amanda Gilbert   13:47
OK.

Sagar Gurudatta Pai   13:49
James is there.

Amanda Gilbert   13:51
Oh, nice.
Hello, James.

James Maki   13:54
Yep, I'm here.
What's up, guys?

Sagar Gurudatta Pai   13:59
Are you not well?

James Maki   14:02
I'm good.

Sagar Gurudatta Pai   14:07
Alright, stage is yours, Supriya Manju s s.

Supriya Siddappa Kulageri   14:18
OK.
Let me share my story.
Um.
So.
Amanda. So I have asked him like, oh, he was getting this error.
Call 3170.

Amanda Gilbert   14:49
All right.
Um, James, we could pull up the dispute and in sonnet Supriya.

Supriya Siddappa Kulageri   15:18
So.
Sorry.

Amanda Gilbert   15:29
Will you go look at the dispute in Sonnet?

Supriya Siddappa Kulageri   15:32
Yes.
We chat and we rock that too.
Error after means in the account history we checked and we can see that the correction was made after the error came. So that's what we have said. The mind is telling.

Amanda Gilbert   16:59
Oh, what was the response code that they used?

Supriya Siddappa Kulageri   17:06
23.

Amanda Gilbert   17:07
Hmm.
Can you look at the history really quick?
OK.
OK.
Did they change the response code at any point in time?

Supriya Siddappa Kulageri   18:09
Window history.

Amanda Gilbert   18:11
Yeah, do a control F to and just search for response code.
Yeah, so that's why.
Um.
It I think the issue is resolved because James, I think this was related to remember that error that was coming for response code 03 when it was a consumer identity the dispute.

James Maki   18:54
Uh, vaguely.

Amanda Gilbert   18:55
Well, they changed it from an 03 to a 23, so that's why I think it's related.

James Maki   19:06
OK, that makes sense.

Amanda Gilbert   19:07
S.
So I think for this one you can tell them that um.

Supriya Siddappa Kulageri   19:10
I.

Amanda Gilbert   19:17
It was a bug related. I don't want to say a bug. How do we phrase that? You can say.
Um, we believe the development team has addressed this.
And if you continue to see this error, please let us know.

Supriya Siddappa Kulageri   19:42
Stop.
Thanks.
Bye.
Oh, Amanda, so for this Dr. notifications.

Amanda Gilbert   21:03
Mhm.

Supriya Siddappa Kulageri   21:04
So I have uh corresponded them this. So what's the next step?
OK. Yeah.

Amanda Gilbert   21:40
OK, let's go look at the transaction inside of Sonnet.

Supriya Siddappa Kulageri   22:12
Yes.

Amanda Gilbert   22:27
You have to change the type that you're searching for.
OK.
So this one.
Is you see the type how it says Dr. Notification ID?
So that means that there may not be a specific account number associated with this.
But basically the Bureau is saying that they deleted.
Some consumer information. Scroll down. Let's see what they deleted.
So they deleted the address. See that in the middle.

Supriya Siddappa Kulageri   23:33
Yes.

Amanda Gilbert   23:37
Keep scrolling down. Let's see what else they have.
OK, that's it.
So that address has been deleted. There is not an account number. They have to do the look up by the consumer information.
So let's, um, back out of it and then let's go back to the ticket.
OK, so.
You can tell Ryan. You can say Ryan, this is a Dr. Notification ID.
Which is related to consumer information only.

Supriya Siddappa Kulageri   24:52
Who?

Amanda Gilbert   24:55
Period. The CRA.
Has deleted.
Some consumer information.
In accordance with their internal policy or IP.

Supriya Siddappa Kulageri   25:26
Hmm?

Amanda Gilbert   25:27
And then period. And then you can say these are not always associated with an account number when they're specifically related to consumer information only.

Supriya Siddappa Kulageri   25:30
Yes.
M.
These are not always associated with.

Amanda Gilbert   25:55
With an account number.

Supriya Siddappa Kulageri   26:02
Who?

Amanda Gilbert   26:05
Especially when they are Dr. Notification ID.
As those are related to consumer information usually.
OK.

Supriya Siddappa Kulageri   26:58
OK.
Is this enough?

Amanda Gilbert   27:08
That's good.

Supriya Siddappa Kulageri   27:26
OK.

Amanda Gilbert   27:34
All right.

Supriya Siddappa Kulageri   27:36
Okay. Uh So this one in the dev environment, I have created his account.
So I think this is his connection issue maybe.

Amanda Gilbert   27:53
Um, there's a separate white listing that needs to be done.

Supriya Siddappa Kulageri   27:53
Damn.

Amanda Gilbert   28:01
James, can James, can you help with that? Because this is in dev and it's got that extra white listing.

James Maki   28:14
Are you talking about like for the firewall?

Amanda Gilbert   28:15
Yeah.

James Maki   28:18
OK.
I can. We are also starting to escalate that to the Pavana IT guys also, right? They're they're handling all the firewall stuff, but yes, I can.

Amanda Gilbert   28:30
OK.

James Maki   28:36
Handle it. Am I? You know, I'm saying there's not an IP address here on the ticket, right? Am I overlooking it?

Amanda Gilbert   28:39
Do do they know also like?

Supriya Siddappa Kulageri   28:48
Yes.

James Maki   28:51
OK. All right. So I know we had one.
On the setup tickets.
Alright, uh, if you go over to the dev environment, uh, there should be an IP address that's already whitelisted for him.
What uh?

Supriya Siddappa Kulageri   29:16
Please.
Oh.

James Maki   30:00
Oh yeah, these were the guys that gave us the 192 address.
OK, uh.
So they they gave us like an internal IP address, so the one that's whitelisted for them.

Supriya Siddappa Kulageri   30:16
Yes, this one.

James Maki   30:17
Yeah, yeah, yeah. So that's not actually like a valid IP address. So I think that's what the problem is. So just just ask them to like verify what the IP address is that they're connecting from.
Uh, like their their public IP.
And then uh, and then we can add that in the firewall.
Because that's not a that's not a public facing IP address, so that's not the one that we need to whitelist.

Supriya Siddappa Kulageri   30:39
OK.
Yes.

James Maki   30:59
And do you guys know what what I mean when I say that that's not a public IP address? Like do you guys know about the 192.168 IPS?

Supriya Siddappa Kulageri   31:07
Yes, means that one will be not applicable for all users.

James Maki   31:08
OK.
Well, it's not even that. It just means like it's it's not even public facing like that's not the IP address that's facing towards the Internet. So that that's like a.

Supriya Siddappa Kulageri   31:21
Hmm.

James Maki   31:24
It's it's like an internal IP address, like it's it's not quite the same as like the 10 dot IPS.
But it's but it's sort of similar to that.
But so anyone, anytime someone sends you an IP address that starts with 192.168, that's not a public IP address and that's not gonna get them.
Uh, connected to to Sonnet.

Supriya Siddappa Kulageri   32:40
OK.
So this one actually I didn't understand. I have asked him for the whatever subscriber code they have created.
So.

James Maki   33:20
Can you can you click on the on the person the profile icon on the right side?
On the right side, just like close that profile part.
Yeah, on the right, click on the person.

Supriya Siddappa Kulageri   33:41
Yeah.
I.

James Maki   33:43
On the far right, like actually all the way to the right.

Amanda Gilbert   33:48
The little symbol, The little person symbol.

Supriya Siddappa Kulageri   33:49
No.

James Maki   33:51
Like above the apps, above the apps icon. Like no further to the right. Yeah, yeah, the one. The person above that. Yes, there, just so we can see the ticket better.

Supriya Siddappa Kulageri   33:53
Yeah.
This one.
You said to maximize the OK.

Amanda Gilbert   34:07
So this one should be.
This one is something you can do by yourself O if you Scroll back to the very first communication.

Supriya Siddappa Kulageri   34:14
Yes.

Amanda Gilbert   34:20
Um, they say we have a new subscriber code. We need to add it.
The only thing that we're really missing from their first reply is the Bureau, because we have to select the Bureau.

Supriya Siddappa Kulageri   34:35
Mhm.

Amanda Gilbert   34:36
But if you'll Scroll down to where Gayla replies right there. Oh, one more just below that you replied and then right there. So she refers to to a novice.

Supriya Siddappa Kulageri   34:48
Hello.

Amanda Gilbert   34:52
So that subscriber code is for Innovus, so let's go add that.
So you'll go into Sonnet.

Supriya Siddappa Kulageri   35:01
Yeah.

Amanda Gilbert   35:04
You'll go to the company admin.
OK. And there you go. And then first thing that we're going to do is go down to Innovus and expand that.
And the reason why we're just double checking is because we don't want to add it twice accidentally.
When we are downloading, if we don't have the subscriber code here, we will add it when we download if it doesn't exist. So just click on the little arrow down there on the right side.
And let's see if that is in the list currently.
And it's not, so you're going to add it at the top.
So you're going to select the Bureau name. You're going to put the subscriber code in.
Remove the space at the end. There you go and then save and then you can let her know that it's been added.

Supriya Siddappa Kulageri   36:41
OK.
Yes, Amanda, I was having only those. So this one, so the rule updates. So do I need to?

Amanda Gilbert   37:18
OK.

Supriya Siddappa Kulageri   37:26
Oh, create a new DevOps or do we have any?

Amanda Gilbert   37:30
Yes, it needs a new DevOps.

Supriya Siddappa Kulageri   37:31
Existing demo.
OK, I will do that.

Sagar Gurudatta Pai   37:41
Supriya Manju s s for any rules related query. If it's a new one or update to the rules engine or anything, you should straight away click a demo. You need to follow the SOP which I have shared with you all.

Supriya Siddappa Kulageri   37:47
Who?

Sagar Gurudatta Pai   37:57
Especially for tickets request which use case for which you have to directly create DevOps. If you have any doubts for that, we can have a session again on that. We'll have it OK.

Supriya Siddappa Kulageri   38:11
No, it's not.
OK, so that's it from and like I don't have anything else.

Amanda Gilbert   38:22
OK.

Supriya Siddappa Kulageri   38:51
Saravana, you're on mute.

Saravanabhavan S   39:01
Hello.

Amanda Gilbert   39:02
Hello.

Saravanabhavan S   39:03
Yeah, so Amanda ticket number 23344. So then they are two users like whenever they are putting into work in progress still it even a active list. So it makes other on the list to place on the board.
So, but they didn't give the any ID, so not ID. So we need ID to investigate, right?

Amanda Gilbert   39:26
Yeah, so.
That's really the like. I've never heard of the send to whip not working ever.
And every user should have access, so I would ask for specific IDs to investigate.

Saravanabhavan S   39:45
OK.
OK. So we have to investigate in both these two companies like RSC and Cyclone.

Amanda Gilbert   39:52
Um.
I What are we doing? I don't think there's anything to investigate right now. I think we prompt them for details, so we need more information. So I would just say we need some more information to.

Saravanabhavan S   40:00
OK.
E.

Amanda Gilbert   40:13
Provide some Sonnet ID's where the user sent them to WIP and they remained inactive so we can investigate.

Saravanabhavan S   40:13
The.
Yes.
OK.
OK, so and.
So same in Barclays, so they also having multiple users accessing same dispute at same time so.
From their side, they know.

Amanda Gilbert   40:42
So we have. Sorry, go ahead.

Saravanabhavan S   40:46
From their side they share that WAP but when I try to research on that I can see like work in progress to complete only.
So may they may there may be bug from their side.

Amanda Gilbert   41:06
Um.
I don't think so. I think that there may be.
This is related to disputes, not walking, right? Something different.

Saravanabhavan S   41:22
Uh.
Like they are two agents, so if one agents like accessing the same same dispute at the same time, they're having issues.

Amanda Gilbert   41:29
Mhm.
Right, so it's dispute's not walking because normally s s.
If I'm in a dispute, you can't go into that dispute and we refer to that as dispute locking. So it's locked. It locks everyone else out and I believe we have a problem ticket for this same issue.

Saravanabhavan S   42:02
OK.

Amanda Gilbert   42:04
So see if you can find the problem ticket for disputes not locking.

Saravanabhavan S   42:11
OK.

Sagar Gurudatta Pai   42:14
I can help with that. It's in the it's in the sheet which SharePoint sheet which I shared which Chandan shared. But Amanda that DevOps ID is listed as deployed and fixed.

Saravanabhavan S   42:14
So I can't stop.

Amanda Gilbert   42:28
OK, it's not. So I is it really deployed? That's what I want to know.

Sagar Gurudatta Pai   42:37
OK, give me a few minutes. I'll share that as it's carry on. I'll share that. Let me get back.

Saravanabhavan S   42:42
Yeah.
So shall I just link this to the problem ticket?

Amanda Gilbert   42:50
Yes.

Saravanabhavan S   42:51
OK.
And one more so we have done that Renton builds on last Friday. So they are asking yes they don't have a sort of interrogation integrations. So the so they asking like remove the current disputes from and schedule the download from.

Amanda Gilbert   43:06
Mm-hmm, mm-hmm.

Saravanabhavan S   43:15
Ask her.

Amanda Gilbert   43:15
Mhm.

Saravanabhavan S   43:17
Asking which time um can take place.

Amanda Gilbert   43:23
So we have a DevOps item for this one also. So if you Scroll down just a little bit, you'll see there's a DevOps item.
Maybe.

Saravanabhavan S   43:37
Noon.

Amanda Gilbert   43:37
No.
Um, can you click on Selfbank to see all of their other tickets?

Saravanabhavan S   43:49
So 8206 we have one DevOps, another DevOps bank.

Amanda Gilbert   43:57
Um.
Scroll down just a little bit.
Hmm, they should have. There is one. Let me find it.
So there is a DevOps work item.
Already. Let me see if I can find it.

Saravanabhavan S   44:15
OK.

Amanda Gilbert   44:19
Um.

Saravanabhavan S   44:19
So we have one existing DevOps 8206 for cell back.

Amanda Gilbert   44:28
8206.

Saravanabhavan S   44:29
Yes.

Amanda Gilbert   44:35
Yeah, that's the one that should be attached.

Saravanabhavan S   44:38
OK.
M.

Amanda Gilbert   45:52
OK, so for now.
You found the link. It looks like it did not get moved over in Sprint, so it probably just dropped and.

Saravanabhavan S   46:05
OK.

Amanda Gilbert   46:08
I went ahead and created another story in 101 with this.

Saravanabhavan S   46:16
OK.

Amanda Gilbert   46:16
But you can still find it. So for now there's another thing that we can do. The disputes are getting stuck in new status and so we need to move the disputes to active status.

Saravanabhavan S   46:30
OK.

Amanda Gilbert   46:31
Do you know how to do that?

Supriya Siddappa Kulageri   47:13
Uh, Sarona, that update.

Saravanabhavan S   47:14
Oh, it's this.
This one time.

Amanda Gilbert   47:22
Um.

Manjunath S   47:22
Yes, let insert into that query.

Amanda Gilbert   47:28
Yes.
You can use that one, but you you'll need to change the Sonnet status from active to new, but you can use both of those.

Saravanabhavan S   47:36
Uh.
OK.

Amanda Gilbert   47:50
So delete that whatever you're typing, delete it.

Saravanabhavan S   47:55
Uh, just I'm putting a no, no, no, no.

Amanda Gilbert   48:00
OK, so see where you have active already there.

Saravanabhavan S   48:05
So we have to give you.

Amanda Gilbert   48:08
Yeah, just replace active with new.

Saravanabhavan S   48:11
OK.
So if we run these two queries.

Amanda Gilbert   48:22
Yeah, I would resave this query. I would take out this one, but like don't take it out, don't delete it. Just change where you have active, change it to new.
On both because we were doing something different when we changed these. So for this purpose where we're trying to move stuff from active to new.

Saravanabhavan S   48:35
OK.
Thank you.

Amanda Gilbert   48:46
You'll just run these two queries and you're referencing new status.

Sagar Gurudatta Pai   49:07
I've pasted the disputes not locking DevOps in the chart.

Amanda Gilbert   49:13
OK.

Saravanabhavan S   49:50
Where else come to them?

Amanda Gilbert   49:53
I'm sorry.

Sagar Gurudatta Pai   49:55
Go to the front, go inside the application and see whether you can see disputes in new status, right? Whenever you make any changes, try to validate first or whenever you guys are communicating.

Saravanabhavan S   49:56
So.
Yes.

Sagar Gurudatta Pai   50:12
Any fixes to customer validated first?

Saravanabhavan S   51:00
It is updating in rules engine, right?

Amanda Gilbert   51:03
Yeah, it looks like it's still running.

Saravanabhavan S   51:07
So it wants everything as to false.

Amanda Gilbert   51:08
Sick.
Yeah, but if you go to the the client side of Sonnet, you should see the number has changed.

Saravanabhavan S   51:42
Yes, the numbers has been changed.

Amanda Gilbert   51:46
You said yes, it has.

Saravanabhavan S   51:51
It was around like 267 before. Now it's changed to 0.

Amanda Gilbert   51:56
Oh, nice. OK, that's good. The other way that you can check is if you go to their look ahead.
On the left menu, yeah, that one right there. And what we're looking for is new. So I don't see any new. Do you see any new?

Saravanabhavan S   52:17
No.

Amanda Gilbert   52:18
Yeah, it's a different color too. So I think what you did worked and you can tell them that it's good. What I would expect. So you fixed it for today, right? Tomorrow they're going to have the same thing that's going to happen.

Saravanabhavan S   52:20
M.
Yeah.

Amanda Gilbert   52:37
We're going to download. The disputes are going to hang out new until dev does their part.

Saravanabhavan S   52:43
OK.

Amanda Gilbert   52:43
Um, you can expect that the client is going to reach out consistently.

Saravanabhavan S   52:50
OK, so instead I didn't have, instead I can do a daily work on until the task missed.

Amanda Gilbert   52:50
But you have a workaround. Do what?
Yeah.

Saravanabhavan S   53:00
OK.

Amanda Gilbert   53:00
That's all that you can do until they fix the the part that's not working.

Saravanabhavan S   53:06
So before that I have to do a download or I'll just if I run this query to move to the end to the new, it's fine.

Amanda Gilbert   53:15
You have all. You don't have to do a download that's already scheduled.

Saravanabhavan S   53:19
OK.

Amanda Gilbert   53:19
You'll just have to run those queries to move them from new to active.

Saravanabhavan S   53:27
OK.
OK.

Amanda Gilbert   53:41
All right. Um.

Saravanabhavan S   53:43
Best one.

Amanda Gilbert   53:44
All right.

Saravanabhavan S   53:45
And this one we took you, uh, create the dev task, right?

Amanda Gilbert   53:51
These can rule to not recommend 03 deletion response. Yeah, that one. That one needs a dev task. It's roles.

Saravanabhavan S   54:09
That's up for my exam.

Amanda Gilbert   54:12
OK, we're out of time and I have a hard stop. So Manju, if it's an emergency, you can message me the IDs and I can help you or you can wait until Wednesday.

Manjunath S   54:29
Sure, Amanda. If any emergency case, I'll let you know.

Amanda Gilbert   54:33
OK.
Thank you. See you guys later.

Manjunath S   54:37
Thank you, Amanda.

Sagar Gurudatta Pai   54:38
Thanks, Amanda. Thanks everyone. Bye, bye.

Saravanabhavan S   54:38
Thank you.

Amanda Gilbert   54:41
Thank you.

James Maki   54:44
Thank you, guys. Hey, uh, Servon, are you uh?
Are you gonna be busy?
In about 30 minutes.

Saravanabhavan S   54:55
No jobs.
No jobs.

James Maki   54:58
OK, do you want to get on a call? I know Scar had asked us to spend a little bit of time, like some one-on-one time together. Can I? I'm gonna send a meeting out just for me and you for like an hour. Is that cool?

Saravanabhavan S   55:11
OK, James.

James Maki   55:12
OK. All right. I will see you then.

Saravanabhavan S   55:15
Thank you. Thanks.

Manjunath S   55:17
Yeah, James. So, James, so.

James Maki   55:17
Right.
Mhm.

Manjunath S   55:22
I have small doubt.
One second.
These two tickets I need to create and already they are dev talk. So for this report one right? Shall I link it to that? It is related to the reports like they're not getting the reports accurate number.

James Maki   55:47
Is this reports tab is not reporting accurate numbers?
For completed responses.
Alright, she didn't really tell us. Is she talking about The productivity reports?
'Cause I don't like that's.

Manjunath S   56:09
Like, yeah, completed response.

James Maki   56:13
OK, but like A. but.
But so like, is she talking about like The disputes submitted or or The pro? OK, all right, she is talking about The productivity reports. OK, all right. So I mean, we already kind of know about that being an issue. So there should, there should be A. problem ticket.

Manjunath S   56:22
The productivity report.
Mhm.

James Maki   56:35
Already. All right. And then and did you find?

Manjunath S   56:35
Yeah.

James Maki   56:40
Did you look in DevOps? You found The dev task board also.
Or that's what you're looking for now.

Manjunath S   56:44
Uh, productivity.
Productivity, I think it is not resolved yet still.

James Maki   56:51
Yeah, no, it's definitely not resolved for sure, 'cause that's gonna be something that Lyd's gonna have to work on. Yeah, incident.
Yeah, there should be something there. There we go. Yeah. So I think that's our main one there.

Manjunath S   57:08
Yeah, I will just update.

James Maki   57:09
If you would just ask her like can for like The like specific examples of like what she's seeing that's wrong just just so we have IT for The problem tickets.
And then I and then you could tell her that we're looking into it. Um.
Be able like in anything that these guys that these that The clients can show us like that shows us like The exact issue and anything that they that you guys can get from them to show that will be helpful.

Manjunath S   57:35
OK.
And I think this one also some I have some image issue.

James Maki   57:51
What was The did we did we complete that one? Oh, The history request 23229, The second one? Yeah, did we complete?

Manjunath S   58:00
This one, this one that's actually I need to send the report to their mail ID.

James Maki   58:08
OK, 'cause didn't we?

Manjunath S   58:11
Actually, we have sent them the report.

James Maki   58:13
OK. And then he was just having trouble accessing it, right?

Manjunath S   58:16
Yeah.

James Maki   58:20
All right. Oh, was it? Was IT Ben or Joey that was having trouble?

Manjunath S   58:25
Hmm.

James Maki   58:26
So I think it's just because whoever IT was, like they weren't copied. I think it's probably Joey, right? Yeah, Joey, can you open The attachment? He doesn't have access. OK, so I think if you just send The attachment again now, now that Joey has CC'd on it, send The attachment again.

Manjunath S   58:32
Yeah, doing, yeah.
Oh.
A.
OK.

James Maki   58:42
And then and then let's also send A. Zendesk password reset for Joey just to make sure that he can just make sure that he can log in and download The attachment.

Manjunath S   58:53
OK.

James Maki   58:53
And that should that should take care of it. Yeah, but I yeah, but so I think Joey just couldn't access IT because he wasn't originally on The ticket. So I think you just have to resend IT again now that he's on it.

Manjunath S   58:55
Shut us.
Uh.
Sure.

James Maki   59:05
All right.

Manjunath S   59:08
That a course.
Yeah, that's it. James dot. Yeah, James, if anything is there, this one James. Actually this is like this is ACDV report, right? I mean ACDV number.

James Maki   59:25
OK.
Yeah, IT looks like A. control number. Yeah. How documents are saved for us. Oh, this is for Columbia. Oh, this is for the.

Manjunath S   59:40
Yeah, yeah, this image issue.

James Maki   59:45
Yeah, alright, so this is for The renaming.

Manjunath S   59:49
Actually, they are facing the image.

James Maki   59:50
I got 35 images, but The download we received for images only contains The first image. What is going on here? OK.
Uh.
OK, so possibly what's happening is because we can receive up to five, up to five TIF files for A. single account. So I suspect that is probably The issue here.

Manjunath S   1:00:11
Mhm.
Yeah.

James Maki   1:00:23
Um uh.
Let's see, he gave us the control number. Look it up on the admin side real fast and let's look at the account history and let's go to the to the very, very beginning of the account history where the image was downloaded and it should tell us.
How many files there were O? Let's start there.
Yeah, but yeah, so these guys are requesting.
Or uh or are in the process of like requesting some uh.
Uh, renaming changes. Uh, but the problem is.
They've already changed their naming format with the credit bureaus, so now they're coming through inconsistently and so they're wanting us.

Manjunath S   1:01:19
Musti.

James Maki   1:01:21
Yeah, yeah, go to history. Alright.
So like whenever you're just looking at history stuff, it's certainly better to look it up on the admin side just so we're not actually going into the account, but it's fine. So let's go all the way down to the bottom. I'll I'll wait at the beginning.
OK.
All the way down.
There we go. OK, oh, and there is only one attachment. OK, alright, so there's only one file 'cause there's only one attachment. So alright, so I was wrong.
Uh, so that doesn't make sense for him to have only gotten the first image.

Manjunath S   1:02:00
Uh.

James Maki   1:02:05
Yeah, so that doesn't make sense at all. OK, this is on.
The API server.
Alright, uh, let's see if the file is. It should still be on the server. Let's let's go see.
But.

Manjunath S   1:02:33
Columbia.

James Maki   1:02:34
It should be on the API server. Let's go ahead, disconnect, disconnect from level one and let's go over to the API.

Manjunath S   1:02:53
Yes, I payable one.

James Maki   1:02:57
No, we want to go to API and I think it's gonna be API 02.
Uh, looks like you might have to go to my list.
Oh, I'll go to the. I mean, you can get it from. Actually, it might not be on here. Go to my the other one.
The the server list.
Uh, back. Uh, go up a level into documents.
Yeah, and the Azure server list.
Yeah.

Manjunath S   1:04:53
This one Jim CPA photo.

James Maki   1:05:00
Yeah, that one. Yep.

Manjunath S   1:05:31
Same thing, the CD space on FTpedia.

James Maki   1:05:36
Well, you're on the API server, so there's no FTP directory.
Oh yeah, I mean, you can pretty much always bet it's always gonna start with slash sonnet, so you can pretty much always start there. And then if you aren't sure, just go there first and then do LL so you can see what's available.
No, you were right. You had it.

Manjunath S   1:06:01
OK, CDs is on it.

James Maki   1:06:04
Uh, you left out the space, but yeah.
Yeah, like you can. You can pretty much guarantee it's always gonna start here. So yeah, so do that first.
And then do LL so you can see the available subfolders. All right, so this is the API directory or server. So the only thing that this is used for is for the clients to pick up their images.
O Let's go into the images folder.
Alright, and now you now you should see your list of clients. So the the API structure, it it kind of mimics the image servers. So they're pretty much the same. Like if if you're going to one of these three servers, either the API or the two image servers, you're probably going to slash on it slash images first.
And then this is gonna be Genesis is is their name. They they have an alias. Yeah, yeah, that's the one.

Manjunath S   1:07:05
Genesis grid.

James Maki   1:07:15
All right, so since this is the API server, there's gonna be a lot of files here. See, I mean, you can list them out first if you want. That's fine. It doesn't matter, but we're gonna oh.
There's nothing.

Manjunath S   1:07:31
0.

James Maki   1:07:34
Alright, that's not what I expected. These guys are API, are they? Didn't I see? Don't they have a token? They do have a token.
I'm confused.

Manjunath S   1:07:52
Yeah.

James Maki   1:07:56
All right, so.

Manjunath S   1:07:56
API client teams.

James Maki   1:07:59
OK, but their image files aren't there.
Or.
Are these guys some kind of weird hybrid? What's going on here?
Uh.
OK, I guess, I guess so.
All right. Uh, OK, so I guess.
Yeah, that's not confusing at all.
Alright, so I guess these guys do the data transfer over API, but I guess their images are sent over FTP.
Alright, so that's kind of unique.
Experian.
All right, well, I guess you can get off of this server then. Apparently they don't use this for the images. All right, so that's actually that's unfortunate.
Um.
Alright, when was the when was the account received? Go back over to your sonnet.
Alright, uh uh, look it up again on the admin side.
Oh, how old is this dispute?
OK. Received on the 30th. OK, well, shoot.
Um.
Oh, well, OK, well.
Alright, alright, so if you go back, let's go go back over to the FTP server over to web 01. So it looks like.
It looks like they're moving.
All right, so they're moving all of their image files.
They're leaving them on our server.
Which is sort of good 'cause that means we can look at him, but.
Yeah, Genesis Grant again.
And go look in their process folder.
So they're leaving all their files out there.

Manjunath S   1:11:31
Uhuh.

James Maki   1:11:33
So for one, that's really annoying. We don't want them to do that. We I've said it before. We are not supposed to be infinite storage for these people. Like they're really kind of abusing us by doing this. But the good news is it looks like everything out there or everything should still be out there, so we can.
Look here and see if the file is there.
Alright, so do you have the do you have the control number copied?

Manjunath S   1:12:03
Yes, James.

James Maki   1:12:03
OK, alright, so let's do uh.
OK, all right, let's do a find Tye find and then sace star and then paste in the control number.
Take off the space at the end, hit hit hit backspace one time and then do another star.
All right, and hit enter.
OK. All right. So the file is there. So that's good. OK. All right. Let's see if we can. Let's see if you can download this. I think this will work. All right.
So uh, go over somewhere on your local on your local side. Uh, go to your folder.
Just anywhere really.

Manjunath S   1:13:01
New folder should create new one.

James Maki   1:13:03
No, like like on on your computer, go to like your local folders, like go go somewhere on your local machine.
And we and we need to open a git bash window.
Yeah, just go like to like to your downloads folder or something, something like that.

Manjunath S   1:13:45
Miss James.

James Maki   1:13:48
Alright, so right click on like a blank space and let's do a open git bash here.
And runs.
Run this command.
Uh, yes.
Alright, good. Alright. And then I'm gonna send you one more command.
Alright, and so we need to paste in the file name.
Uh.
So before you run that, go back to. Yeah, go back to the server. Copy the dot TIFF file name.

Manjunath S   1:15:08
Yeah.

James Maki   1:15:17
The dot TIF one, the dot TIF one, the one above that.

Manjunath S   1:15:17
The working.

James Maki   1:15:21
Yeah, yeah, copy the whole thing.
Alright, and then and then over in your bash window after after the processed slash.

Manjunath S   1:15:31
A.

James Maki   1:15:33
So go left one more space and then paste that. Paste that file name in right there. There you go. Alright, go ahead and run that.
Perfect. All right, so you have downloaded the file. All right, so if we go back to your Downloads folder, we should see that TIF image now.

Manjunath S   1:16:06
Yeah, it's a case.

James Maki   1:16:07
Alright, so let's let's take a look at that and let's see if we can see all the pages.

Manjunath S   1:16:15
Open with.

James Maki   1:16:15
The the the TIF file. The TIF file. You're clicking the wrong thing.
Yeah.
There we go. All right. And all right. And it looks like there's 38 pages there. So, So what's he talking about?

Manjunath S   1:16:28
Yeah.

James Maki   1:16:33
All right.
Alright, so we verified that all the pages are there. It's one file.
Dude, I've I've seen it before and I swear I bet he's probably just not looking at it right. And I bet he's just missing the page button where like wherever it is that he's looking, if he's looking at it in his system, whatever it is that he's doing.
But alright, but so we've verified now that all the pages are there, so you can so you can tell him.

Manjunath S   1:16:59
Uh-huh.
Uh.

James Maki   1:17:06
We have fair so you can tell them exactly what we did.
Uh.

Manjunath S   1:17:10
We have.

James Maki   1:17:15
Yeah, we we verified all pages are present in the file. I would send him the file name that you downloaded. I would send him that file name so you can tell him exactly what file to look at and you can also tell him it's still on the server. So if he wants to go redownload it, he can do that.
So most of the time people can't do this because I mean this, this is probably why we tell them to pick up their files, right? Is 'cause we don't we don't want, we don't want to be responsible for this kind of thing, but.

Manjunath S   1:17:52
Uh huh.

James Maki   1:17:59
But in this case, it is kind of good for us like that. We can literally tell him, yeah, just go download it again and see for yourself.
So that that is that is kind of helpful for us.
Available, yeah, on the server in I would say in the process folder and then I would say yeah and then.

Manjunath S   1:18:26
Available on the server in the.

James Maki   1:18:29
Yep, and yeah, in the process folder.
And so you're telling them exactly where to look.

Manjunath S   1:18:46
Oh, we'll attest the document that we have downloaded.

James Maki   1:18:51
Um.
I mean, I don't think you, I don't think you need to do that since it's already on the FTP and we saw as you were thumbing through those images, there is PII in there like it looked like there was a Social Security card. So I really would rather not send that.

Manjunath S   1:18:56
Yeah.
Uh huh.

James Maki   1:19:09
But uh yeah, but but give them the file name though. Like just just copy that and tell them this is the file.

Manjunath S   1:19:18
This is the file name right?

James Maki   1:19:19
Yeah, Yep, that one.

Manjunath S   1:19:35
Yeah.

James Maki   1:19:36
Yeah, yeah, I think that's good.
So I mean like this should have answered any questions that he has, right? Like like we verified that the images are all there. If you don't believe us, you can go download the file again. Here is where it is. Here's the file name.

Manjunath S   1:19:45
Ha ha.

James Maki   1:19:56
So yeah, so it should take should take care of it.

Manjunath S   1:19:57
OK.
Oh.

James Maki   1:20:00
All right, and so so save those commands that I just said because so like that's that's what you can use to download files off the FTP server. So you have to run that first command. So like that creates like the permission file, right? And I know we've talked about it before, but just to reiterate.

Manjunath S   1:20:04
Uhuh.

James Maki   1:20:15
So that was the that's what the first command I sent does is it sets up like your little the credential for you to log in. And then yeah, then that second one. So you're.
Like the the way that the commands work in there is just telling.
So that's like the that's the local IP address for the server is what that 10.104.4.50 is. So there's a different local IP address for each server, right? So like if you wanted to download from the API server, you could do that also. It's just gonna have a different IP address.

Manjunath S   1:20:45
Mhm.

James Maki   1:20:47
And I don't know all of them, but.
Uh, I think I do have the API one though.
I think it's buried in my history somewhere.
All right. Do you guys have have more tickets that you guys need help with? Do I need to set up some more time later on this afternoon?

Manjunath S   1:21:53
Uh, no.

James Maki   1:21:53
Well, my afternoon, I know it's already getting kinda late for you guys.

Manjunath S   1:21:59
Yeah, James, that something related to like asterisk symbol.
For the you just federal.
Like, uh, said like valid character. So again they were given a reply.

James Maki   1:22:27
To use Azure.
All right.
Alright, So what is she trying to do? She's trying to.

Manjunath S   1:22:46
First trying to like in the payment portal. Oh, she would like to use the asterisk symbol to remove this completely.

James Maki   1:23:06
Uh.
Um, I.
I think they just leave it blank, but I'm not positive.
Um.
Uh, yeah, that might be kind of a question for Amanda. Um.

Manjunath S   1:23:48
Yeah.

James Maki   1:23:48
Yeah, I don't. I don't think I have an answer on that one, unfortunately, or not, not one that I'm positive about anyway.

Manjunath S   1:23:54
Sure.
This mass good account. We have a OPS link for this items. Oh yeah, already Amanda has created, I think.

James Maki   1:24:13
OK, yeah, yeah. So I met just already got that in place, it looks like.

Manjunath S   1:24:28
Yeah, I just update this in on hold.
OK yeah James, so like how do we send the step to file for the previous date? Like I'll just check it but we haven't received the step two for the date 7/10.

James Maki   1:24:49
Alright, so the automation is only gonna pick up the current day's files, so if you're trying to get an old one, you have to do it manually.

Manjunath S   1:24:54
Mhm.

James Maki   1:24:59
Uh, so you have to go go get the credentials from VS code.
And from the server you have to log in and download the file.

Manjunath S   1:25:10
True code is for like ERC, right?

James Maki   1:25:17
True Accord is, yes, but was that was for team recovery, right?

Manjunath S   1:25:23
Oh yeah, so that thing recovery.
Oh, yes.
So password we have to remove the own special character items.

James Maki   1:25:58
Yes, yes, there is one there.

Manjunath S   1:26:03
On this one.

James Maki   1:26:05
Yep.

Manjunath S   1:26:12
We need this P no right only this is the password.

James Maki   1:26:18
Uh, that is the password. Yeah, the whole thing. Yep, you got it.

Manjunath S   1:26:28
Oh, we need to do so.

James Maki   1:26:31
You do so do control C to to stop the connection.
And then we'll we'll see if it'll let you connect now, 'cause these guys.
They do like a temporary logout every time you have a failed attempt.
OK, that's good.

Manjunath S   1:27:03
Oh.

James Maki   1:27:04
Alright, is that not the right password?
Open. Open up your terminal, yeah.

Manjunath S   1:27:11
This one.

James Maki   1:27:16
Yeah.
All right, all right. Just all right. I I don't like what you're doing. All right.
Did did the password get updated? Is there? Are are you behind? Open up your terminal. Do do control C again. Stop the connection.
All right, in VS code, open up your terminal.
Let's go to view, I think view terminal.
Alright, so let's do get checkout main.
Uh gets GIT.
No, whenever you're doing a get command in VS like in VS code, it's always gonna be GIT.

Manjunath S   1:28:14
OK, good check out main singles without space.

James Maki   1:28:20
Uh, with a space.
Space between out and main. Yeah, checkout's one word. Space. Space. Main. There you go. Yes.
Alright, and then do get pull.
Yep.
Now see in your team recovery commands just got updated.
All right, all right. OK, all right. So now you're up to date. closeout of your Team Recovery Step 2 tab.
Yeah, close it, don't save and then and then go back and open it again.
So it looks like you were using. You were using the old password because your script was not up to date.

Manjunath S   1:29:28
OK.

James Maki   1:29:29
So there's so there's the new password.

Manjunath S   1:29:46
No special characters, right? Yeah.

James Maki   1:29:49
Yeah, no, no escape character. Yep.
Mm.
All right, something.
OK.

Manjunath S   1:30:16
Mm.
I think it takes some time to grant the access right once it is denied.

James Maki   1:30:29
I mean possibly.

Manjunath S   1:30:32
Mhm.
OK Jim, so once we login into this, it will be in the out folder, right?

James Maki   1:30:42
Uh, yes.

Manjunath S   1:30:45
OK, so it will be in the database.

James Maki   1:30:46
I'm afraid. All right, I'm. I'm afraid that I really hope you didn't lock out our account.
Like that's actually.
Yes.
I don't understand what's happening. Why is this not working?
Why is that password not working?
Uh, yeah, it looks like that was taken care of.

Manjunath S   1:32:31
SCCS is so dungeon, so I just processed the step 2 files and all the dispute size been moved to the active status.

James Maki   1:32:40
Great.

Manjunath S   1:32:48
So just select those this ticket.

James Maki   1:32:54
Uh, yeah, it looks like it.

Manjunath S   1:33:21
Uh, Jim, so that uh landly the properties have been corrected.

James Maki   1:33:38
Oh yeah, what was?
Uh, was this one of the two that was that was having the?

Manjunath S   1:33:48
Yeah they were able to access so but some error they are getting in properly. So last time we checked it right.

James Maki   1:34:04
Yeah, alright. So I think we need to look at crush for this, right?

Manjunath S   1:34:08
Uh.

James Maki   1:34:10
Wait, what? What did that message say? What was that error?
OK.

Manjunath S   1:35:10
Properties.

James Maki   1:35:11
Yeah.
I.
Yeah, OK, so this is for Langley. All right, so this is connecting to the web 01 server is where this is looking. All right, so Langley FCU is the correct.
OK, alright, so in the in the URL go all the way to the end.

Manjunath S   1:35:40
Uh.

James Maki   1:35:47
And it should have Langley FCU there.

Manjunath S   1:35:50
Yeah.

James Maki   1:35:52
OK.
OK, uh, alright, hit. Uh, let's let's try and test it.
OK.
Right. Uh, was this the one that you? This was one that you had to remake, right? Because I had the 'cause I had the.org.

Manjunath S   1:37:07
Yes, James yeah.org I just but did it my mistake and.
We deleted all the directories for them and recreated once again.

James Maki   1:37:25
OK, all right. And so in here, did you just edit the URL? Did you take out the.org and then save it? Is that how you?

Manjunath S   1:37:34
Yeah, yeah, I removed the and updated it as a Lang FCU.

James Maki   1:37:36
OK.

Manjunath S   1:37:48
Yeah, before they were not able to access, but now they are able to access.

James Maki   1:37:48
OK.
Who was able to access?

Manjunath S   1:37:58
The line set of which.
Like Vikas has just got me an update like after creating the new one I just sent him like only team can access but there are error images they are getting.

James Maki   1:38:22
All right.
Alright, so the error messages are getting there, so it's having trouble listing the directory. So it seems like it's still having trouble finding the Langley FCU folder that you created. So that's so that's what's causing the error. So.
The way that I would try to address that.
Uh.
How should we address that?
All right. Um.
Let me see.
You guys still never had like Bitwardin access figured out, right?

Manjunath S   1:40:15
No, James.

James Maki   1:40:19
OK.
And I don't know what to do about that. Um.
So like what I wanna try and do is is copy.
The properties from another company like one that's working.
Is what I wanna try and do.
Um.

Manjunath S   1:41:09
Test.

James Maki   1:41:15
I mean, yeah, you can if you want.

Manjunath S   1:41:22
Yeah.

James Maki   1:41:23
Alright, so that's one that's working.
So I would start with copying the username.
The the problem is the password because the password is encrypted, so you can't just copy that. Copy the username.

Manjunath S   1:41:49
Oh.

James Maki   1:41:50
No, not that username. No, go, go back, go back to where you were.

Manjunath S   1:41:56
URL.

James Maki   1:41:57
Go go back to LFCU, go back to the other one.

Manjunath S   1:42:00
Yeah.
A.

James Maki   1:42:04
And and go to properties.
The username right there. It's like in the middle.
Or is it username and password?

Manjunath S   1:42:14
Yes. Oh.

James Maki   1:42:17
Yeah, that copy that.
Alright, and then and then cancel this and let's go back over to the Langley one.
Uh, go ahead and paste it over the username.
Alright, uh, and hit OK.
1.

Manjunath S   1:42:55
Save.

James Maki   1:42:58
Yeah, go ahead, save it and then let's test it and let's see if that did anything.

Manjunath S   1:43:05
Test.

James Maki   1:43:06
Yeah.
I feel like it's probably not gonna help, but who knows, yeah.
So connect cost.
Uh, what can we do here?
Uh, go back over to the end of the URL again.
OK.
Alright, alright, how do we how do we change this? Alright, so I think there's some stuff missing from the URL.

Manjunath S   1:46:12
Uh.

James Maki   1:46:14
Uh.
Alright, uh.
Here. Um.
OK, here.
Alright, uh, in the URL change.
Overwrite. What's there with this? So it looks like there might be some more stuff to the URL.
So like everything from like the at symbol over to the company name.
Yeah, so I'll put it in the chat so you so you can copy what I have and overwrite overwrite what's there.

Manjunath S   1:47:18
Still here?
This whole thing, James.

James Maki   1:47:24
Uh.
That that's what you're gonna overwrite, yes.
Except for the company name.
No, sorry, no, I I sent it. Copy what I sent.
Copy what I sent and overwrite what's there for the URL.

Manjunath S   1:48:19
From the Earth chamber.

James Maki   1:48:23
Right.
And then and leave the company, yeah.

Manjunath S   1:48:28
Yeah.

James Maki   1:48:35
No, I I already, I already sent it. I'm telling you what to paste in. I sent it. The thing that I sent. The last thing that I sent, I sent the URL, yeah.

Manjunath S   1:48:42
Are you saying? Sorry, sorry, sorry, sorry, sorry.

James Maki   1:48:50
Yeah.
There you go. Yeah, paste that in. Alright, and let's test that.
I don't know if we need to save it first. Let's see.

Manjunath S   1:49:15
Service shape or like?

James Maki   1:49:17
Alright, let's let's let's go and test it. I mean, why not? It's just a test.
Hey, there we go. Hell yeah, that's what I'm talking about. All right, it's OK.

Manjunath S   1:49:23
Yeah, that sounds sexy.

James Maki   1:49:30
Alright, uh, and then save.
Alright, and now.
Alright, and now let's have them try again. Alright, well, hold on, let's before we do that, let's see if I can.
Why don't we test it first? Do you do you have their FTP credentials?
I think you sent it to me.

Manjunath S   1:49:51
Yes, chips.
Yeah, I have it.

James Maki   1:49:56
All right, let me see if I still.

Manjunath S   1:49:56
And is available or not? Yeah, I will send you the password.

James Maki   1:50:03
Let me see if you already sent it. I think you did.

Manjunath S   1:50:07
I'll send you again, right?

James Maki   1:50:18
All right, and this is for Langley FCU.
Wow, what the heck?
Alright, it's still saying it's having trouble listing the.
Yeah, come on, man. Really.
Alright, go back over to crush, see if it. Is it giving the error again?

Manjunath S   1:51:35
So we test the connection again.

James Maki   1:51:38
Yeah, did did you save it?

Manjunath S   1:51:42
Yeah.

James Maki   1:51:45
The.
Uh, check the URL again.
Yeah, it's back. It doesn't have the the dot file dot core. It doesn't have that stuff again.
Where's that pulling from?
Uh, try updating the URL again. Uh.
Paste in the the part that I sent.
What the heck?
All right, hit OK.
All right, and save again.
All right, let's go back to properties.
And and check to check the URLs, see if it's still there.
OK, alright.

Manjunath S   1:53:08
Test.

James Maki   1:53:12
Uh, no. I'm just gonna go ahead and run.
What the heck?
Why is this Kee reverting?
What is going on here?
That is not correct. You're not.
Go and test it.
OK.
So why am I still not getting into VaZilla?

Manjunath S   1:55:00
So I check the URL once again.

James Maki   1:55:05
Uh, sure.

Manjunath S   1:55:18
Wishing that file code.

James Maki   1:55:21
And it was gone again, wasn't it?

Manjunath S   1:55:23
Yeah.

James Maki   1:55:28
What the heck?

Manjunath S   1:55:43
OK.

James Maki   1:56:10
It wasn't. There was a second person that was having trouble, wasn't there? Wasn't there another client that was having like the same issue or something similar?

Manjunath S   1:56:21
No, James, only for Langley, I think so.

James Maki   1:56:25
Yes.

Manjunath S   1:56:30
But for the SFTP Selana had on ticket, I don't know what was the update on the Selana.

Saravanabhavan S   1:56:42
Yes, man, Joe.

Manjunath S   1:56:44
Yeah, I don't ticket it for that SFTP creation. Is it done?
Are you facing any issues on the?

Saravanabhavan S   1:56:55
So the only thing is build bottom access we raise the ticket.

Manjunath S   1:57:01
For the IP address.

Saravanabhavan S   1:57:05
No IP address. I done that. The teammate ticket you're asking, right?

Manjunath S   1:57:08
Oh, OK.
No, no, for the SFTP only. Oh yeah, don't take it right for the new connection SFTP.
Hello.

Saravanabhavan S   1:57:37
Yes, blue checking, blue it 812.

Manjunath S   1:57:48
So I think only for the the slam.
Mhm.

Saravanabhavan S   1:57:57
SFTPI don't have manjo but IP has been widely trans.

Manjunath S   1:58:05
OK.
Oh.
Um.

James Maki   1:58:11
Uh.
All right, I'm showing that the test is still successful when I when I try it.
Um, but when I try in FileZilla, like it's saying it's connected, but it's not actually listing out.
Like the contents like I can't see the image images and process folders.
So it's definitely not working.

Manjunath S   1:58:41
Uh, have you checked in the server?

James Maki   1:58:42
Please.
I mean, I don't think there's really anything to do on the server.
I think it has to do with like with the way that the the login is trying to find the directory. Like that's where the problem seems to be.
But.
All right. Um.
Let's try right over in crush. Let's just try setting up a whole new destination for it. Go ahead and cancel this. Or actually, let's see what? Yeah, go ahead. Dang it. How are we gonna do this?
Alright, I think I'm gonna have to do it since.
I'm the only one that's in.
Alright.
All right.
I'm just gonna create a new one, new remote item.
SMB 3.
FCU.
Alright, why didn't?
Oh, I think I supposed to do that first, OK.
OK.
Yes.
So here.
Spell stuff right.
Yeah, come on. Are you kidding me? What the hell is your deal?
Oh, why is this not saving currently? Why does this keep changing? I don't understand.
Why? Why do you keep ******* changing?
Literally doesn't make any sense.
This is so ******* annoying.
I don't understand why I just keep changing. Why is it not saving?
Just crap.
Just a bunch of crap.
It just immediately overrides it. It just immediately takes it out. It's not doing anything right. Now you don't even have to ******* add symbol here. What the hell?
This thing is so stupid.
Finally got it.
Oh my God, that was an absolute pain.
Bro, how are you gonna start giving an error after you just ******* worked? How the hell?
Unbelievable.
All right, I don't know what's going on. It keeps reverting like it's not saving the change, like the thing with the URL. That's definitely the problem.
I don't know why. I don't know why it's broken. I don't know.

Manjunath S   2:09:39
OK.

James Maki   2:09:45
I don't know, I don't know. But that's the answer. It's like it's the URL.
Because whenever it's there, whenever it has it the way that I set it, when I tell it what to ******* use, it works and then it keeps removing it and it keeps going back.
To the old URL and every time it does that is when it stops working.
So I don't know what's going on.
Um.
But that is 100% the problem.

Manjunath S   2:10:20
Oh.
Sados.
So like there'll be regularly, there'll be accessing like all the other items. So is this a major issue?

James Maki   2:10:35
And now it's and now it's working again.
All right, now it's working.

Manjunath S   2:10:48
OK.

James Maki   2:10:49
Alright, so maybe if we just stop touching it.
All right, it should be working now.
Lang Langley should be working.

Manjunath S   2:11:07
Yeah.
So like we need to test it again or just shall I respond to the OK, OK, OK.

James Maki   2:11:13
No, don't touch. Do not. Do not test it again. Don't touch it. It's working. Just respond on the ticket and tell them. Tell them to try it again.
Alright, alright, I need to drop so I have another call coming up.

Manjunath S   2:12:27
Oh.
Sure, yes.

James Maki   2:12:28
And and I have my own tickets that I'm working on. I'm trying to finish up today.

Manjunath S   2:12:33
Yeah.

James Maki   2:12:35
Alright, so let me do this. If there's anything else like high priority you guys still want help with today, shoot me a message and I should be done.
In 45 minutes. And if there's something else that I need that I can help you guys with, I will do what I can.

Manjunath S   2:12:48
Yeah.
OK, James.

James Maki   2:12:53
All right. All right. Thank you, guys.

Manjunath S   2:12:54
Thank you, James.

Saravanabhavan S   2:12:58
My minutes.

James Maki   2:12:59
Alright, alright, no problem. Talk to you later.

Saravanabhavan S stopped transcription
--------------------------------------------------------------------------------
Title: Sym-exchange.txt

USE CASE 9 - Disputes are in new state want to pushed over to active (Sym-exchange) or Load the dispute.

Step 1 – Go to the sonnet and select the company.
                                                                      
Step 2 – Go to Pg-admin and type query as    à select id from dispute where company_id = ____ and sonnet_status = 'New'
Step 3 – Once u execute the step 2 you will get the id below..

Step 4 – Go to sonnet admin and select the rules engine queue from the dispute section and paste the id one by one and click submit.
                                               
Step 6 – Run the Rules engine command in the command prompt till u find the company id.

Step 7 – Once you run the rules engine queue in the command prompt data waiting in the Sym-exchange should be changed to 0.
                             
Step 8 – Give a response and mark the ticket as solved.

--------------------------------------------------------------------------------
Title: UI Stuff 2.txt
*to find which controller the logic is in, just find the route in web.php

Dashboard

Dispute Backlog and Volume Per Day we use echarts
Changes are in dashboard.js (echart logic) and dashboard controller and dashboardHiome.blade

The tiles are in dashboardHome.blade but we use dashboard controller for the logic. 

The query for tiles is from the dispute table
Query for vpd from daily_totals table (not currently running in uat) except images which is dispute table – new pr making whole vpd graph asynchronous 

Reasons come from default_dispute_reason for the description and the dispute table for most popular dispute codes this month


As a Sonnet user, I want to see the number of disputes with images for 30 days regardless of status so that I can monitor my volume of disputes with images.

Load dashboard data in without making Sonnet slow

The problem is that there are so many disputes on the dispute table and the vpd images is not in the daily_totals table so ultimately for speed sake we just took out the  Complwted disputes from the graph, but that looks weird. Navy recently noticed that it looked weird so we need to address this.

After discussing with Lidi, we decided we needed to make the vpd data retrival asynchronous.  

We need a new method in the controller for this, so see pr 2302 https://dev.azure.com/Palinode/Sonnet/_git/4e242732-d1dc-47ab-a7d7-4ebce03855aa/pullrequest/2302

We need a new route in web.php and we need to update the data retrieval in dashboard.js to use ajax. 

As a Sonnet user, I want to see the number of disputes received for the day on the Dispute Received today tile so that I can see the actual number of disputes receiving.  On 08/05/2024 the download for 08/04/2024 was delayed so the count is showing 0, but there were 2909 disputes downloaded for the day, but the tile is still showing 0.  The volume line graph at the bottom and this tile should match.

Basically for this one the query was wrong at it was only looking for disputes created on before today and not today. Including this to show that all the dashboard queries are in the dashboardcontroller.

https://dev.azure.com/Palinode/Sonnet/_git/4e242732-d1dc-47ab-a7d7-4ebce03855aa/pullrequest/1939


 
Tiles are all in the dashboardHome blade. If you want to make a new one, just create the query or whatever data you want in the controller and then update the blade and css and voila.  

https://dev.azure.com/Palinode/Sonnet/_git/4e242732-d1dc-47ab-a7d7-4ebce03855aa/pullrequest/471

dispute.js

		
As a Sonnet user, I want Sonnet to update the consumer comparison indicators as I make changes to the consumer information so that I can save a step.

When the dispute is processed through the rules engine, the consumer comparison indicators are set.  The user can update the recommended response values and then Sonnet automatically updates the comparison indicator.  The user can also change the comparison indicator against sonnet's recommendation which will result in the user getting an error and be unable to submit.

I am searching in dispute.js for anywhere that has .addClass("eoscar-warning");
Instead of sending false validation, change the indicator if it pertains to the _comparison

We do some of them differently (names and addresses) so you also need to search _comparison and make sure you’re not returning true for any comparison

If you make changes in js or css, don’t forget npm run dev to see the changes

https://dev.azure.com/Palinode/Sonnet/_git/sonnet-app-20/pullrequest/2312




When the response code 01, 12, 21, 22, 23, or 24 then the ssn and dob comparison indicator should be selected and not left blank.  Do not allow the user to navigate away from the consumer information if the ssn and dob comparison indicator is left blank.  Should function like the middle name field and comparison


So when the ssn, dob, or middle_name fields are blank, the inicator has to be Unk and not blank 
  function isValidDate(dateString, dateType = "") {
    // blank is OK

    if (dateType == "dob" && dateString == "" && $('select[name="dob_comparison"]').val() != "Unk") {
      $('select[name="dob_comparison"]').val('Unk').change;
      verify_consumer_fields()
      return true;
    } else if (dateType == "dob" && dateString != "" && $('select[name="dob_comparison"]').val() == "") {
      $('select[name="dob_comparison"]').val('Unk').change;
      verify_consumer_fields()
      return true;
    } else if (dateType == "dob" && dateString == "" && $('select[name="dob_comparison"]').val() == "Unk") {
      return true;
    } else if (dateType != "dob" && dateString == "") {
      return true;
    }



User used the consumer information indicator E without a DOFD and was able to complete in Sonnet, but the dispute was returned with a response error - FCRA 1st Date of Delinquency is required when Consumer Information Indicator is E. Sep 27th, 2023, 8:25:39am CDT.  

The user then corrects the response error and inputs the DOFD, but Sonnet will not allow the user to complete as it produces the error 

https://dev.azure.com/Palinode/Sonnet/_git/4e242732-d1dc-47ab-a7d7-4ebce03855aa/pullrequest/1264

this is old but if Date of Delinquency must have a value if consumer information indicator is 'E'


Reports (most common UI request)

e-Oscar Report Card is showing different totals between the total number of items based on the response type and the total number of items based on the response time. The response type is showing the correct number so need to identify where the extras are coming from for the All eOscar Queues.

Reports are in either acdvreportsservice (dispute), directreportservice, customreportservice, audreportservice, brrreportservice, 

If the customer wants any report that is just for them, put it in custom so we’re not cluttering up the main reports with if statements

For the above bug, the fix was in the accdvreportsservice and the function was eoscarReportCardReport. You can look for the title from the browser and then the function related to it to find the report 

https://dev.azure.com/Palinode/Sonnet/_git/4e242732-d1dc-47ab-a7d7-4ebce03855aa/pullrequest/2189?_a=files

As a Sonnet user, I want to see a Direct Dispute Checklist report for each Direct Dispute Completed in Sonnet with the Sonnet ID, Account Number, Date Complete, User who completed and each checklist item so that I can have better reporting for checklist utilization for Direct Disputes.

This was a brand new report request but it was one that we wanted to globally offer so we wrote a new array item in the constructor for directreportsservice. Each of those things get sent in the payload to return the needed information. And then the function is where you would go to write the query.

https://dev.azure.com/Palinode/Sonnet/_git/4e242732-d1dc-47ab-a7d7-4ebce03855aa/pullrequest/2278

Getting an error


This was happening in the blade. When you run that report to see the error, the category will tell you which service is is, the the name will tell you which function it is, and then the function name is the blade name (plus blade.php at the end) 

https://dev.azure.com/Palinode/Sonnet/_git/4e242732-d1dc-47ab-a7d7-4ebce03855aa/pullrequest/2036

--------------------------------------------------------------------------------
Title: USER CREATION.txt
USE CASE   -   SONNET USER CREATION.

STEP 1 – Go to sonnet and select the company.

STEP 2 - Select menu at right top corner and click on the sonnet admin and select view users and click on the add user.
                                                
STEP 3 – Enter the appropriate information in each of the designated fields.


*** First name, last name and e-mail address will be available in the Zendesk.
STEP 4– If the IP address is not specified in the zen desk then add all the available IP addresses and click on add user.
STEP 5 – Re-fresh the page and check whether the user id created or not.
STEP 6- Give response to the ticket and mark it as solved.
--------------------------------------------------------------------------------
Title: Whitelisting IP.txt

Use Case 5 – Whitelisting IP 


Select the company in the sonnet.
Select menu at right top corner and click on sonnet admin.
Click view users and click on the users.
Copy the given IP from the Zendesk and find for the IP, If the IP is not found then need to create the new IP.
Creating New IP.
Go to menu click on the sonnet Admin and select edit company and click on the IP address and select the user.
Paste the IP address on the IPV4 and click on the user and add the description and click on the save changes.
Come back to Zendesk and give the response to the ticket and mark it as solved.

--------------------------------------------------------------------------------
